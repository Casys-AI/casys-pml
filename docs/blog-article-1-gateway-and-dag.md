# L'architecture Gateway MCP : DÃ©couverte sÃ©mantique et exÃ©cution parallÃ¨le

**Auteur:** AgentCards Team
**Date:** Janvier 2025
**Sujets:** MCP Protocol, Agent Architecture, Performance Optimization

---

## Le paradoxe de la scalabilitÃ© MCP

Le Model Context Protocol (MCP) se voulait le "standard USB" des agents IA â€” une interface universelle pour connecter les modÃ¨les de langage aux outils et sources de donnÃ©es. Et sur de nombreux aspects, c'est une rÃ©ussite : des centaines de serveurs MCP existent aujourd'hui, couvrant l'accÃ¨s aux systÃ¨mes de fichiers, l'intÃ©gration GitHub, les requÃªtes de bases de donnÃ©es, et bien plus encore.

Mais il y a une ironie au cÅ“ur de l'adoption de MCP : **le protocole scale, mais pas l'expÃ©rience utilisateur.**

L'architecture standard aujourd'hui consiste Ã  connecter Claude Desktop (ou Claude Code) directement Ã  plusieurs serveurs MCP simultanÃ©ment. Une configuration typique ressemble Ã  ceci :

```json
{
  "mcpServers": {
    "filesystem": { "command": "npx", "args": ["-y", "@modelcontextprotocol/server-filesystem"] },
    "github": { "command": "npx", "args": ["-y", "@modelcontextprotocol/server-github"] },
    "database": { "command": "npx", "args": ["-y", "@modelcontextprotocol/server-postgres"] },
    // ... 12 serveurs supplÃ©mentaires
  }
}
```

Cette approche fonctionne admirablement bien pour 3 Ã  5 serveurs. Mais au-delÃ  de 15 serveurs, des fissures apparaissent :

1. **Saturation du contexte** : Les schÃ©mas d'outils consomment 30-50% de la fenÃªtre de contexte de Claude avant mÃªme que le travail ne commence
2. **ExÃ©cution sÃ©quentielle** : Les workflows multi-outils s'exÃ©cutent un outil Ã  la fois, accumulant de la latence
3. **Ballonnement des donnÃ©es intermÃ©diaires** : Des ensembles de donnÃ©es volumineux transitent inutilement par la fenÃªtre de contexte

Ce ne sont pas des bugs â€” ce sont des limitations architecturales du modÃ¨le de connexion directe.

Dans cet article (premier d'une sÃ©rie de deux), nous explorons deux concepts architecturaux qui adressent ces limitations :

1. **Semantic Gateway Pattern** â€” DÃ©couverte dynamique d'outils via recherche vectorielle
2. **DAG-Based Parallel Execution** â€” Ã‰liminer les goulots d'Ã©tranglement sÃ©quentiels via des graphes de dÃ©pendances

---

## Concept 1 : Le Semantic Gateway Pattern

### De la dÃ©couverte statique Ã  la dÃ©couverte dynamique

Le protocole MCP dÃ©finit une mÃ©thode simple pour la dÃ©couverte d'outils : le client demande la liste complÃ¨te, le serveur renvoie tous ses outils. Simple, mais avec un problÃ¨me critique : **aucun contexte sur ce que l'utilisateur essaie de faire**.

Le serveur n'a d'autre choix que de tout renvoyer. Si vous avez 15 serveurs MCP avec en moyenne 45 outils chacun, cela reprÃ©sente 687 schÃ©mas d'outils chargÃ©s dans le contexte de Claude. Ã€ environ 80-150 tokens par schÃ©ma, on parle de 55 000 Ã  103 000 tokens consommÃ©s avant le premier message utilisateur.

Pour la fenÃªtre de contexte de 200 000 tokens de Claude, cela reprÃ©sente **27-51% de surcharge rien que pour les dÃ©finitions d'outils**.

Cette dÃ©cision architecturale avait du sens quand MCP Ã©tait nouveau et les serveurs peu nombreux. Mais elle ne passe pas Ã  l'Ã©chelle. C'est une asymÃ©trie d'information : le serveur ne connaÃ®t pas l'intention de l'utilisateur, donc il doit tout envoyer. Le client doit tout charger pour dÃ©cider ce qui est pertinent.

### L'architecture Gateway

Une gateway se positionne entre Claude et vos serveurs MCP :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARCHITECTURE TRADITIONNELLE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                          â”‚  Claude Code â”‚                              â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                  â”‚                                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚              â”‚                   â”‚                   â”‚                 â”‚
â”‚              â–¼                   â–¼                   â–¼                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚    â”‚  Filesystem MCP â”‚ â”‚   GitHub MCP    â”‚ â”‚  Database MCP   â”‚       â”‚
â”‚    â”‚   (8 outils)    â”‚ â”‚   (12 outils)   â”‚ â”‚   (15 outils)   â”‚       â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                         â”‚
â”‚              Tous les 35 schÃ©mas chargÃ©s dans le contexte              â”‚
â”‚              Utilisation : ~4,200 tokens (2.1% de 200K)                â”‚
â”‚              Pour 15 serveurs : ~82,440 tokens (41% du contexte !)     â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ARCHITECTURE GATEWAY                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                          â”‚  Claude Code â”‚                              â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                  â”‚ Connexion MCP unique                â”‚
â”‚                                  â–¼                                      â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚   AgentCards Gateway    â”‚                         â”‚
â”‚                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                         â”‚
â”‚                    â”‚  ğŸ” Vector Search       â”‚                         â”‚
â”‚                    â”‚  ğŸ“Š PGlite + pgvector   â”‚                         â”‚
â”‚                    â”‚  ğŸ§  Semantic Discovery  â”‚                         â”‚
â”‚                    â”‚  âš¡ DAG Executor        â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                               â”‚ Proxy des appels d'outils               â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚              â”‚                â”‚                â”‚                        â”‚
â”‚              â–¼                â–¼                â–¼                        â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚    â”‚  Filesystem MCP â”‚ â”‚   GitHub MCP    â”‚ â”‚  Database MCP   â”‚       â”‚
â”‚    â”‚   (8 outils)    â”‚ â”‚   (12 outils)   â”‚ â”‚   (15 outils)   â”‚       â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                               â”‚                                         â”‚
â”‚              ... + 12 serveurs MCP supplÃ©mentaires (15 au total)       â”‚
â”‚                                                                         â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚    â”‚ RequÃªte : "Lire les fichiers de configuration"            â”‚     â”‚
â”‚    â”‚ â†’ La recherche vectorielle identifie 3 outils pertinents : â”‚     â”‚
â”‚    â”‚   â€¢ filesystem:read_file                                   â”‚     â”‚
â”‚    â”‚   â€¢ filesystem:list_directory                              â”‚     â”‚
â”‚    â”‚   â€¢ json:parse                                             â”‚     â”‚
â”‚    â”‚                                                             â”‚     â”‚
â”‚    â”‚ Utilisation contexte : ~360 tokens (0.18%)                 â”‚     â”‚
â”‚    â”‚ vs. charger les 687 outils : ~82,440 tokens (41%)          â”‚     â”‚
â”‚    â”‚                                                             â”‚     â”‚
â”‚    â”‚ ğŸ¯ RÃ©duction du contexte : amÃ©lioration de 229x            â”‚     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

La gateway fournit un point de terminaison MCP unique Ã  Claude tout en maintenant des connexions vers tous vos serveurs MCP rÃ©els. Mais plus important encore, elle peut prendre des dÃ©cisions intelligentes sur les outils Ã  exposer.

### Les embeddings vectoriels comme mÃ©canisme de dÃ©couverte

Pourquoi la recherche vectorielle plutÃ´t qu'une indexation traditionnelle ?

Les approches basÃ©es sur des mots-clÃ©s Ã©chouent rapidement. Par exemple, pour l'intention "Lire les fichiers de configuration et les parser", une recherche par mots-clÃ©s manquerait `yaml:load` (vocabulaire diffÃ©rent) ou `S3:get_object` (pourrait lire des configs depuis S3).

Les embeddings sÃ©mantiques capturent l'intention Ã  travers les variations de vocabulaire :

```
RequÃªte : "lire les fichiers de configuration et les parser"

Scores de similaritÃ© sÃ©mantique :
[0.94] filesystem:read_file
[0.89] json:parse
[0.87] yaml:load
[0.85] toml:parse
[0.81] S3:get_object
[0.78] config:get_value
[0.24] github:create_issue  â† Correctement exclu
[0.19] slack:send_message   â† Correctement exclu
```

La gateway gÃ©nÃ¨re des embeddings pour tous les schÃ©mas d'outils lors de l'initialisation (opÃ©ration ponctuelle), puis effectue une recherche de similaritÃ© vectorielle au moment de l'exÃ©cution. La philosophie d'implÃ©mentation est simple :

**Initialisation** : Pour chaque outil, on combine nom + description + schÃ©ma en un texte recherchable, on gÃ©nÃ¨re l'embedding, et on le stocke dans une base vectorielle (PGlite + pgvector).

**Recherche runtime** : On gÃ©nÃ¨re l'embedding de l'intention utilisateur, on interroge la base vectorielle avec un seuil de similaritÃ© (0.6), et on retourne les outils les plus pertinents.

> **Note de validation :** Les mÃ©triques de rÃ©duction de contexte (229x) sont validÃ©es empiriquement par nos tests. Pour une requÃªte typique "lire config.json et crÃ©er une issue GitHub", la recherche vectorielle identifie 3 outils pertinents sur 687 disponibles (score de similaritÃ© >0.6), rÃ©duisant l'utilisation du contexte de 82,440 tokens (41%) Ã  360 tokens (0.18%) â€” une amÃ©lioration de 229x. Temps de recherche : <6ms en moyenne.

### Embeddings locaux vs. cloud : analyse des trade-offs

Nous avons choisi les embeddings locaux (Transformers.js + BGE-M3) plutÃ´t que les API cloud. Voici pourquoi :

**Embeddings locaux (notre choix) :**
- âœ… Latence nulle (pas d'aller-retour rÃ©seau)
- âœ… ConfidentialitÃ© totale (aucune donnÃ©e ne quitte la machine)
- âœ… CoÃ»t nul (pas de frais d'API)
- âœ… Fonctionne hors ligne
- âš ï¸ CoÃ»t de setup ponctuel (60s pour embedder 687 outils)
- âš ï¸ QualitÃ© : trÃ¨s bonne, pas parfaite

**Embeddings cloud (OpenAI, Cohere, Voyage) :**
- âœ… Meilleure qualitÃ© d'embedding
- âš ï¸ Latence de 100-300ms par requÃªte
- âš ï¸ PrÃ©occupations de confidentialitÃ© (les schÃ©mas rÃ©vÃ¨lent l'architecture systÃ¨me)
- âš ï¸ CoÃ»ts API qui scalent avec l'usage
- âš ï¸ DÃ©pendance rÃ©seau

Pour une gateway qui s'exÃ©cute localement et manipule des schÃ©mas d'outils potentiellement sensibles, **la confidentialitÃ© et la latence l'emportent sur des amÃ©liorations marginales de qualitÃ©**. Le modÃ¨le local est "suffisamment bon" pour la rÃ©cupÃ©ration d'outils â€” nous voyons rarement des outils pertinents classÃ©s sous le seuil.

### La gateway comme middleware universel

Une question intÃ©ressante se pose : la recherche sÃ©mantique devrait-elle faire partie du protocole MCP lui-mÃªme ?

**Arguments pour l'extension du protocole :**
- Standardise la dÃ©couverte sÃ©mantique
- Permet aux clients d'optimiser leur propre chargement d'outils
- RÃ©trocompatible (paramÃ¨tre optionnel)

**Arguments contre :**
- DÃ©place la complexitÃ© vers chaque implÃ©mentation de serveur
- Tous les serveurs n'ont pas de capacitÃ©s d'embedding
- Pourrait fragmenter l'Ã©cosystÃ¨me
- La recherche sÃ©mantique n'est peut-Ãªtre pas la bonne primitive pour tous les cas d'usage

**Notre approche : La gateway comme couche middleware**

Au lieu d'exiger que tous les serveurs MCP implÃ©mentent la recherche sÃ©mantique, la gateway la fournit comme couche universelle. Tout serveur MCP existant en bÃ©nÃ©ficie immÃ©diatement sans modification de code. Les serveurs restent simples. La complexitÃ© vit Ã  un seul endroit.

Cela reflÃ¨te des patterns de l'infrastructure web : nginx gÃ¨re le caching et le load balancing pour que les services backend n'aient pas Ã  le faire. La gateway MCP gÃ¨re l'optimisation de la dÃ©couverte d'outils pour que les serveurs MCP n'aient pas Ã  le faire.

---

## Concept 2 : ExÃ©cution parallÃ¨le basÃ©e sur les DAGs

### GraphRAG vs DAG : clarification architecturale

Avant de plonger dans l'exÃ©cution parallÃ¨le, il est crucial de comprendre la distinction entre deux composants architecturaux qui travaillent ensemble :

**GraphRAG (Graphe de connaissances)** â€” La base de connaissances complÃ¨te
- Stocke TOUS les outils de TOUS les serveurs MCP (ex: 687 outils)
- Contient l'historique des exÃ©cutions de workflows et leurs patterns de succÃ¨s/Ã©chec
- Maintient les relations entre outils (ex: "filesystem:read souvent suivi de json:parse")
- Contient les embeddings pour la recherche sÃ©mantique
- **PortÃ©e :** Globale, toutes les possibilitÃ©s

**DAG (Directed Acyclic Graph)** â€” L'instance de workflow spÃ©cifique
- Un workflow concret pour UNE tÃ¢che spÃ©cifique
- Contient seulement les 3-5 outils pertinents pour cette requÃªte
- DÃ©finit explicitement les dÃ©pendances (la tÃ¢che B dÃ©pend de la tÃ¢che A)
- **PortÃ©e :** Locale, exÃ©cution unique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GRAPHRAG : Toutes les possibilitÃ©s (Base de connaissances) â”‚
â”‚                                                        â”‚
â”‚ â€¢ 687 outils sur 15 serveurs                          â”‚
â”‚ â€¢ 10,000+ exÃ©cutions historiques                      â”‚
â”‚ â€¢ Relations entre outils & patterns                   â”‚
â”‚ â€¢ Embeddings vectoriels pour la recherche             â”‚
â”‚                                                        â”‚
â”‚ Exemple de relations apprises :                       â”‚
â”‚ - "filesystem:read" â†’ "json:parse" (85% corrÃ©lation)  â”‚
â”‚ - "git:log" â†’ "text:summarize" (72% corrÃ©lation)      â”‚
â”‚                                                        â”‚
â”‚ = LA CONNAISSANCE, pas l'exÃ©cution                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ Intention utilisateur : "Lire config et crÃ©er issue"
                 â”‚
                 â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  DAG SUGGESTER      â”‚  â† Couche d'intelligence
       â”‚                     â”‚
       â”‚ 1. Interroger GraphRAG
       â”‚ 2. Trouver les patterns
       â”‚ 3. PrÃ©dire le workflow
       â”‚ 4. Construire le DAG
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DAG : Instance de workflow spÃ©cifique                   â”‚
â”‚                                                          â”‚
â”‚ tasks: [                                                 â”‚
â”‚   { id: "t1", tool: "filesystem:read_file" },           â”‚
â”‚   { id: "t2", tool: "json:parse", depends_on: ["t1"] }, â”‚
â”‚   { id: "t3", tool: "github:create_issue",              â”‚
â”‚     depends_on: ["t2"] }                                 â”‚
â”‚ ]                                                        â”‚
â”‚                                                          â”‚
â”‚ = LE PLAN D'EXÃ‰CUTION, extrait de la connaissance       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pourquoi cette distinction est importante :**
- GraphRAG = "Quels workflows ont fonctionnÃ© avant ?"
- DAG Suggester = "BasÃ© sur cette intention, quel workflow construire ?"
- DAG = "Voici le plan concret Ã  exÃ©cuter"
- DAG Executor = "ExÃ©cutons ce plan (possiblement de maniÃ¨re spÃ©culative)"

Sans GraphRAG (la connaissance), on ne peut pas prÃ©dire quel DAG construire. Sans DAG (la structure), on ne peut pas exÃ©cuter les workflows en parallÃ¨le. Ils sont complÃ©mentaires.

### Le goulot d'Ã©tranglement de l'exÃ©cution sÃ©quentielle

Les workflows MCP aujourd'hui s'exÃ©cutent sÃ©quentiellement. Le LLM doit :
1. Faire un appel d'outil
2. Attendre le rÃ©sultat
3. Incorporer le rÃ©sultat dans le contexte
4. DÃ©cider du prochain appel d'outil
5. RÃ©pÃ©ter

C'est by design. MCP garde les serveurs stateless et simples. L'orchestration est laissÃ©e au client (Claude). Mais cela crÃ©e un goulot d'Ã©tranglement fondamental : **mÃªme quand les tÃ¢ches sont indÃ©pendantes, elles s'exÃ©cutent en sÃ©rie**.

Prenons un exemple concret :

```
RequÃªte utilisateur : "Lire ces 5 fichiers de configuration"
Fichiers : config.json, database.json, api.json, auth.json, features.json

Timeline d'exÃ©cution (sÃ©quentielle) :
0.0s â†’ 1.2s: Lire config.json
1.2s â†’ 2.3s: Lire database.json
2.3s â†’ 3.3s: Lire api.json
3.3s â†’ 4.6s: Lire auth.json
4.6s â†’ 5.7s: Lire features.json

Temps total : 5.7 secondes
```

Mais ces lectures sont **complÃ¨tement indÃ©pendantes**. Elles pourraient s'exÃ©cuter en parallÃ¨le :

```
Timeline d'exÃ©cution (parallÃ¨le) :
0.0s â†’ 1.2s: Lire les 5 fichiers simultanÃ©ment
             (le fichier le plus long prend 1.2s)

Temps total : 1.2 secondes
AccÃ©lÃ©ration : 4.75x
```

Pourquoi cela n'arrive-t-il pas automatiquement ? **Parce que le protocole MCP n'exprime pas les dÃ©pendances entre les appels d'outils**.

### Introduction au modÃ¨le d'exÃ©cution DAG

Un **Graphe Acyclique DirigÃ© (DAG)** reprÃ©sente explicitement les dÃ©pendances entre les tÃ¢ches. Voici la diffÃ©rence :

**Workflow sÃ©quentiel :**
```
t1 â†’ t2 â†’ t3
(doit s'exÃ©cuter sÃ©quentiellement)
```

**Workflow parallÃ¨le :**
```
t1 â”€â”
t2 â”€â”¤
t3 â”€â”¼â”€â†’ Toutes s'exÃ©cutent simultanÃ©ment
t4 â”€â”¤
t5 â”€â”˜
```

L'executeur DAG utilise un tri topologique pour identifier les "couches" de tÃ¢ches qui peuvent s'exÃ©cuter en parallÃ¨le. Pour chaque couche, toutes les tÃ¢ches s'exÃ©cutent simultanÃ©ment via `Promise.all()`. Entre les couches, on attend que toutes les tÃ¢ches se terminent avant de passer Ã  la suivante.

### RÃ©solution de dÃ©pendances avec les rÃ©fÃ©rences $OUTPUT

Les tÃ¢ches ont souvent besoin des rÃ©sultats des tÃ¢ches prÃ©cÃ©dentes. Nous utilisons une syntaxe de placeholder simple :

```typescript
{
  id: "t2",
  tool: "json:parse",
  arguments: {
    input: "$OUTPUT[t1]"  // RÃ©fÃ©rence au rÃ©sultat de t1
  },
  depends_on: ["t1"]
}
```

Cela supporte des rÃ©fÃ©rences complexes avec une syntaxe de style JSONPath :

```typescript
{
  arguments: {
    title: "$OUTPUT[t1].config.version",      // AccÃ¨s Ã  une propriÃ©tÃ© profonde
    tags: "$OUTPUT[t2][0].labels",            // Indexation de tableau
    summary: "$OUTPUT[t3].data.summary.text"  // Objets imbriquÃ©s
  }
}
```

### Quand l'exÃ©cution parallÃ¨le est-elle importante ?

Nous avons benchmarkÃ© divers patterns de workflows :

| Type de workflow | TÃ¢ches | SÃ©quentiel | ParallÃ¨le | AccÃ©lÃ©ration |
|-----------------|--------|------------|-----------|--------------|
| Lectures de fichiers indÃ©pendantes | 5 | 5.7s | 1.2s | **4.75x** |
| Appels API parallÃ¨les (I/O bound) | 8 | 12.4s | 2.1s | **5.90x** |
| Mixte (quelques dÃ©pendances) | 10 | 15.2s | 4.8s | **3.17x** |
| ChaÃ®ne purement sÃ©quentielle | 5 | 5.7s | 5.7s | **1.00x** |
| Fan-out puis fan-in | 12 | 18.9s | 4.2s | **4.50x** |

**Insight clÃ© : Les gains de parallÃ©lisation sont proportionnels Ã  la "largeur" du workflow** (nombre de branches indÃ©pendantes).

### Comparaison visuelle : ExÃ©cution sÃ©quentielle vs. parallÃ¨le

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EXÃ‰CUTION SÃ‰QUENTIELLE (MCP Traditionnel)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Workflow : Lire 5 fichiers de config                                  â”‚
â”‚                                                                         â”‚
â”‚  t=0.0s â”€â”€â”€â”€â”€â–º lire config1 â”€â”€â”€â”€â”€â–º [1.2s] â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                                                  â”‚                      â”‚
â”‚  t=1.2s â”€â”€â”€â”€â”€â–º lire config2 â”€â”€â”€â”€â”€â–º [1.1s] â”€â”€â”€â”€â”€â”€â”¤                      â”‚
â”‚                                                  â”‚                      â”‚
â”‚  t=2.3s â”€â”€â”€â”€â”€â–º lire config3 â”€â”€â”€â”€â”€â–º [1.0s] â”€â”€â”€â”€â”€â”€â”¤  Attente             â”‚
â”‚                                                  â”‚  sÃ©quentielle        â”‚
â”‚  t=3.3s â”€â”€â”€â”€â”€â–º lire config4 â”€â”€â”€â”€â”€â–º [1.3s] â”€â”€â”€â”€â”€â”€â”¤                      â”‚
â”‚                                                  â”‚                      â”‚
â”‚  t=4.6s â”€â”€â”€â”€â”€â–º lire config5 â”€â”€â”€â”€â”€â–º [1.1s] â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                                         â”‚
â”‚  t=5.7s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º TERMINÃ‰                          â”‚
â”‚                                                                         â”‚
â”‚  Temps total : 5.7 secondes                                            â”‚
â”‚  Temps d'inactivitÃ© CPU : ~80% (attente I/O)                           â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EXÃ‰CUTION PARALLÃˆLE (BasÃ©e sur DAG)                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Workflow : Lire 5 fichiers de config (mÃªmes tÃ¢ches, parallÃ©lisÃ©es)    â”‚
â”‚                                                                         â”‚
â”‚                â”Œâ”€â–º lire config1 â”€â–º [1.2s] â”€â”€â”                          â”‚
â”‚                â”‚                             â”‚                          â”‚
â”‚                â”œâ”€â–º lire config2 â”€â–º [1.1s] â”€â”€â”¤                          â”‚
â”‚                â”‚                             â”‚                          â”‚
â”‚  t=0.0s â”€â”€â”€â”€â”€â”€â”€â”¼â”€â–º lire config3 â”€â–º [1.0s] â”€â”€â”¼â”€â–º TERMINÃ‰ (toutes complÃ¨tes) â”‚
â”‚                â”‚                             â”‚                          â”‚
â”‚                â”œâ”€â–º lire config4 â”€â–º [1.3s] â—„â”€â”˜   (tÃ¢che la plus longue: 1.3s) â”‚
â”‚                â”‚                                                        â”‚
â”‚                â””â”€â–º lire config5 â”€â–º [1.1s]                              â”‚
â”‚                                                                         â”‚
â”‚  t=1.3s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º TERMINÃ‰                          â”‚
â”‚                                                                         â”‚
â”‚  Temps total : 1.3 secondes (max de toutes les tÃ¢ches parallÃ¨les)      â”‚
â”‚  AccÃ©lÃ©ration : 4.4x plus rapide                                       â”‚
â”‚  Utilisation CPU : ~95% (tous les cÅ“urs actifs)                        â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Les workflows du monde rÃ©el ont typiquement 30-50% de tÃ¢ches parallÃ©lisables. MÃªme les workflows modestes voient des accÃ©lÃ©rations de 2-3x. Les workflows hautement parallÃ¨les (lecture de multiples fichiers, appels multiples d'API) peuvent voir des amÃ©liorations de 5-6x.

### Pattern complexe : Fan-Out, Fan-In

Un pattern courant est le "fan-out, fan-in" : exÃ©cuter plusieurs tÃ¢ches en parallÃ¨le, puis agrÃ©ger les rÃ©sultats.

```
Workflow : "Lire 5 configs, parser chacune, puis agrÃ©ger en un rÃ©sumÃ©"

                         â”Œâ”€â–º lire f1 â”€â–º [0.8s] â”€â”€â”
                         â”‚                        â”‚
  t=0.0s â–º lister fichiers â”€â”¼â”€â–º lire f2 â”€â–º [0.9s] â”€â”€â”¼â”€â–º parser tous â”€â”€â”
           [0.5s]        â”‚                        â”‚   [0.3s]      â”‚
                         â””â”€â–º lire f3 â”€â–º [0.7s] â”€â”€â”˜               â”‚
                                                                  â”‚
  t=1.4s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º agrÃ©ger  â”‚
                                                         [0.2s]   â”‚
                                                                  â”‚
  t=1.6s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º TERMINÃ‰

  Couche 0 : lister (1 tÃ¢che)         â†’ 0.5s
  Couche 1 : lire (3 parallÃ¨les)      â†’ 0.9s (max)
  Couche 2 : parser (1 tÃ¢che)         â†’ 0.3s
  Couche 3 : agrÃ©ger (1 tÃ¢che)        â†’ 0.2s

  Total : 1.9s
  SÃ©quentiel serait : 0.5 + (0.8+0.9+0.7) + 0.3 + 0.2 = 3.4s
  AccÃ©lÃ©ration : 1.8x
```

Ce pattern est extrÃªmement courant dans les workflows d'agents : rÃ©cupÃ©rer des donnÃ©es de multiples sources, traiter en parallÃ¨le, puis agrÃ©ger pour l'analyse finale.

---

## Conclusion de la Partie 1

Nous avons explorÃ© deux concepts architecturaux qui adressent les limitations de scalabilitÃ© de l'architecture MCP traditionnelle :

1. **Semantic Gateway Pattern** : Utiliser la recherche vectorielle pour exposer dynamiquement uniquement les outils pertinents, rÃ©duisant l'utilisation du contexte de 229x (validÃ© empiriquement)

2. **DAG-Based Parallel Execution** : Exprimer explicitement les dÃ©pendances entre tÃ¢ches pour permettre l'exÃ©cution parallÃ¨le, avec des accÃ©lÃ©rations de 2-6x selon la "largeur" du workflow

Ces deux concepts fonctionnent en synergie : la gateway rÃ©duit la surcharge de contexte, rendant possible l'ajout de plus de serveurs MCP, tandis que l'exÃ©cution DAG optimise les workflows multi-outils qui deviennent possibles avec cet Ã©cosystÃ¨me Ã©largi.

Dans la **Partie 2** de cette sÃ©rie, nous explorerons deux concepts encore plus ambitieux :

- **Agent Code Sandboxing** : DÃ©placer la computation hors du protocole vers l'exÃ©cution locale de code
- **Speculative Execution** : PrÃ©dire et prÃ©-exÃ©cuter les workflows avant mÃªme qu'ils soient demandÃ©s

Ces concepts poussent encore plus loin les limites de ce qui est possible avec l'architecture MCP, introduisant des questions fascinantes sur la sÃ©curitÃ©, l'intelligence prÃ©dictive, et l'avenir des agents IA.

---

**Ã€ propos d'AgentCards** : AgentCards est une exploration open-source de patterns architecturaux avancÃ©s pour les agents MCP. Le code complet et les benchmarks sont disponibles sur GitHub.

**Questions ou feedback ?** Nous serions ravis d'entendre vos retours sur ces concepts. Ces patterns devraient-ils faire partie du protocole MCP lui-mÃªme ? Contactez-nous sur notre dÃ©pÃ´t GitHub.
