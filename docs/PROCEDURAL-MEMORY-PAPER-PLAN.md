# Procedural Memory Layer - Research & Communication Plan

> Document crÃ©Ã© le 2025-12-13
> Objectif: Ã‰valuer et planifier la publication scientifique + communication LinkedIn

---

## 0. Explication simple (pour ta femme, tes parents, n'importe qui)

### Version 30 secondes

> **"J'apprends aux robots Ã  se souvenir de comment faire les choses."**
>
> Aujourd'hui, quand tu demandes Ã  ChatGPT de faire une tÃ¢che, il oublie tout aprÃ¨s. La prochaine fois, il recommence de zÃ©ro.
>
> Mon systÃ¨me, c'est comme lui donner une mÃ©moire musculaire. Comme quand tu apprends Ã  faire du vÃ©lo : au dÃ©but tu rÃ©flÃ©chis Ã  chaque mouvement, puis Ã§a devient automatique.

---

### Version 2 minutes (avec analogie cuisine)

**Le problÃ¨me:**

Imagine un chef qui, chaque fois qu'il doit faire une omelette, relit la recette depuis le dÃ©but. MÃªme s'il en a fait 100 avant. Il ne se souvient jamais de comment il l'a faite la derniÃ¨re fois.

C'est exactement ce que font les assistants IA aujourd'hui. Ils ont une super mÃ©moire pour les **faits** (les recettes), mais zÃ©ro mÃ©moire pour les **gestes** (comment cuisiner).

**Ma solution:**

Je construis un systÃ¨me qui leur donne une "mÃ©moire des gestes" :

1. **Il observe** â€” Quand l'IA fait quelque chose qui marche, mon systÃ¨me note exactement ce qu'elle a fait

2. **Il se souvient** â€” La prochaine fois qu'on lui demande quelque chose de similaire, il retrouve ce qui a marchÃ© avant

3. **Il s'amÃ©liore** â€” Si une mÃ©thode Ã©choue souvent, il la propose moins. Si elle marche bien, il la propose plus.

**RÃ©sultat:**

Au lieu de tout rÃ©inventer Ã  chaque fois, l'IA rÃ©utilise ce qui a dÃ©jÃ  marchÃ©. C'est plus rapide, plus fiable, et Ã§a s'amÃ©liore avec le temps.

---

### Version technique-mais-accessible (pour un dev ou quelqu'un de curieux)

**Les 3 types de mÃ©moire humaine:**

| Type | C'est quoi | Exemple | L'IA aujourd'hui |
|------|------------|---------|------------------|
| **SÃ©mantique** | Les faits | "Paris est la capitale de la France" | âœ… RAG, ChatGPT |
| **Ã‰pisodique** | Les Ã©vÃ©nements | "Hier j'ai mangÃ© une pizza" | âœ… Historique de conversation |
| **ProcÃ©durale** | Les gestes | "Comment faire du vÃ©lo" | âŒ **Personne ne fait Ã§a** |

**Ce que je construis:**

Un systÃ¨me qui capture la **mÃ©moire procÃ©durale** des agents IA :

- Quand l'agent Ã©crit du code qui marche â†’ on le stocke
- On dÃ©duit automatiquement les paramÃ¨tres (qu'est-ce qui peut changer)
- On suit le taux de succÃ¨s (est-ce que Ã§a marche souvent?)
- On dÃ©tecte les dÃ©pendances (cette action a besoin de celle-lÃ  avant)

**Pourquoi c'est utile:**

- **5x plus rapide** â€” Pas besoin de tout rÃ©gÃ©nÃ©rer
- **Plus fiable** â€” On rÃ©utilise ce qui a fait ses preuves
- **Ã‡a s'amÃ©liore** â€” Contrairement Ã  ChatGPT qui reste statique

---

### La phrase qui tue (pour les cocktails)

> "Tu sais comment ChatGPT oublie tout entre chaque conversation? Moi je lui apprends Ã  se souvenir de *comment* faire les choses, pas juste de *quoi* dire."

---

## 1. Ã‰valuation du potentiel scientifique

### 1.1 Contribution principale

**"Emergent Procedural Memory for LLM Agents"**

Les agents LLM actuels rÃ©gÃ©nÃ¨rent du code Ã  chaque exÃ©cution (paradigme RAG = knowledge retrieval).
Notre approche introduit une **mÃ©moire procÃ©durale** qui apprend des **skills** rÃ©utilisables.

> "RAG gave agents knowledge. PML gives them skills."

### 1.2 Innovations techniques (par ordre de nouveautÃ©)

| Innovation | Description | NouveautÃ© |
|------------|-------------|-----------|
| **Eager Learning** | Stockage dÃ¨s la 1Ã¨re exÃ©cution rÃ©ussie, filtrage lazy au moment des suggestions | â­â­â­â­â­ |
| **Combinaison rÃ©cursive** | Tools â†’ CapacitÃ©s â†’ MÃ©ta-capacitÃ©s (modÃ¨le SECI, Nonaka & Takeuchi) | â­â­â­â­â­ |
| **Apprentissage implicite** | Workflows Ã©mergent de l'observation, pas de dÃ©finition explicite (vs n8n/Windmill) | â­â­â­â­â­ |
| **Schema Inference via AST** | InfÃ©rence automatique des paramÃ¨tres JSON Schema via SWC parsing | â­â­â­â­ |
| **Transitive Reliability** | FiabilitÃ© d'une chaÃ®ne de capacitÃ©s = maillon le plus faible | â­â­â­â­ |
| **Capability Composition** | DÃ©tection automatique des relations (contains, dependency, sequence, alternative) | â­â­â­â­ |
| **Hypergraph Scoring** | PageRank/Spectral Clustering avec edges N-aires (capabilityâ†”capability) | â­â­â­ |
| **Adaptive Thresholds** | Seuils de suggestion qui s'adaptent par contexte de workflow (EMA) | â­â­â­ |

### 1.3 Concepts clÃ©s (potentiel scientifique fort)

#### ğŸ”® Combinaison rÃ©cursive (modÃ¨le SECI)

**Origine:** ModÃ¨le SECI de Nonaka & Takeuchi (1995) â€” rÃ©fÃ©rence classique en Knowledge Management.

```
Le modÃ¨le SECI:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Socialisation   â”‚ Externalisation â”‚
â”‚ (tacitâ†’tacit)   â”‚ (tacitâ†’explicit)â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Internalisation â”‚ Combinaison     â”‚ â† C'EST ICI
â”‚ (explicitâ†’tacit)â”‚ (explicitâ†’explicit)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Combinaison** = assembler des connaissances explicites pour en crÃ©er de nouvelles.

**Application Ã  PML:**

```
Niveau 0: Tools (atomiques, explicites)
    â”‚
    â–¼ combinaison
Niveau 1: CapacitÃ©s (combinaisons de tools)
    â”‚
    â–¼ combinaison
Niveau 2: MÃ©ta-capacitÃ©s (combinaisons de capacitÃ©s)
    â”‚
    â–¼ combinaison
Niveau N: ...
```

**Exemple concret:**
```
Tools: filesystem:read, json:parse, memory:store
    â†“ combinaison (aprÃ¨s observation)
CapacitÃ©: "parse-and-cache-config"
    â†“ combinaison (aprÃ¨s observation)
MÃ©ta-capacitÃ©: "setup-environment" (qui inclut parse-and-cache-config + autres)
```

**IntÃ©rÃªt scientifique:**
- S'inscrit dans un cadre thÃ©orique Ã©tabli (SECI, 1995)
- Ã‰mergence hiÃ©rarchique sans design explicite
- RÃ©cursivitÃ©: le mÃªme processus s'applique Ã  chaque niveau
- Potentiel pour l'abstraction automatique de workflows complexes

**LittÃ©rature connexe:**
- Nonaka & Takeuchi (1995) - The Knowledge-Creating Company
- Hierarchical Reinforcement Learning, Option Framework (Sutton)

---

#### ğŸŒŠ Apprentissage implicite vs Workflows explicites

**Concept:** Contrairement aux outils de workflow (n8n, Windmill, Temporal, etc.) oÃ¹ l'utilisateur *dÃ©finit* explicitement les Ã©tapes, PML *observe* ce que l'agent fait et combine Ã§a en capacitÃ©s.

| Aspect | Workflows explicites (n8n, Windmill) | PML (implicite) |
|--------|--------------------------------------|-----------------|
| **DÃ©finition** | L'utilisateur dessine le workflow | L'agent exÃ©cute, PML observe |
| **Connaissance** | Ã€ priori (design-time) | Ã€ posteriori (runtime) |
| **FlexibilitÃ©** | Rigide (suit le schÃ©ma) | Adaptative (apprend les variations) |
| **DÃ©couverte** | Non (tu sais ce que tu veux) | Oui (patterns Ã©mergents) |
| **Maintenance** | Manuelle (update le workflow) | Automatique (stats, success rate) |

**Analogie:**
- **Explicite** = Apprendre Ã  cuisiner avec une recette Ã©tape par Ã©tape
- **Implicite** = Apprendre Ã  cuisiner en regardant un chef et en retenant ses gestes

**IntÃ©rÃªt scientifique:**
- Capture de la connaissance tacite (ce que l'expert fait sans y penser)
- Pas besoin de formaliser Ã  l'avance
- DÃ©couverte de patterns que mÃªme l'utilisateur ne connaissait pas

**LittÃ©rature connexe:** Tacit Knowledge (Polanyi), Learning by Demonstration, Imitation Learning

### 1.4 Positionnement vs Ã©tat de l'art

| Approche | Learning | Composition | Schema Inference | Reliability |
|----------|----------|-------------|------------------|-------------|
| Skill Libraries (CodeBERT, etc.) | âŒ Statique | âŒ | âŒ Manuel | âŒ |
| Code Retrieval (Copilot) | âŒ PrÃ©-entraÃ®nÃ© | âŒ | âŒ | âŒ |
| Tool Discovery (RAG) | âŒ | âŒ | âŒ | âŒ |
| Docker Dynamic MCP | âŒ | âŒ | âŒ | âŒ |
| Anthropic PTC | âŒ | âŒ | âŒ | âŒ |
| **Anthropic Skills** | âŒ Manuel | âŒ | âŒ | âŒ |
| **Casys PML** | âœ… Runtime | âœ… Auto-dÃ©tectÃ©e | âœ… AST | âœ… Transitive |

### 1.5 Clarification terminologique: Skills vs Capabilities

**Note:** Pour Ã©viter toute confusion avec les "Skills" d'Anthropic (qui sont des instructions textuelles), nous utilisons le terme **"Capabilities"** pour dÃ©signer nos patterns de code appris.

| Aspect | Anthropic Skills | Casys PML Capabilities |
|--------|------------------|------------------------|
| **Nature** | Instructions textuelles (prompts) | **Code exÃ©cutable** |
| **Stockage** | Texte/markdown | Code + JSON Schema + stats |
| **Apprentissage** | Manuel (user Ã©crit le skill) | **Automatique** (Ã©mergent de l'exÃ©cution) |
| **ParamÃ¨tres** | Implicites dans le texte | **SchÃ©ma infÃ©rÃ© via AST parsing** |
| **Composition** | Non dÃ©tectÃ©e | **Auto-dÃ©tectÃ©e** (dependency, contains, sequence) |
| **FiabilitÃ©** | Non trackÃ©e | **Success rate + propagation transitive** |
| **ExÃ©cution** | LLM interprÃ¨te â†’ gÃ©nÃ¨re code | **Code direct dans sandbox** |

**Analogie cognitive:**
- **Skills (instructions)** = MÃ©moire sÃ©mantique (savoir quoi faire)
- **Capabilities (code)** = MÃ©moire procÃ©durale (savoir comment faire)

**Exemple concret:**

```
# Anthropic Skill (textuel)
"Pour dÃ©ployer en prod: 1) Lance les tests 2) Build l'image Docker 3) Apply sur K8s"
â†’ Le LLM doit gÃ©nÃ©rer le code Ã  chaque exÃ©cution
â†’ Pas de tracking de succÃ¨s/Ã©chec
â†’ Pas de composition dÃ©tectÃ©e

# Casys Capability (code)
{
  intent: "deploy to production",
  code: "await mcp.jest.run({path: args.testPath}); await mcp.docker.build({...}); ...",
  parametersSchema: { testPath: "string", dockerTag: "string", namespace: "string" },
  successRate: 0.94,
  usageCount: 47,
  dependencies: ["capability:run-tests", "capability:docker-build"]
}
â†’ ExÃ©cution directe (pas de rÃ©gÃ©nÃ©ration)
â†’ FiabilitÃ© trackÃ©e et propagÃ©e
â†’ Composition auto-dÃ©tectÃ©e
```

**Implication pour le papier:** Notre contribution se situe au niveau du **"procedural learning"** â€” l'apprentissage automatique de code exÃ©cutable Ã  partir des exÃ©cutions d'agents. C'est complÃ©mentaire aux approches existantes basÃ©es sur les instructions.

---

## 2. Plan du papier scientifique

### 2.1 Titre proposÃ©

> **"Emergent Capabilities: Learning Executable Patterns from LLM Agent Executions"**

Alternatives:
- "Beyond RAG: Procedural Memory for Tool-Using LLM Agents"
- "From Knowledge to Capabilities: Procedural Learning for AI Agents"

**âš ï¸ Terminologie:** On utilise **"Capabilities"** (pas "Skills") pour se diffÃ©rencier d'Anthropic Skills (qui sont textuels).

### 2.2 Abstract (draft)

> Large Language Model agents repeatedly generate similar code for recurring tasks, wasting compute and context window. We introduce **Procedural Memory Layer (PML)**, a system that automatically learns reusable capabilities from agent executions.
>
> Unlike retrieval-augmented generation (RAG) that retrieves knowledge, PML learns *skills*â€”executable code patterns that can be composed and reused.
>
> Key contributions: (1) **eager learning** with lazy suggestion filtering via adaptive thresholds, (2) **automatic parameter schema inference** through AST parsing, (3) **transitive reliability propagation** through capability dependency graphs.
>
> On a benchmark of N multi-tool workflows, PML achieves X% code reuse rate and Y% latency reduction compared to vanilla execution, while maintaining Z% success rate.

### 2.3 Structure

```
1. INTRODUCTION
   - Problem: LLM agents regenerate code every time
   - Human analogy: Procedural memory (riding a bike)
   - Contribution: First runtime learning system for agent skills

2. RELATED WORK
   2.1 Skill/Program Libraries
   2.2 Code Retrieval & Embeddings
   2.3 Tool Discovery for Agents
   2.4 Knowledge Graphs for Agents

3. APPROACH: PROCEDURAL MEMORY LAYER
   3.1 System Overview (3-layer architecture)

   3.2 Capability Learning
       - Eager storage on first execution
       - Code hashing for deduplication
       - UPSERT with statistics tracking

   3.3 Schema Inference
       - SWC AST parsing
       - Multi-source type inference
       - JSON Schema generation

   3.4 Capability Matching
       - Semantic search (vector embeddings)
       - Reliability scoring
       - Adaptive threshold filtering

   3.5 Composition & Dependencies
       - Edge types and detection
       - Transitive reliability propagation
       - Cycle detection (max depth)

4. EXPERIMENTAL EVALUATION
   4.1 Benchmark Design
   4.2 Baselines
   4.3 Metrics
   4.4 Results
   4.5 Ablation Study

5. DISCUSSION
   - Limitations
   - Generalization beyond exact matches
   - Future: meta-capability learning

6. CONCLUSION
```

### 2.4 ExpÃ©riences Ã  dÃ©velopper

#### Benchmark (Ã  crÃ©er)
- 20-30 tÃ¢ches multi-outils reprÃ©sentatives
- CatÃ©gories: file ops, API calls, data processing, deployments
- Variations: paramÃ¨tres diffÃ©rents, contextes similaires

#### Baselines
1. **Vanilla**: Pas de cache, rÃ©gÃ©nÃ©ration Ã  chaque fois
2. **Simple Cache**: Hash exact de l'intent
3. **RAG Retrieval**: Embedding search sans learning
4. **PML (ours)**: Full system

#### MÃ©triques
| MÃ©trique | Description | Target |
|----------|-------------|--------|
| **Reuse Rate** | % d'exÃ©cutions utilisant une capability existante | > 40% |
| **Latency Reduction** | Temps gagnÃ© vs vanilla | > 50% |
| **Success Rate** | % d'exÃ©cutions rÃ©ussies | > 85% |
| **Context Savings** | Tokens Ã©conomisÃ©s | > 30% |

#### Ablation Study
- Sans eager learning (attendre 3+ patterns)
- Sans schema inference (schema vide)
- Sans transitive reliability
- Sans adaptive thresholds

---

## 3. Venues ciblÃ©es

| Venue | Type | Deadline 2025 | Fit | Notes |
|-------|------|---------------|-----|-------|
| **NeurIPS Workshop LLM Agents** | Workshop | Sept 2025 | â­â­â­â­â­ | IdÃ©al pour premiÃ¨re publication |
| **EMNLP** | ConfÃ©rence | Mai 2025 | â­â­â­â­ | Track agents/tools |
| **NAACL** | ConfÃ©rence | Jan 2025 | â­â­â­ | Si prÃªt rapidement |
| **AAMAS** | ConfÃ©rence | Oct 2025 | â­â­â­â­ | Multi-agent systems |
| **MLSys** | ConfÃ©rence | Nov 2025 | â­â­â­ | Angle systems |
| **ICML Workshop** | Workshop | Mai 2025 | â­â­â­â­ | Si workshop agents existe |

**Recommandation**: Viser **NeurIPS Workshop LLM Agents 2025** comme premiÃ¨re cible.

---

## 4. Article LinkedIn

### 4.1 Terminologie

**âš ï¸ IMPORTANT:** Utiliser **"Capabilities"** ou **"CapacitÃ©s"**, jamais "Skills"
- "Skills" = Anthropic (instructions textuelles)
- "Capabilities" = Casys PML (code exÃ©cutable appris)

### 4.2 Angle & Hook

**ProblÃ¨me relatable:**
> "Vos agents AI rÃ©gÃ©nÃ¨rent le mÃªme code 100 fois par jour. Et si ils apprenaient?"

**Analogie humaine:**
> "Vous n'avez pas besoin de rÃ©apprendre Ã  faire du vÃ©lo chaque matin. Pourquoi vos agents AI devraient-ils?"

**Positionnement (complÃ©mentaire, pas compÃ©titif):**
> "Les Skills gÃ¨rent les instructions. Les Capabilities gÃ¨rent le code appris. Ce sont deux approches complÃ©mentaires."

### 4.3 Structure proposÃ©e (format LinkedIn)

```
ğŸ§  HOOK (2-3 lignes)
Accroche Ã©motionnelle/provocante

ğŸ“Š PROBLÃˆME (3-4 lignes)
Le coÃ»t cachÃ© de la rÃ©gÃ©nÃ©ration de code

ğŸ’¡ INSIGHT (2-3 lignes)
L'analogie avec la mÃ©moire procÃ©durale humaine

ğŸ”§ SOLUTION (4-5 lignes)
PML en 3 points clÃ©s

ğŸ“ˆ RÃ‰SULTATS (2-3 lignes)
Chiffres concrets (speedup, reuse rate)

ğŸ¯ CALL TO ACTION
Invitation Ã  discuter / lien vers article dÃ©taillÃ©

#tags
```

### 4.4 Draft de l'article

---

**ğŸ§  Vos agents AI ont un problÃ¨me de mÃ©moire.**

Pas la mÃ©moire conversationnelle. La mÃ©moire procÃ©durale.

Celle qui fait que vous n'avez pas besoin de rÃ©apprendre Ã  faire du vÃ©lo chaque matin.

---

**ğŸ“Š Le problÃ¨me invisible:**

Chaque fois que votre agent Claude/GPT exÃ©cute une tÃ¢che multi-outils, il rÃ©gÃ©nÃ¨re le code from scratch.

â†’ MÃªme workflow rÃ©pÃ©tÃ© 50 fois = 50 gÃ©nÃ©rations de code
â†’ 30-50% du context window gaspillÃ© en schÃ©mas d'outils
â†’ Latence qui s'accumule (2-5s par Ã©tape)

C'est comme si vous deviez rÃ©apprendre Ã  conduire Ã  chaque trajet.

---

**ğŸ’¡ L'insight:**

Les humains ont 3 types de mÃ©moire:
- **SÃ©mantique** (faits) â†’ C'est ce que fait RAG
- **Ã‰pisodique** (Ã©vÃ©nements) â†’ C'est ce que font les "memory" tools
- **ProcÃ©durale** (savoir-faire) â†’ **Personne ne fait Ã§a pour les agents**

RAG a donnÃ© la connaissance aux agents.
Il est temps de leur donner des **capacitÃ©s**.

---

**ğŸ”§ Ce qu'on construit: Procedural Memory Layer (PML)**

1ï¸âƒ£ **Apprentissage eager**: DÃ¨s qu'un code s'exÃ©cute avec succÃ¨s, il devient une **capacitÃ©** rÃ©utilisable

2ï¸âƒ£ **InfÃ©rence de schÃ©ma automatique**: Le systÃ¨me dÃ©duit les paramÃ¨tres via parsing AST (pas besoin de documentation)

3ï¸âƒ£ **FiabilitÃ© transitive**: Si la capacitÃ© A dÃ©pend de B, et B Ã©choue souvent, A est pÃ©nalisÃ©e

Le rÃ©sultat: Un agent qui **apprend** de ses exÃ©cutions et **rÃ©utilise** ce qui marche.

Chaque Capability = **code exÃ©cutable** + schÃ©ma JSON + stats de succÃ¨s + composition auto-dÃ©tectÃ©e.

---

**ğŸ“ˆ Premiers rÃ©sultats:**

- Context window: 30-50% â†’ **<5%**
- Workflows 5 outils: 8.2s â†’ **1.8s** (5x speedup)
- Et Ã§a s'amÃ©liore avec le temps (contrairement Ã  RAG statique)

---

**ğŸ¯ On prÃ©pare un papier de recherche sur le sujet.**

Curieux d'avoir vos retours:
- Quels use cases vous semblent les plus pertinents?
- Quelles mÃ©triques vous convaincraient?

[Lien vers article technique dÃ©taillÃ©]

---

#AI #LLM #Agents #MachineLearning #ProceduralMemory #MCP #Claude #OpenSource

---

### 4.5 Visuels suggÃ©rÃ©s

1. **SchÃ©ma comparatif**: RAG (knowledge) vs PML (skills)
2. **Diagramme 3-layer**: Orchestration â†’ PML â†’ MCP Servers
3. **Graphe de capabilities**: Visualisation hypergraph avec nodes composÃ©s
4. **Before/After**: Metrics comparison (context, latency)

### 4.6 Timing recommandÃ©

- **Mardi ou Mercredi** matin (meilleur engagement LinkedIn)
- **8h-9h** heure franÃ§aise
- PrÃ©voir rÃ©ponses aux commentaires dans les 2h

---

## 5. Prochaines Ã©tapes

### ImmÃ©diat (cette semaine)
- [ ] Finaliser et poster article LinkedIn
- [ ] CrÃ©er 1-2 visuels pour accompagner

### Court terme (2-4 semaines)
- [ ] Article de blog technique dÃ©taillÃ©
- [ ] DÃ©finir benchmark (liste de tÃ¢ches)
- [ ] ImplÃ©menter baseline "vanilla"

### Moyen terme (2-3 mois)
- [ ] ComplÃ©ter expÃ©riences
- [ ] RÃ©diger papier
- [ ] Soumettre Ã  workshop/confÃ©rence

---

## 6. Questions ouvertes

1. **Benchmark**: Quelles tÃ¢ches inclure? (file ops, API, data processing?)
2. **Baselines**: Quels systÃ¨mes existants comparer? (LangChain? AutoGPT?)
3. **MÃ©triques**: Qu'est-ce qui convaincrait les reviewers?
4. **Angle LinkedIn**: Plus technique ou plus "business value"?

---

*Document vivant - Ã  mettre Ã  jour au fur et Ã  mesure*
