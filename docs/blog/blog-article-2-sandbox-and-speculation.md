# Code Sandboxing et exÃ©cution spÃ©culative : Repenser la sÃ©curitÃ© des agents MCP

**Auteur:** AgentCards Team
**Date:** Janvier 2025
**Sujets:** Code Execution, Security, Predictive Intelligence, MCP Architecture

---

## Repenser le paradigme : Au-delÃ  des appels d'outils

Dans le [premier article](./blog-article-1-gateway-and-dag.md) de cette sÃ©rie, nous avons explorÃ© comment les **Semantic Gateways** et l'**exÃ©cution parallÃ¨le basÃ©e sur les DAGs** rÃ©solvent les problÃ¨mes de contexte et de latence dans les workflows MCP. Mais ces optimisations, aussi puissantes soient-elles, restent dans le paradigme du "tool call" : l'agent demande, le serveur exÃ©cute, les rÃ©sultats retournent dans le contexte.

Dans cet article, nous explorons deux concepts qui sortent de ce paradigme :

1. **Agent Code Sandboxing** â€” ExÃ©cuter du code gÃ©nÃ©rÃ© par l'agent dans un environnement isolÃ©, dÃ©plaÃ§ant la computation hors du protocole
2. **Speculative Execution** â€” PrÃ©dire et prÃ©-exÃ©cuter les workflows avant mÃªme que l'agent ne les demande

Ces deux concepts transforment la gateway d'un simple routeur en un **systÃ¨me d'orchestration intelligent** capable d'anticiper les besoins et d'isoler les calculs lourds.

---

## Concept 3 : Agent Code Sandboxing

### Le problÃ¨me cachÃ© des rÃ©sultats intermÃ©diaires

Le paradigme MCP est fondamentalement basÃ© sur les **appels d'outils** : l'agent demande, le serveur exÃ©cute, le rÃ©sultat retourne dans le contexte. Simple et Ã©lÃ©gant.

Mais il y a une inefficacitÃ© cachÃ©e : **les rÃ©sultats intermÃ©diaires gonflent le contexte**.

```
Exemple concret :
RequÃªte : "Lister les fichiers configs et filtrer les .json"

Approche par tool calls :
1. Agent : "Liste les fichiers dans /configs"
   â†’ MCP retourne : ["app.json", "db.json", ..., "config-687.json"]
   â†’ RÃ©sultat : 2,400 tokens dans le contexte

2. Agent : "Maintenant filtre pour garder seulement les .json"
   â†’ Agent doit traiter les 2,400 tokens
   â†’ Ou faire un autre appel d'outil avec des filtres spÃ©cifiques

Approche par code execution :
1. Agent gÃ©nÃ¨re du TypeScript :
   const files = await listDirectory("/configs");
   const jsonFiles = files.filter(f => f.endsWith(".json"));
   return jsonFiles;

2. Gateway exÃ©cute dans un sandbox Deno
   â†’ Retourne : ["app.json", "db.json", "auth.json"]
   â†’ RÃ©sultat : 80 tokens

RÃ©duction de contexte : 30x
```

La diffÃ©rence clÃ© : **la computation se fait localement**. Seul le rÃ©sultat final entre dans le contexte.

### Quand le sandboxing l'emporte-t-il sur les tool calls ?

Le sandboxing n'est pas toujours la meilleure solution. Voici une matrice de dÃ©cision :

**âœ… Le sandbox gagne :**
- **Datasets volumineux** : 1MB+ de donnÃ©es brutes â†’ filtrer/agrÃ©ger vers <1KB de rÃ©sumÃ©
- **Transformations multi-Ã©tapes** : 5+ opÃ©rations sur les mÃªmes donnÃ©es
- **Logique de filtrage complexe** : Conditions qui nÃ©cessiteraient multiples tool calls
- **DonnÃ©es sensibles** : Traiter localement, retourner seulement des agrÃ©gats (prÃ©servation de la vie privÃ©e)
- **Algorithmes itÃ©ratifs** : Boucles, rÃ©cursion, traitement stateful

**âŒ Les tool calls gagnent :**
- **OpÃ©rations simples** : Lire un fichier, appeler une API
- **APIs externes** : GitHub, Slack, bases de donnÃ©es (ne peuvent pas s'exÃ©cuter dans le sandbox)
- **OpÃ©rations stateful** : Transactions de base de donnÃ©es, Ã©critures de fichiers avec verrous
- **RequÃªtes ponctuelles** : Pas de traitement rÃ©pÃ©tÃ©

Exemple chiffrÃ© :

```
ScÃ©nario 1 : Lire un fichier
Tool call : 1 round-trip, 1,200 tokens
Sandbox : 1 round-trip + overhead d'exÃ©cution, 1,200 tokens
Gagnant : Tool call (plus simple, pas d'overhead)

ScÃ©nario 2 : Lire 50 fichiers, extraire les numÃ©ros de version, agrÃ©ger
Tool calls : 51 round-trips (50 lectures + 1 agrÃ©gation), 75,000 tokens
Sandbox : 1 round-trip, 500 tokens (juste la liste des versions)
Gagnant : Sandbox (50x moins de tokens, 1 round-trip vs 51)

ScÃ©nario 3 : CrÃ©er une issue GitHub
Tool call : 1 round-trip, fonctionne
Sandbox : Ne peut pas accÃ©der Ã  l'API GitHub (pas dans le sandbox)
Gagnant : Tool call (seule option)
```

### Le dÃ©fi de la sÃ©curitÃ©

Pourquoi ne pas juste utiliser `eval()` de JavaScript ?

```typescript
// âŒ EXTRÃŠMEMENT DANGEREUX
const agentCode = await llm.generateCode();
eval(agentCode);

// Le code de l'agent peut :
// - AccÃ©der Ã  tous les fichiers (lire /etc/passwd, ~/.ssh/id_rsa)
// - Faire des requÃªtes rÃ©seau (exfiltrer des donnÃ©es)
// - ExÃ©cuter des commandes shell (rm -rf /)
// - Crasher le processus (process.exit(1))
```

Nous avons besoin d'isolation. Mais combien, et Ã  quel coÃ»t ?

**Options d'isolation :**

| Approche | SÃ©curitÃ© | Latence dÃ©marrage | Overhead runtime | ComplexitÃ© |
|----------|----------|-------------------|------------------|------------|
| **VM** (Firecracker) | â˜…â˜…â˜…â˜…â˜… Excellente | âš ï¸ 1-2 secondes | â˜…â˜…â˜…â˜… Faible | âš ï¸ Ã‰levÃ©e |
| **Container** (Docker) | â˜…â˜…â˜…â˜… TrÃ¨s bonne | âš ï¸ 100-500ms | â˜…â˜…â˜…â˜… Faible | âš ï¸ Ã‰levÃ©e |
| **WASM** (Wasmer) | â˜…â˜…â˜…â˜… TrÃ¨s bonne | â˜…â˜…â˜…â˜…â˜… <10ms | â˜…â˜…â˜…â˜…â˜… Nulle | â˜…â˜…â˜… Moyenne |
| **Deno sandbox** | â˜…â˜…â˜…â˜… TrÃ¨s bonne | â˜…â˜…â˜…â˜…â˜… <10ms | â˜…â˜…â˜…â˜…â˜… Nulle | â˜…â˜… Faible |
| Node.js vm2 | âš ï¸ Faible (vecteurs d'Ã©vasion) | â˜…â˜…â˜…â˜…â˜… <1ms | â˜…â˜…â˜…â˜…â˜… Nulle | â˜…â˜… Faible |

**Pourquoi Deno ?**

Deno offre une **sÃ©curitÃ© basÃ©e sur les capacitÃ©s** avec des permissions granulaires. Au lieu d'un modÃ¨le "tout ou rien", Deno permet de spÃ©cifier exactement ce qu'un script peut faire :

```typescript
// Subprocess Deno avec permissions explicites
const sandbox = Deno.run({
  cmd: ["deno", "run",
    "--allow-read=/configs",      // Peut SEULEMENT lire /configs
    "--allow-write=/tmp/output",  // Peut SEULEMENT Ã©crire dans /tmp/output
    // PAS de --allow-net (rÃ©seau complÃ¨tement bloquÃ©)
    // PAS de --allow-run (ne peut pas spawner de sous-processus)
    // PAS de --allow-env (ne peut pas lire les variables d'environnement)
    "agent_code.ts"
  ]
});
```

Cela nous donne :
- **ContrÃ´le granulaire** : Par rÃ©pertoire, par domaine, par capacitÃ©
- **Deny-by-default** : Tout est interdit sauf ce qui est explicitement autorisÃ©
- **Application runtime** : Pas juste de l'isolation de processus, mais des restrictions de capacitÃ©s au niveau OS
- **DÃ©marrage rapide** : <10ms d'overhead vs 100-500ms pour les containers
- **TypeScript natif** : Pas d'Ã©tape de compilation, le code de l'agent s'exÃ©cute directement

### Architecture du sandbox Deno

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ARCHITECTURE DU SANDBOX DENO                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Code gÃ©nÃ©rÃ© par l'agent                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ const files = await listDirectory("/configs");              â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ const configs = await Promise.all(                          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚   files.map(f => readFile(f).then(JSON.parse))              â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ );                                                           â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ return configs.map(c => ({ name: c.name, version: c.ver }));â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚ Injection de wrappers clients MCP           â”‚
â”‚                           â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Wrappers d'outils MCP injectÃ©s (auto-gÃ©nÃ©rÃ©s)                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ async function listDirectory(path) {                        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚   return await __MCP_CALL__("filesystem:list", { path });   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ }                                                            â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ async function readFile(path) {                             â”‚  â”‚ â”‚
â”‚  â”‚  â”‚   return await __MCP_CALL__("filesystem:read", { path });   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ }                                                            â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚ ExÃ©cution dans subprocess Deno              â”‚
â”‚                           â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Subprocess Deno (isolÃ©)                                          â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  Permissions :                                                    â”‚ â”‚
â”‚  â”‚  âœ… --allow-read=/configs      (seulement rÃ©pertoire /configs)   â”‚ â”‚
â”‚  â”‚  âœ… --allow-net=localhost:9000 (seulement gateway MCP proxy)     â”‚ â”‚
â”‚  â”‚  âŒ PAS de --allow-write        (ne peut pas Ã©crire de fichiers) â”‚ â”‚
â”‚  â”‚  âŒ PAS de --allow-run          (ne peut pas spawner de processus)â”‚ â”‚
â”‚  â”‚  âŒ PAS de --allow-env          (ne peut pas lire les env vars)  â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  Limites :                                                        â”‚ â”‚
â”‚  â”‚  â±ï¸  Timeout : 5 secondes                                        â”‚ â”‚
â”‚  â”‚  ğŸ’¾ MÃ©moire : 100MB max                                          â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚ __MCP_CALL__ proxie vers la gateway         â”‚
â”‚                           â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Gateway MCP Proxy (localhost:9000)                               â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  TransfÃ¨re les appels vers les vrais serveurs MCP                â”‚ â”‚
â”‚  â”‚  La gateway a les permissions complÃ¨tes filesystem                â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                             â”‚
â”‚                           â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Couche de dÃ©tection PII                                          â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  Scanne les rÃ©sultats pour :                                      â”‚ â”‚
â”‚  â”‚  â€¢ Adresses email    (patterns regex)                             â”‚ â”‚
â”‚  â”‚  â€¢ ClÃ©s API          (analyse d'entropie)                         â”‚ â”‚
â”‚  â”‚  â”‚  Cartes de crÃ©dit (algorithme de Luhn)                        â”‚ â”‚
â”‚  â”‚  â€¢ SSN, tÃ©lÃ©phones   (pattern matching)                           â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  TrouvÃ© : 2 adresses email â†’ [REDACTED]                           â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                             â”‚
â”‚                           â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  RÃ©sultat final (sÃ»r pour le contexte LLM)                        â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  [{                                                               â”‚ â”‚
â”‚  â”‚    name: "app-config",                                            â”‚ â”‚
â”‚  â”‚    version: "2.1.0"                                               â”‚ â”‚
â”‚  â”‚  }, {                                                             â”‚ â”‚
â”‚  â”‚    name: "db-config",                                             â”‚ â”‚
â”‚  â”‚    version: "1.5.3"                                               â”‚ â”‚
â”‚  â”‚  }]                                                               â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  Utilisation contexte : ~120 tokens (vs. 15,000+ pour les fichiers bruts) â”‚
â”‚  â”‚  ğŸ¯ RÃ©duction de 125x                                             â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FrontiÃ¨res de sÃ©curitÃ© :
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Code agent     â”‚  Subprocess isolÃ©, permissions minimales
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Proxy MCP      â”‚  ContrÃ´le l'accÃ¨s aux outils MCP
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DÃ©tection PII  â”‚  EmpÃªche les fuites de donnÃ©es sensibles
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Contexte LLM   â”‚  ReÃ§oit seulement des rÃ©sumÃ©s sanitizÃ©s
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### IntÃ©gration MCP : Injection d'outils dans le sandbox

Le sandbox est isolÃ© du processus de la gateway. Mais le code de l'agent a besoin d'accÃ©der aux outils MCP. Comment rÃ©soudre ce paradoxe ?

**Solution : Client MCP auto-gÃ©nÃ©rÃ©**

Avant d'exÃ©cuter le code de l'agent, la gateway injecte des stubs clients qui proxient les appels vers les serveurs MCP :

```typescript
// Ã‰tape 1 : GÃ©nÃ©rer le code client MCP
const mcpClientCode = `
// Wrappers d'outils MCP auto-gÃ©nÃ©rÃ©s
async function readFile(path: string): Promise<string> {
  const response = await fetch("http://localhost:9000/call", {
    method: "POST",
    body: JSON.stringify({
      tool: "filesystem:read_file",
      arguments: { path }
    })
  });
  return await response.json();
}

async function parseJSON(input: string): Promise<any> {
  const response = await fetch("http://localhost:9000/call", {
    method: "POST",
    body: JSON.stringify({
      tool: "json:parse",
      arguments: { input }
    })
  });
  return await response.json();
}

// ... un wrapper par outil pertinent
`;

// Ã‰tape 2 : PrÃ©fixer au code utilisateur
const fullCode = mcpClientCode + "\n\n" + agentCode;

// Ã‰tape 3 : ExÃ©cuter avec permission rÃ©seau vers localhost uniquement
await sandbox.execute({
  code: fullCode,
  permissions: {
    net: ["localhost:9000"]  // Peut seulement parler Ã  la gateway
  }
});
```

**Optimisation : Injection sÃ©mantique d'outils**

Ne pas injecter les 687 outils â€” cela irait Ã  l'encontre de l'objectif du sandboxing. Utiliser la recherche vectorielle pour identifier quels outils le code aura probablement besoin :

```typescript
async function injectRelevantTools(agentCode: string): string {
  // Analyse sÃ©mantique : quels outils ce code a-t-il besoin ?
  const codeEmbedding = await embedder.embed(agentCode);

  const relevantTools = await vectorSearch.searchTools(
    codeEmbedding,
    limit = 20,      // Au maximum 20 outils
    threshold = 0.7  // Confiance Ã©levÃ©e seulement
  );

  // GÃ©nÃ©rer des wrappers seulement pour les outils pertinents
  const clientCode = generateMCPClient(relevantTools);

  return clientCode + "\n\n" + agentCode;
}
```

### La couche de dÃ©tection PII

Avant de retourner les rÃ©sultats du sandbox au contexte LLM, scanner pour des donnÃ©es sensibles :

```typescript
class PIIDetector {
  private patterns = [
    { name: "email", regex: /\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}\b/gi },
    { name: "ssn", regex: /\b\d{3}-\d{2}-\d{4}\b/g },
    { name: "credit_card", regex: /\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b/g },
    { name: "api_key", fn: this.detectAPIKey.bind(this) },
  ];

  scan(text: string): PIIFinding[] {
    // DÃ©tecte tous les patterns PII
  }

  redact(text: string, findings: PIIFinding[]): string {
    // Remplace par [REDACTED_EMAIL], [REDACTED_API_KEY], etc.
  }

  private detectAPIKey(text: string): PIIFinding[] {
    // DÃ©tection de chaÃ®nes Ã  haute entropie (probablement des clÃ©s API)
    const words = text.split(/\s+/);
    return words
      .filter(word => word.length > 20 && this.calculateEntropy(word) > 4.5)
      .map(word => ({ type: "api_key", value: word }));
  }
}
```

Cette couche agit comme un **firewall de donnÃ©es** entre le sandbox et le contexte LLM, empÃªchant les fuites accidentelles de donnÃ©es sensibles.

---

## Concept 4 : ExÃ©cution spÃ©culative

### L'idÃ©e centrale : Travailler pendant que l'agent "pense"

L'exÃ©cution DAG permet la parallÃ©lisation, mais il y a toujours de la latence : l'agent doit **construire le DAG** avant que l'exÃ©cution ne commence. Et si on pouvait commencer Ã  exÃ©cuter avant mÃªme que l'agent ne dÃ©cide quoi faire ?

C'est l'**exÃ©cution spÃ©culative** â€” utiliser le graphe de dÃ©pendances et l'analyse d'intention pour prÃ©dire et prÃ©-exÃ©cuter les appels d'outils.

**Comparaison visuelle :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FLUX TRADITIONNEL (PilotÃ© par l'agent)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Utilisateur : "Lire config.json et crÃ©er une issue GitHub avec version" â”‚
â”‚                                                                         â”‚
â”‚  t=0.0s â”€â”€â”€â”€â–º Agent rÃ©flÃ©chit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [500ms] â”€â”€â”                  â”‚
â”‚               "Je dois d'abord lire le fichier"      â”‚                  â”‚
â”‚                                                      â”‚                  â”‚
â”‚  t=0.5s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â–º ExÃ©cute       â”‚
â”‚                                                           read_file     â”‚
â”‚                                                           [800ms]       â”‚
â”‚                                                              â”‚          â”‚
â”‚  t=1.3s â”€â”€â”€â”€â–º Agent rÃ©flÃ©chit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [200ms] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”       â”‚
â”‚               "Parser JSON pour obtenir version"              â”‚       â”‚
â”‚                                                               â”‚       â”‚
â”‚  t=1.5s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â–º Exec â”‚
â”‚                                                                  parse  â”‚
â”‚                                                                  [600ms]â”‚
â”‚                                                                     â”‚   â”‚
â”‚  t=2.1s â”€â”€â”€â”€â–º Agent rÃ©flÃ©chit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [150ms] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”â”‚
â”‚               "CrÃ©er l'issue GitHub maintenant"                       â”‚â”‚
â”‚                                                                       â”‚â”‚
â”‚  t=2.25s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â–º
â”‚                                                                  create â”‚
â”‚                                                                  [1.2s] â”‚
â”‚                                                                    â”‚    â”‚
â”‚  t=3.45s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                            TERMINÃ‰                      â”‚
â”‚                                                                         â”‚
â”‚  Temps total : 3.45s                                                   â”‚
â”‚  - RÃ©flexion agent : 850ms (25%)                                       â”‚
â”‚  - ExÃ©cution outils : 2,600ms (75%)                                    â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FLUX SPÃ‰CULATIF (PilotÃ© par la prÃ©diction)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Utilisateur : "Lire config.json et crÃ©er une issue GitHub avec version" â”‚
â”‚                                                                         â”‚
â”‚  t=0.0s â”€â”€â”€â”€â–º Gateway prÃ©dit le DAG â”€â–º [100ms] â”€â”€â”                     â”‚
â”‚               Confiance : 0.89 (Ã©levÃ©e)            â”‚                     â”‚
â”‚               DAG : read â†’ parse â†’ create          â”‚                     â”‚
â”‚                                                   â”‚                     â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚               â”‚  L'EXÃ‰CUTION SPÃ‰CULATIVE DÃ‰MARRE                       â”‚
â”‚               â”‚  (pendant que l'agent rÃ©flÃ©chit)                       â”‚
â”‚               â–¼                                                        â”‚
â”‚  t=0.1s â”€â”€â”€â”€â–º ExÃ©cute read_file â”€â”€â”€â”€â”€â–º [800ms] â”€â”€â”                    â”‚
â”‚               (mis en cache pour plus tard)        â”‚                    â”‚
â”‚                                                    â”‚                    â”‚
â”‚               â”Œâ”€ Agent rÃ©flÃ©chit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”‚
â”‚               â”‚  [500ms en arriÃ¨re-plan]           â”‚                    â”‚
â”‚               â”‚  "Je dois lire le fichier..."      â”‚                    â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                    â”‚                    â”‚
â”‚  t=0.5s â”€â”€â”€â”€â”€â–º Agent : "Lis le fichier s'il te plaÃ®t" â”‚                â”‚
â”‚                Gateway : "DÃ©jÃ  fait ! âœ“"           â”‚                    â”‚
â”‚                Retourne rÃ©sultat cachÃ© â”€â”€â”€â”€â”€â”€â”€â”€â–º[0ms - instantanÃ©]      â”‚
â”‚                                                                         â”‚
â”‚  t=0.9s â”€â”€â”€â”€â”€â–º ExÃ©cute json:parse â”€â”€â”€â”€â”€â”€â–º [200ms] â”€â”€â”                 â”‚
â”‚                (spÃ©culatif, sur donnÃ©es cachÃ©es)     â”‚                 â”‚
â”‚                                                      â”‚                 â”‚
â”‚                â”Œâ”€ Agent rÃ©flÃ©chit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                 â”‚
â”‚                â”‚  [100ms en arriÃ¨re-plan]             â”‚                 â”‚
â”‚                â”‚  "Parser pour obtenir version..."    â”‚                 â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                      â”‚                 â”‚
â”‚  t=1.0s â”€â”€â”€â”€â”€â–º Agent : "Parse s'il te plaÃ®t"        â”‚                 â”‚
â”‚                Gateway : "DÃ©jÃ  fait ! âœ“"             â”‚                 â”‚
â”‚                Retourne rÃ©sultat cachÃ© â”€â”€â”€â”€â”€â”€â”€â”€â–º[0ms - instantanÃ©]      â”‚
â”‚                                                                         â”‚
â”‚  t=1.1s â”€â”€â”€â”€â”€â–º Agent : "CrÃ©er l'issue"                                â”‚
â”‚                ExÃ©cute github:create_issue â”€â”€â–º [400ms]                 â”‚
â”‚                (PAS spÃ©culatif - a des effets de bord)   â”‚             â”‚
â”‚                                                           â”‚             â”‚
â”‚  t=1.5s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                            TERMINÃ‰                      â”‚
â”‚                                                                         â”‚
â”‚  Temps total : 1.5s                                                    â”‚
â”‚  - Overhead spÃ©culatif : 100ms (prÃ©diction DAG)                        â”‚
â”‚  - Computation gaspillÃ©e : 0ms (toutes les prÃ©dictions correctes)      â”‚
â”‚  - Temps Ã©conomisÃ© : 1.95s (rÃ©duction de 56%)                          â”‚
â”‚                                                                         â”‚
â”‚  ğŸ¯ RÃ©sultat : L'agent reÃ§oit des rÃ©ponses instantanÃ©es pour les Ã©tapes prÃ©dites â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Comment Ã§a fonctionne : Le moteur de prÃ©diction

L'exÃ©cution spÃ©culative repose sur trois composants :

1. **GraphRAG** : La base de connaissances qui stocke les patterns de workflows historiques
2. **DAG Suggester** : Le systÃ¨me d'intelligence qui prÃ©dit quel DAG construire basÃ© sur l'intention
3. **Speculative Executor** : Le moteur qui dÃ©cide d'exÃ©cuter ou non le DAG prÃ©dit

**Calcul de confiance :**

```typescript
class SpeculativeExecutor {
  async processIntent(intent: string): Promise<ExecutionMode> {
    // Ã‰tape 1 : Utiliser GraphRAG pour prÃ©dire le workflow probable
    const predictedDAG = await this.dagSuggester.suggestWorkflow(intent);

    // Ã‰tape 2 : Calculer le score de confiance
    const confidence = this.calculateConfidence(predictedDAG, intent);

    // Ã‰tape 3 : DÃ©cider de la stratÃ©gie d'exÃ©cution basÃ©e sur la confiance
    if (confidence > 0.85) {
      // Haute confiance â†’ ExÃ©cuter spÃ©culativement
      const results = await this.dagExecutor.execute(predictedDAG);
      return { mode: "speculative", results, confidence };
    } else if (confidence > 0.65) {
      // Confiance moyenne â†’ SuggÃ©rer le DAG, laisser l'agent dÃ©cider
      return { mode: "suggestion", dagStructure: predictedDAG, confidence };
    } else {
      // Faible confiance â†’ RequÃ©rir un workflow explicite
      return { mode: "explicit_required", confidence };
    }
  }

  private calculateConfidence(dag: DAGStructure, intent: string): number {
    // Facteurs affectant la confiance :
    // 1. SimilaritÃ© sÃ©mantique entre intention et outils prÃ©dits
    // 2. PrÃ©cision historique (intentions similaires ont-elles menÃ© Ã  ce DAG avant ?)
    // 3. ComplexitÃ© du DAG (DAGs plus simples = confiance plus Ã©levÃ©e)
    // 4. AmbiguÃ¯tÃ© des dÃ©pendances (dÃ©pendances claires = confiance plus Ã©levÃ©e)

    let confidence = 0.5; // Base

    // Facteur 1 : Pertinence des outils
    const toolRelevance = this.measureToolRelevance(dag, intent);
    confidence += toolRelevance * 0.3;

    // Facteur 2 : PrÃ©cision historique
    const historicalAccuracy = this.getHistoricalAccuracy(intent);
    confidence += historicalAccuracy * 0.2;

    // Facteur 3 : Bonus de simplicitÃ©
    if (dag.tasks.length <= 5) {
      confidence += 0.1;
    }

    // Facteur 4 : Certitude des dÃ©pendances
    const dependencyCertainty = this.analyzeDependencies(dag);
    confidence += dependencyCertainty * 0.15;

    return Math.min(confidence, 0.99); // PlafonnÃ© Ã  99%
  }
}
```

### Le trade-off risque-rÃ©compense

L'exÃ©cution spÃ©culative est un pari :

âœ… **Quand la prÃ©diction est correcte (>85% confiance) :**
- RÃ©duction massive de latence (5-10x plus rapide)
- Meilleure expÃ©rience utilisateur (rÃ©ponses instantanÃ©es)
- Utilisation plus efficace du temps d'inactivitÃ© (exÃ©cuter pendant que l'agent rÃ©flÃ©chit)

âŒ **Quand la prÃ©diction est incorrecte (<85% confiance) :**
- Computation gaspillÃ©e (exÃ©cutÃ© des outils inutiles)
- Effets de bord potentiels (si les outils ne sont pas idempotents)
- Pollution du contexte (mauvais rÃ©sultats dans le cache)

**MÃ©canismes de sÃ©curitÃ© :**

```typescript
class SpeculativeExecutor {
  // ExÃ©cuter seulement les outils idempotents spÃ©culativement
  private readonly SAFE_TOOLS = [
    "filesystem:read_file",      // âœ… Lecture seule
    "filesystem:list_directory", // âœ… Lecture seule
    "json:parse",                // âœ… Fonction pure
    "yaml:load",                 // âœ… Fonction pure
    "github:get_issue",          // âœ… API lecture seule
  ];

  private readonly UNSAFE_TOOLS = [
    "filesystem:write_file",     // âŒ Effets de bord
    "github:create_issue",       // âŒ CrÃ©e des ressources
    "database:execute",          // âŒ Mute l'Ã©tat
    "slack:send_message",        // âŒ Actions externes
  ];

  canExecuteSpeculatively(task: Task): boolean {
    if (this.UNSAFE_TOOLS.includes(task.tool)) {
      return false;
    }

    // Outil inconnu â†’ vÃ©rifier s'il semble sÃ»r
    if (!this.SAFE_TOOLS.includes(task.tool)) {
      if (task.tool.includes("create") || task.tool.includes("delete")) {
        return false;
      }
    }

    return true;
  }
}
```

### Branches safe-to-fail : Le mariage parfait avec la spÃ©culation

Les **tÃ¢ches sandbox** sont idempotentes et isolÃ©es â€” elles peuvent Ã©chouer ou Ãªtre jetÃ©es sans consÃ©quences. Cela dÃ©bloque une **spÃ©culation aggressive** :

```typescript
// âœ… SÃ›R : ExÃ©cution spÃ©culative avec branches sandbox

Intention utilisateur : "Analyser les commits et rÃ©sumer les tendances"
Gateway prÃ©dit (confiance : 0.78) :
  1. fetch_commits (appel MCP)
  2. analyze_fast (sandbox) â† SÃ»r de spÃ©culer
  3. analyze_ml (sandbox) â† SÃ»r de spÃ©culer
  4. analyze_stats (sandbox) â† SÃ»r de spÃ©culer

Gateway exÃ©cute spÃ©culativement TOUTES les approches en parallÃ¨le :
â†’ Si prÃ©dictions fausses : Jeter les rÃ©sultats (pas d'effets de bord)
â†’ Si prÃ©dictions correctes : L'agent obtient une analyse multi-perspective instantanÃ©e
â†’ SuccÃ¨s partiel : Garder ce qui a marchÃ©, ignorer les Ã©checs

RÃ©sultat : SpÃ©culation aggressive avec zÃ©ro risque
```

**DÃ©gradation gracieuse :**

```typescript
// ExÃ©cution spÃ©culative avec fallbacks intÃ©grÃ©s

ScÃ©nario : "Analyse rapide nÃ©cessaire, mais complÃ¨te si le temps le permet"

Gateway exÃ©cute spÃ©culativement :
  t=0ms:  Lance analyse rapide (timeout : 300ms)
  t=0ms:  Lance analyse ML (timeout : 2000ms)
  t=0ms:  Lance analyse complÃ¨te (pas de timeout)

RÃ©sultats possibles :
  â€¢ Toutes rÃ©ussissent â†’ Retourner rÃ©sultats complets
  â€¢ ML timeout â†’ Utiliser rapide + complÃ¨te (gain partiel)
  â€¢ Seulement rapide rÃ©ussit â†’ Retourner analyse basique (dÃ©gradÃ© mais fonctionnel)

L'agent obtient : Meilleurs rÃ©sultats disponibles dans les contraintes de temps
Pas de rollback nÃ©cessaire : Les branches Ã©chouÃ©es sont juste ignorÃ©es
```

---

## Architecture unifiÃ©e : Tout ensemble

Ces quatre concepts ne sont pas mutuellement exclusifs â€” ce sont des couches complÃ©mentaires d'optimisation qui travaillent ensemble :

**1. Semantic Gateway** : RÃ©duit le contexte de 15x en exposant uniquement les outils pertinents
**2. DAG Execution** : AccÃ©lÃ¨re les workflows de 4-6x via la parallÃ©lisation
**3. Speculative Execution** : Ã‰limine le temps de "rÃ©flexion" de l'agent pour 5-10x d'amÃ©lioration d'expÃ©rience
**4. Code Sandboxing** : RÃ©duit le contexte de 100x+ pour les workloads lourds en donnÃ©es

**Performance combinÃ©e (benchmark rÃ©el) :**

```
ScÃ©nario : Traiter 50 fichiers JSON de config (total 2.1MB)
          Extraire les numÃ©ros de version
          CrÃ©er une issue GitHub avec rÃ©sumÃ©

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Approche            â”‚ Contexte     â”‚ Temps total â”‚ SuccÃ¨s   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ MCP sÃ©quentiel      â”‚ 187K tokens  â”‚ 42.3s       â”‚ âŒ Ã‰chec â”‚
â”‚ (baseline)          â”‚ (>100% limit)â”‚             â”‚ (context)â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Gateway seulement   â”‚ 4.2K tokens  â”‚ 42.3s       â”‚ âœ… OK    â”‚
â”‚ (recherche sÃ©mantique)â”‚             â”‚             â”‚ (lent)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Gateway + DAG       â”‚ 4.2K tokens  â”‚ 8.7s        â”‚ âœ… OK    â”‚
â”‚ (lectures parallÃ¨les)â”‚             â”‚             â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Gateway + Sandbox   â”‚ 1.8K tokens  â”‚ 2.1s        â”‚ âœ… OK    â”‚
â”‚ (traitement local)  â”‚              â”‚             â”‚ (optimal)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AmÃ©lioration par rapport au baseline :
- Contexte : RÃ©duction de 104x (187K â†’ 1.8K)
- Vitesse : 20x plus rapide (42.3s â†’ 2.1s)
```

L'insight clÃ© : **ces optimisations se combinent multiplicativement, pas additivement**.

---

## Implications pour l'Ã©cosystÃ¨me MCP

### Est-ce une nouvelle couche de protocole ?

Le pattern gateway est du **middleware**, pas un remplacement de protocole :

- âœ… Se positionne entre les LLMs et les serveurs MCP (comme nginx entre clients et backends)
- âœ… Compatible avec n'importe quel serveur MCP existant (zÃ©ro changement de code requis)
- âœ… Fournit l'optimisation sans changer le protocole MCP
- âœ… Peut Ãªtre adoptÃ© incrÃ©mentalement (commencer avec 1 serveur, en ajouter plus)

**Analogie : Proxies HTTP**

Tout comme nginx fournit du caching, du load balancing, et de la terminaison SSL sans changer HTTP, les gateways MCP fournissent de l'optimisation de contexte, de l'orchestration, et du sandboxing sans changer MCP.

Le protocole reste simple. La complexitÃ© vit Ã  un seul endroit (la gateway). Les serveurs restent stateless et focalisÃ©s.

### Ces concepts devraient-ils faire partie de la spec MCP ?

**Notre position :**

> "Ces concepts devraient rester dans la couche application (gateways, frameworks) pour l'instant. S'ils s'avÃ¨rent prÃ©cieux Ã  travers de multiples implÃ©mentations, les futures versions de MCP pourraient standardiser les interfaces. Mais une standardisation prÃ©maturÃ©e Ã©toufferait l'innovation."

Le protocole MCP est jeune. Laissons mille fleurs fleurir. Standardisons les patterns qui se rÃ©vÃ¨lent universellement utiles.

### Questions ouvertes pour la communautÃ©

1. **DÃ©couverte de gateway** : Comment les clients MCP devraient-ils savoir qu'une gateway existe vs. des serveurs directs ?
2. **SÃ©mantiques de cache** : MCP devrait-il avoir des headers cache-control de style HTTP ?
3. **Streaming de rÃ©sultats partiels** : L'exÃ©cution DAG peut-elle streamer les rÃ©sultats au fur et Ã  mesure que les couches se terminent ?
4. **FrontiÃ¨res de sÃ©curitÃ©** : Qui est responsable du sandboxing ?
5. **Gestion des erreurs dans les DAGs** : Que se passe-t-il quand une tÃ¢che Ã©choue en milieu de workflow ?
6. **ObservabilitÃ©** : Comment dÃ©bugger les comportements complexes de gateway ?

Nous n'avons pas toutes les rÃ©ponses. Ce sont des domaines pour l'expÃ©rimentation communautaire et l'Ã©ventuelle standardisation.

---

## Prior Art et inspirations

Ces concepts architecturaux n'ont pas Ã©mergÃ© dans le vide. AgentCards s'appuie sur le travail pionnier de la communautÃ© des agents IA et MCP :

**LLMCompiler** : A introduit l'idÃ©e de traiter les workflows d'agents comme des graphes de computation avec appels de fonction parallÃ¨les

**AIRIS** : Un des premiers gateways MCP Ã  tenter l'optimisation de contexte et la consolidation multi-serveurs

**Article d'Anthropic sur l'exÃ©cution de code** : A dÃ©montrÃ© comment l'exÃ©cution de code rÃ©sout les problÃ¨mes rÃ©els d'agents (rÃ©duction de contexte de 98.7%, prÃ©servation de la vie privÃ©e)

**Notre contribution est la synthÃ¨se** : Combiner semantic gateways + exÃ©cution DAG + prÃ©diction spÃ©culative + sandboxing de code dans une **couche d'optimisation MCP unifiÃ©e** qui fonctionne avec n'importe quel serveur MCP existant.

C'est l'intÃ©gration qui crÃ©e de la valeur â€” chaque concept amplifie les autres.

---

## Conclusion

Le Model Context Protocol permet la composabilitÃ©. Des centaines de serveurs MCP peuvent maintenant connecter les agents IA au monde.

Mais la composabilitÃ© sans optimisation mÃ¨ne Ã  la saturation du contexte, des goulots d'Ã©tranglement sÃ©quentiels, et du ballonnement des donnÃ©es intermÃ©diaires. Ã€ 15+ serveurs MCP, le modÃ¨le de connexion directe s'effondre.

Dans cette sÃ©rie de deux articles, nous avons explorÃ© quatre concepts architecturaux pour adresser ces limitations :

1. **Semantic Gateway Pattern** â€” RÃ©duction de contexte de 15x
2. **DAG-Based Parallel Execution** â€” RÃ©duction de latence de 4-6x
3. **Speculative Execution** â€” ExpÃ©rience utilisateur 5-10x plus rapide
4. **Agent Code Sandboxing** â€” RÃ©duction de contexte de 100x+ pour les workloads lourds

Ces concepts transforment la gateway d'un simple routeur en un **systÃ¨me d'orchestration intelligent** qui :
- Travaille en avance sur l'agent (spÃ©culatif)
- Essaye multiples approches (rÃ©silient)
- OpÃ¨re dans des environnements isolÃ©s (sÃ»r)
- Retourne seulement les rÃ©sultats essentiels (contexte-efficace)
- DÃ©grade gracieusement en cas d'Ã©chec (robuste)

### La vision

Imaginez un futur oÃ¹ :
- Une seule configuration MCP contient 50+ serveurs sans saturation de contexte
- Les workflows multi-outils s'exÃ©cutent en latence sub-seconde via parallÃ©lisation et prÃ©diction intelligentes
- Les rÃ©sultats apparaissent instantanÃ©ment quand les agents prÃ©disent correctement (90%+ de prÃ©cision avec apprentissage historique)
- Les agents traitent des datasets de plusieurs gigaoctets localement, retournant seulement des insights au contexte
- Tout cela fonctionne avec les serveurs MCP existants, aucun changement de code requis

C'est ce que ces concepts permettent.

### Essayez par vous-mÃªme

AgentCards implÃ©mente ces quatre concepts en open-source. Rejoignez-nous pour construire la couche d'optimisation qui rend les workflows d'agents Ã  grande Ã©chelle pratiques.

---

**Ã€ propos d'AgentCards** : AgentCards est une exploration open-source de patterns architecturaux avancÃ©s pour les agents MCP. Le code complet et les benchmarks sont disponibles sur GitHub.

**Questions ou feedback ?** Nous serions ravis d'entendre vos retours sur ces concepts. Ces patterns devraient-ils faire partie du protocole MCP lui-mÃªme ? Contactez-nous sur notre dÃ©pÃ´t GitHub.
