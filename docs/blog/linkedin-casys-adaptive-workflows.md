# MCP Gateway Architecture (Part 2): Adaptive Workflows with AIL/HIL

**Author:** Erwan Lee Pesle
**Date:** November 2025
**Series:** MCP Gateway Architecture

---

*In [Part 1](https://www.linkedin.com/pulse/mcp-gateway-architecture-part-1-semantic-discovery-erwan-lee-pesle-kiczf/), we saw how semantic discovery and parallel execution solve MCP scalability issues. Today, we tackle a more fundamental problem: workflow rigidity in the face of unexpected discoveries.*

---

## The Problem: Inefficient Ad-Hoc Adaptation

LLM agents already adapt naturallyâ€”but they do it **inefficiently**.

Here's the problem: **adaptation happens reactively, turn-by-turn**.

**Concrete example:**

```
Task: "Analyze configuration files"

Typical LLM agent behavior:
Turn 1: List files â†’ Discovers JSON, XML, YAML
Turn 2: Decides to parse JSON â†’ Processes 8 files
Turn 3: Realizes XML exists â†’ Processes 5 files
Turn 4: Discovers YAML â†’ Processes 2 files

âŒ Problems:
- 4 decision rounds (latency overhead)
- Sequential execution (no parallelization)
- Reactive discovery (tools found one-by-one)
- No learning (repeats this every time)
```

**What if we could make this adaptation proactive and efficient?**

---

## Agent-in-the-Loop (AIL): Formalizing Adaptation

The concept: **make ad-hoc adaptation observable and controllable**.

LLMs already adapt naturally, but it happens in a black box. AIL formalizes this process through structured decision points and command injection.

### How the formalization works

Instead of invisible reasoning, adaptation becomes explicit:

**Traditional LLM (invisible):**
```
Agent thinks: "I need XML parsers" â†’ next turn uses them
(no visibility, no control, no logging)
```

**AIL formalized (observable):**
```
Agent executes: list_directory("/config")
  â†“ Result: 8 JSON, 5 XML, 2 YAML

ğŸ“¡ Event emitted: {type: "discovery", formats: ["json", "xml", "yaml"]}

Agent decision point activated:
  â†“ Query GraphRAG: "tools for XML/YAML parsing"

ğŸ“¡ Event emitted: {type: "replanning", tools: ["xml.parse", "yaml.load"]}

Agent injects: {type: "replan_dag", tools: ["xml.parse", "yaml.load"]}

DAG Executor rebuilds:
  Layer 0: list_directory [COMPLETED]
  Layer 1: [parse_json, parse_xml, parse_yaml] â† Dynamically added
  Layer 2: aggregate_results

ğŸ“¡ Event emitted: {type: "dag_updated", new_nodes: 2}
```

**Key insight:** This doesn't enable new capabilitiesâ€”it **structures and exposes** what LLMs already do, enabling observability, control, and learning.

---

## Human-in-the-Loop (HIL): Validation for Critical Operations

Sometimes, total autonomy is not desirable. For sensitive operations, you want **human validation**.

### When to use HIL

- Destructive operations (file deletion, Git commits)
- Critical business decisions (expense approval)
- Security workflows (production deployments)
- Quality validation (generated code review)

### How it works

The workflow can **stop at a checkpoint** and request validation:

```
Workflow reaches HIL checkpoint
  â†“ Generates a summary:
  "Ready to deploy 47 modified files to production.
   Changes: 342 lines added, 89 deleted.
   Tests: 156/156 passed."

  â†“ Awaits human validation

Human responds:
  - âœ… Approve â†’ Workflow continues
  - âŒ Reject â†’ Workflow stops
  - ğŸ”§ Modify â†’ Injects modification commands â†’ Continues
```

**Modification example:**
```json
{
  "decision": "modify",
  "commands": [
    { "type": "exclude_files", "pattern": "*.test.ts" },
    { "type": "add_review_comment", "text": "Deploying core files only" }
  ]
}
```

The workflow integrates these modifications and continues.

---

## 3-Loop Learning Architecture

The real power emerges when combining **three learning loops** operating at different time scales:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ğŸ”„ 3-LOOP LEARNING ARCHITECTURE                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                       â•‘
â•‘  âš¡ Loop 1: EXECUTION (real-time - milliseconds)
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â•‘  â”‚  ğŸ“¡ Event Stream        â†’ Complete observability                â”‚
â•‘  â”‚  ğŸ›ï¸  Command Queue       â†’ Dynamic control                      â”‚
â•‘  â”‚  ğŸ’¾ State Management    â†’ Automatic reducers                    â”‚
â•‘  â”‚  ğŸ’¿ Checkpoint/Resume   â†’ Interruption safe                     â”‚
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â•‘                            â†“ feed into â†“
â•‘  ğŸ§  Loop 2: ADAPTATION (runtime - seconds)
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â•‘  â”‚  ğŸ¤– AIL: Agent decides  â†’ Autonomous replanning                 â”‚
â•‘  â”‚  ğŸ‘¤ HIL: Human validates â†’ Critical approval                    â”‚
â•‘  â”‚  ğŸ”€ DAG Replanning      â†’ Dynamic modification                  â”‚
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â•‘                            â†“ feedback to â†“
â•‘  ğŸ“ Loop 3: META-LEARNING (continuous - long-term)
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â•‘  â”‚  ğŸ•¸ï¸  GraphRAG Updates   â†’ Knowledge enrichment                  â”‚
â•‘  â”‚  ğŸ”— Co-occurrence       â†’ Pattern learning                      â”‚
â•‘  â”‚  ğŸ“ˆ Self-improvement    â†’ Each exec improves the next           â”‚
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Loop 1: Real-Time Observability and Control

**Event Stream:** Every workflow step emits events (`workflow_start`, `task_complete`, `checkpoint`, `error`). Complete real-time observability.

**Command Queue:** The agent (or human) can inject commands **during** execution: `{type: "replan_dag"}`, `{type: "abort"}`, `{type: "pause"}`. Non-blocking, processed between DAG layers.

**State Management:** Automatic reducers (inspired by LangGraph MessagesState) maintain state: messages, tasks, decisions, context. Automatic append/merge.

**Checkpoint/Resume:** The workflow can be interrupted and resumed. State is saved, allowing crash survival or asynchronous HIL validation.

### Loop 2: Adaptive Decisions During Execution

**Agent-in-the-Loop (AIL):** The agent can replan dynamically. XML file discovery â†’ Agent injects `{replan_dag: "parse XML"}` â†’ GraphRAG query â†’ New nodes added to DAG â†’ Execution continues.

**Human-in-the-Loop (HIL):** Human validation for critical operations. Checkpoint â†’ Summary generated â†’ Human review (Approve/Reject/Modify) â†’ Commands injected â†’ Workflow continues.

**DAG Replanning:** Unlike fixed DAGs, Casys rebuilds the DAG **during execution** via GraphRAG queries. Preserves completed tasks, adds new branches in parallel.

### Loop 3: Continuous Learning

**GraphRAG Updates:** After each workflow, the system enriches the knowledge graph.

Example: If `list_directory` and `parse_xml` are used together, the knowledge graph strengthens this relationship (weight +1). PageRank is recalculated. Future similar workflows benefit from learned patterns.

**Co-occurrence Learning:** The system learns which tools go together.

After 50 workflows on configuration files:
- `parse_json` co-occurs 95% with `list_directory`
- `parse_xml` co-occurs 60%
- `parse_yaml` co-occurs 30%

Result: The 51st similar workflow **automatically suggests all 3 parsers** from the start.

---

## Use Case: Configuration File Analysis

Let's compare LLM ad-hoc adaptation vs Casys structured approach on a real scenario.

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“‚ SCENARIO: "Analyze config files"                                 â•‘
â•‘  Unexpected discovery: 8 JSON + 5 XML + 2 YAML                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                       â•‘
â•‘  ğŸ”„ LLM AD-HOC APPROACH       â”‚  âœ… CASYS STRUCTURED APPROACH         â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â•‘
â•‘                                 â”‚                                     â•‘
â•‘  Turn 1: list_directory        â”‚  ğŸ“¡ Vector Search (upfront):        â•‘
â•‘    â†“ Discovers: 8 JSON files   â”‚    â†’ Identifies all parsers needed  â•‘
â•‘    â†“ Decides: parse JSON       â”‚    â†’ list_directory (0.94)          â•‘
â•‘                                 â”‚    â†’ parse_json (0.89)              â•‘
â•‘  Turn 2: parse_json (8 files)  â”‚    â†’ parse_xml (0.87)               â•‘
â•‘    â†“ Sequential execution      â”‚    â†’ parse_yaml (0.85)              â•‘
â•‘    â†“ Notices: XML files exist  â”‚                                     â•‘
â•‘                                 â”‚  ğŸ”€ DAG Generated:                  â•‘
â•‘  Turn 3: parse_xml (5 files)   â”‚    Layer 0: list_directory          â•‘
â•‘    â†“ Sequential execution      â”‚    Layer 1: [json, xml, yaml] âš¡    â•‘
â•‘    â†“ Notices: YAML files too   â”‚    Layer 2: aggregate               â•‘
â•‘                                 â”‚                                     â•‘
â•‘  Turn 4: parse_yaml (2 files)  â”‚  âš¡ Parallel Execution:             â•‘
â•‘    â†“ Sequential execution      â”‚    â†’ All 3 parsers run together     â•‘
â•‘                                 â”‚    â†’ 4.75x faster than sequential   â•‘
â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•           â”‚                                     â•‘
â•‘  Result: âœ… Complete (eventually)â”‚  ğŸ“ Loop 3: Meta-Learning         â•‘
â•‘  Turns: 4 LLM rounds            â”‚    â†’ Pattern saved to GraphRAG     â•‘
â•‘  Time: 8-12 seconds             â”‚    â†’ Next "config" task: suggests  â•‘
â•‘  Execution: Sequential          â”‚      all 3 parsers immediately     â•‘
â•‘  Memory: Forgets next session   â”‚                                     â•‘
â•‘                                 â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•               â•‘
â•‘                                 â”‚  Result: âœ… Complete                â•‘
â•‘                                 â”‚  Turns: 1 LLM round                 â•‘
â•‘                                 â”‚  Time: 2.1 seconds                  â•‘
â•‘                                 â”‚  Execution: Parallel                â•‘
â•‘                                 â”‚  Memory: Learns for next time       â•‘
â•‘                                 â”‚                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Concrete results:**
- LLM ad-hoc: 4 turns, 8-12s, sequential, no learning
- Casys structured: 1 turn, 2.1s, parallel, learns pattern

**And on the 10th similar workflow:**
- LLM ad-hoc: Still 4 turns, still discovers tools one-by-one
- Casys: GraphRAG learned the pattern â†’ suggests all 3 parsers upfront in workflow #11

---

## Positioning: What Doesn't Exist Elsewhere

### The LLM Adaptation Paradox

**LLMs like Claude already adapt naturally** - but in an inefficient way:

```
Task: "Analyze config files"

Claude's natural approach (ad-hoc adaptation):
  Turn 1: Decides â†’ list_directory("/config")
  Turn 2: Sees JSON/XML/YAML â†’ Decides â†’ parse_json (only)
  Turn 3: Realizes XML exists â†’ Decides â†’ parse_xml
  Turn 4: Discovers YAML too â†’ Decides â†’ parse_yaml

  Result: 4 LLM turns, sequential execution, manual decisions at each step
```

**The problem isn't lack of adaptationâ€”it's inefficiency:**
- âŒ Manual decision-making at each turn (latency overhead)
- âŒ Sequential execution (no parallelization)
- âŒ No memory across sessions (repeats the same discoveries)
- âŒ Black-box process (no observability)

### What Casys Actually Solves

**1. Pre-configured DAG via Vector Search (eliminates decision tours)**

Instead of discovering tools turn-by-turn, Casys identifies all relevant tools upfront:

```
User intent: "Analyze config files"
  â†“ Vector search (from Part 1):
    - filesystem:list_directory (0.94 similarity)
    - json:parse (0.89)
    - xml:parse (0.87)
    - yaml:load (0.85)

  â†“ DAG generated automatically:
    Layer 0: list_directory
    Layer 1: [parse_json, parse_xml, parse_yaml] â† Parallel execution
    Layer 2: aggregate_results

  Result: 1 decision turn â†’ parallel execution
```

**2. Meta-Learning Across Sessions (GraphRAG)**

After 10 "config analysis" workflows, Casys learns the pattern:

```
Workflow #1-10: Discovers JSON+XML+YAML each time
Workflow #11: Automatically suggests all 3 parsers upfront
```

Claude forgets between sessions; Casys remembers.

**3. Formal Observability & Control**

```
Claude (ad-hoc):          Casys (formalized):
"Thinking..."             Event stream: checkpoint_reached
"Adapting plan..."        Command queue: {type: "replan_dag"}
(no visibility)           Observable state + external control
```

### Comparison Matrix

| Capability | Claude Code (LLM) | Anthropic Code Exec | Casys |
|-----------|-------------------|---------------------|-------|
| **Adaptation** | âœ… Ad-hoc (inefficient) | âŒ Fixed code execution | âœ… Pre-configured + adaptive |
| **Tool discovery** | ğŸ”„ Turn-by-turn | âš ï¸ Manual | âœ… Vector search upfront |
| **Execution mode** | â¸ï¸ Sequential | â¸ï¸ Sequential | âš¡ Parallel DAG |
| **Code execution** | âŒ | âœ… Sandbox | âœ… Sandbox + MCP tools |
| **Meta-learning** | âŒ Forgets each session | âŒ | âœ… GraphRAG |
| **Observability** | âŒ Black box | âš ï¸ Basic | âœ… Event stream |
| **Human control (HIL)** | âŒ | âŒ | âœ… Checkpoint validation |

### The Real Innovation

**Casys doesn't enable adaptationâ€”LLMs already do that.**

**Casys makes adaptation efficient:**
- **Proactive** (vector search predicts tools) vs **Reactive** (discover turn-by-turn)
- **Parallel** (DAG layers execute simultaneously) vs **Sequential** (wait for each result)
- **Learning** (patterns improve over time) vs **Amnesic** (restart from scratch)
- **Observable** (event stream + control) vs **Black-box** (hope for the best)

**Example impact:**
- LLM natural approach: 4 turns, 8-12s, sequential
- Casys approach: 1 turn, 2.1s, parallel
- Speedup: 4-6x, with learning for next time

---

## Technical Implementation

### Modular Architecture

Adaptive loops are implemented through several components working together:

**Event Stream:**
- 9 event types (workflow_start, task_complete, checkpoint, error, etc.)
- Real-time emission via observers
- Used for logging, debugging, monitoring

**Command Queue:**
- Non-blocking command queue
- Injection possible during execution (replan_dag, pause, abort, modify)
- Processing between DAG layers

**State Management:**
- Reducers inspired by LangGraph
- Workflow state: messages, tasks, decisions, context
- Automatic update merging

**DAG Replanning:**
- GraphRAG query based on discoveries
- Dynamic construction of new nodes
- Preservation of completed tasks (no re-execution)

### Performance Metrics

Real benchmarks comparing approaches:

**Structured vs ad-hoc replanning:** 5x speedup
- LLM ad-hoc with multiple turns: 23.4s
- Formalized AIL with DAG replanning: 4.7s

**Infrastructure overhead (formalization cost):**
- State update latency: 3ms (target <10ms) âœ…
- Event emission overhead: <5ms P95 âœ…
- Command injection latency: <10ms P95 âœ…

**Key finding:** Formalization overhead is negligible compared to eliminating decision rounds.

---

## Concrete Use Cases

### 1. Multi-Language Codebase Analysis

```
Task: "Analyze this project and identify dependencies"

Initial DAG: Python analysis
  â†“ Discovers: TypeScript, Rust also present

AIL Decision: Adds TS and Rust analyzers
  â†“ New DAG: [Python, TypeScript, Rust] in parallel

Result: Complete analysis in a single execution
```

### 2. CI/CD Pipeline with Human Validation

```
DAG: build â†’ test â†’ deploy

HIL Checkpoint before deploy:
  "156 tests passed, ready to deploy"


Human: Approve

Workflow: Continues to production
```

### 3. Data Pipeline with Format Discovery

```
Task: "Import data from /exports directory"

Initial DAG: CSV import
  â†“ Discovers: CSV, JSON, Parquet

AIL: Adds JSON and Parquet parsers
  â†“ All formats processed automatically

Loop 3: Next time, suggests all 3 parsers upfront
```

---

## Conclusion: Three Architectural Concepts

This article introduced three complementary concepts for making LLM agent workflows more efficient:

### Loop 1: Execution Infrastructure
**Concept:** Make workflow state observable and controllable.
- Event streams for real-time visibility
- Command queues for external control
- State reducers for automatic merging
- Checkpoint/resume for fault tolerance

**Value:** Black-box reasoning becomes transparent and debuggable.

### Loop 2: Formalized Adaptation
**Concept:** Structure what LLMs do naturally.
- **AIL:** Agent replanning through explicit decision points
- **HIL:** Human validation at critical checkpoints
- **DAG replanning:** Dynamic workflow modification with preserved state

**Value:** Ad-hoc adaptation becomes efficient, observable, and controllable.

### Loop 3: Meta-Learning
**Concept:** Learn patterns across workflow executions.
- GraphRAG enrichment from tool co-occurrence
- Pattern recognition for proactive suggestions
- Continuous improvement without manual tuning

**Value:** Amnesic workflows become self-improving systems.

---

## The Core Insight

**LLMs already adaptâ€”they're just inefficient at it.**

The architectural contribution isn't enabling adaptation, but **making it:**
- âš¡ **Proactive** (vector search predicts needs)
- ğŸ”€ **Parallel** (DAG execution eliminates sequential waits)
- ğŸ§  **Learning** (GraphRAG remembers patterns)
- ğŸ‘ï¸ **Observable** (event streams expose reasoning)

**Impact:** 4-6x speedup on multi-tool workflows, with continuous improvement over time.

---

**This series:**
- **Part 1:** [Semantic Discovery and Parallel Execution](https://www.linkedin.com/pulse/mcp-gateway-architecture-part-1-semantic-discovery-erwan-lee-pesle-kiczf/) - Vector search + DAG execution
- **Part 2:** Adaptive Workflows with AIL/HIL (this article) - Formalized adaptation + meta-learning
- **Part 3:** Code Sandboxing + MCP Tools Injection (coming soon) - Local execution + context reduction

**These concepts** are explored in the Casys MCP Gateway project, demonstrating how to structure and optimize LLM agent workflows at scale.
