# Code Sandboxing and Speculative Execution: Rethinking Agent Security for MCP

**Author:** AgentCards Team
**Date:** January 2025
**Topics:** Code Execution, Security, Predictive Intelligence, MCP Architecture

---

## Rethinking the Paradigm: Beyond Tool Calls

In the [first article](./blog-article-1-gateway-and-dag-en.md) of this series, we explored how **Semantic Gateways** and **DAG-based parallel execution** solve the context and latency problems in MCP workflows. But these optimizations, as powerful as they are, remain within the "tool call" paradigm: the agent asks, the server executes, results return to context.

In this article, we explore two concepts that break free from this paradigm:

1. **Agent Code Sandboxing** â€” Execute agent-generated code in an isolated environment, moving computation out of the protocol
2. **Speculative Execution** â€” Predict and pre-execute workflows before the agent even requests them

These two concepts transform the gateway from a simple router into an **intelligent orchestration system** capable of anticipating needs and isolating heavy computations.

---

## Concept 3: Agent Code Sandboxing

### The Hidden Problem of Intermediate Results

The MCP paradigm is fundamentally based on **tool calls**: the agent asks, the server executes, the result returns to context. Simple and elegant.

But there's a hidden inefficiency: **intermediate results bloat the context**.

```
Concrete example:
Request: "List config files and filter for .json"

Tool call approach:
1. Agent: "List files in /configs"
   â†’ MCP returns: ["app.json", "db.json", ..., "config-687.json"]
   â†’ Result: 2,400 tokens in context

2. Agent: "Now filter to keep only .json"
   â†’ Agent must process the 2,400 tokens
   â†’ Or make another tool call with specific filters

Code execution approach:
1. Agent generates TypeScript:
   const files = await listDirectory("/configs");
   const jsonFiles = files.filter(f => f.endsWith(".json"));
   return jsonFiles;

2. Gateway executes in Deno sandbox
   â†’ Returns: ["app.json", "db.json", "auth.json"]
   â†’ Result: 80 tokens

Context reduction: 30x
```

The key difference: **computation happens locally**. Only the final result enters the context.

### When Does Sandboxing Win Over Tool Calls?

Sandboxing isn't always the best solution. Here's a decision matrix:

**âœ… Sandbox wins:**
- **Large datasets**: 1MB+ raw data â†’ filter/aggregate to <1KB summary
- **Multi-step transformations**: 5+ operations on the same data
- **Complex filtering logic**: Conditions that would require multiple tool calls
- **Sensitive data**: Process locally, return only aggregates (privacy preservation)
- **Iterative algorithms**: Loops, recursion, stateful processing

**âŒ Tool calls win:**
- **Simple operations**: Read a file, call an API
- **External APIs**: GitHub, Slack, databases (cannot run in sandbox)
- **Stateful operations**: Database transactions, file writes with locks
- **One-off queries**: No repeated processing

Quantified example:

```
Scenario 1: Read a file
Tool call: 1 round-trip, 1,200 tokens
Sandbox: 1 round-trip + execution overhead, 1,200 tokens
Winner: Tool call (simpler, no overhead)

Scenario 2: Read 50 files, extract version numbers, aggregate
Tool calls: 51 round-trips (50 reads + 1 aggregation), 75,000 tokens
Sandbox: 1 round-trip, 500 tokens (just the version list)
Winner: Sandbox (50x fewer tokens, 1 round-trip vs 51)

Scenario 3: Create a GitHub issue
Tool call: 1 round-trip, works
Sandbox: Cannot access GitHub API (not in sandbox)
Winner: Tool call (only option)
```

### The Security Challenge

Why not just use JavaScript's `eval()`?

```typescript
// âŒ EXTREMELY DANGEROUS
const agentCode = await llm.generateCode();
eval(agentCode);

// Agent code can:
// - Access all files (read /etc/passwd, ~/.ssh/id_rsa)
// - Make network requests (exfiltrate data)
// - Execute shell commands (rm -rf /)
// - Crash the process (process.exit(1))
```

We need isolation. But how much, and at what cost?

**Isolation options:**

| Approach | Security | Startup latency | Runtime overhead | Complexity |
|----------|----------|-----------------|------------------|------------|
| **VM** (Firecracker) | â˜…â˜…â˜…â˜…â˜… Excellent | âš ï¸ 1-2 seconds | â˜…â˜…â˜…â˜… Low | âš ï¸ High |
| **Container** (Docker) | â˜…â˜…â˜…â˜… Very good | âš ï¸ 100-500ms | â˜…â˜…â˜…â˜… Low | âš ï¸ High |
| **WASM** (Wasmer) | â˜…â˜…â˜…â˜… Very good | â˜…â˜…â˜…â˜…â˜… <10ms | â˜…â˜…â˜…â˜…â˜… None | â˜…â˜…â˜… Medium |
| **Deno sandbox** | â˜…â˜…â˜…â˜… Very good | â˜…â˜…â˜…â˜…â˜… <10ms | â˜…â˜…â˜…â˜…â˜… None | â˜…â˜… Low |
| Node.js vm2 | âš ï¸ Low (escape vectors) | â˜…â˜…â˜…â˜…â˜… <1ms | â˜…â˜…â˜…â˜…â˜… None | â˜…â˜… Low |

**Why Deno?**

Deno offers **capability-based security** with granular permissions. Instead of an "all or nothing" model, Deno allows you to specify exactly what a script can do:

```typescript
// Deno subprocess with explicit permissions
const sandbox = Deno.run({
  cmd: ["deno", "run",
    "--allow-read=/configs",      // Can ONLY read /configs
    "--allow-write=/tmp/output",  // Can ONLY write to /tmp/output
    // NO --allow-net (network completely blocked)
    // NO --allow-run (cannot spawn subprocesses)
    // NO --allow-env (cannot read environment variables)
    "agent_code.ts"
  ]
});
```

This gives us:
- **Granular control**: Per-directory, per-domain, per-capability
- **Deny-by-default**: Everything is forbidden except what's explicitly allowed
- **Runtime enforcement**: Not just process isolation, but OS-level capability restrictions
- **Fast startup**: <10ms overhead vs 100-500ms for containers
- **Native TypeScript**: No compilation step, agent code runs directly

### Deno Sandbox Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DENO SANDBOX ARCHITECTURE                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Agent-generated code                                             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ const files = await listDirectory("/configs");              â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ const configs = await Promise.all(                          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚   files.map(f => readFile(f).then(JSON.parse))              â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ );                                                           â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ return configs.map(c => ({ name: c.name, version: c.ver }));â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚ Inject MCP client wrappers                  â”‚
â”‚                           â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Injected MCP tool wrappers (auto-generated)                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ async function listDirectory(path) {                        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚   return await __MCP_CALL__("filesystem:list", { path });   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ }                                                            â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ async function readFile(path) {                             â”‚  â”‚ â”‚
â”‚  â”‚  â”‚   return await __MCP_CALL__("filesystem:read", { path });   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ }                                                            â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚ Execute in Deno subprocess                  â”‚
â”‚                           â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Deno subprocess (isolated)                                       â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  Permissions:                                                     â”‚ â”‚
â”‚  â”‚  âœ… --allow-read=/configs      (only /configs directory)         â”‚ â”‚
â”‚  â”‚  âœ… --allow-net=localhost:9000 (only MCP gateway proxy)          â”‚ â”‚
â”‚  â”‚  âŒ NO --allow-write            (cannot write files)             â”‚ â”‚
â”‚  â”‚  âŒ NO --allow-run              (cannot spawn processes)         â”‚ â”‚
â”‚  â”‚  âŒ NO --allow-env              (cannot read env vars)           â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  Limits:                                                          â”‚ â”‚
â”‚  â”‚  â±ï¸  Timeout: 5 seconds                                          â”‚ â”‚
â”‚  â”‚  ğŸ’¾ Memory: 100MB max                                            â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚ __MCP_CALL__ proxies to gateway             â”‚
â”‚                           â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  MCP Gateway Proxy (localhost:9000)                               â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  Forwards calls to real MCP servers                              â”‚ â”‚
â”‚  â”‚  Gateway has full filesystem permissions                         â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                             â”‚
â”‚                           â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  PII detection layer                                              â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  Scans results for:                                               â”‚ â”‚
â”‚  â”‚  â€¢ Email addresses   (regex patterns)                             â”‚ â”‚
â”‚  â”‚  â€¢ API keys          (entropy analysis)                           â”‚ â”‚
â”‚  â”‚  â€¢ Credit cards      (Luhn algorithm)                             â”‚ â”‚
â”‚  â”‚  â€¢ SSN, phones       (pattern matching)                           â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  Found: 2 email addresses â†’ [REDACTED]                            â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                             â”‚
â”‚                           â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Final result (safe for LLM context)                              â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  [{                                                               â”‚ â”‚
â”‚  â”‚    name: "app-config",                                            â”‚ â”‚
â”‚  â”‚    version: "2.1.0"                                               â”‚ â”‚
â”‚  â”‚  }, {                                                             â”‚ â”‚
â”‚  â”‚    name: "db-config",                                             â”‚ â”‚
â”‚  â”‚    version: "1.5.3"                                               â”‚ â”‚
â”‚  â”‚  }]                                                               â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â”‚  Context usage: ~120 tokens (vs. 15,000+ for raw files)          â”‚ â”‚
â”‚  â”‚  ğŸ¯ 125x reduction                                                â”‚ â”‚
â”‚  â”‚                                                                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Security boundaries:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent code     â”‚  Isolated subprocess, minimal permissions
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ MCP proxy      â”‚  Controls access to MCP tools
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PII detection  â”‚  Prevents sensitive data leaks
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LLM context    â”‚  Receives only sanitized summaries
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MCP Integration: Injecting Tools into the Sandbox

The sandbox is isolated from the gateway process. But the agent's code needs access to MCP tools. How do we resolve this paradox?

**Solution: Auto-generated MCP client**

Before executing agent code, the gateway injects client stubs that proxy calls to MCP servers:

```typescript
// Step 1: Generate MCP client code
const mcpClientCode = `
// Auto-generated MCP tool wrappers
async function readFile(path: string): Promise<string> {
  const response = await fetch("http://localhost:9000/call", {
    method: "POST",
    body: JSON.stringify({
      tool: "filesystem:read_file",
      arguments: { path }
    })
  });
  return await response.json();
}

async function parseJSON(input: string): Promise<any> {
  const response = await fetch("http://localhost:9000/call", {
    method: "POST",
    body: JSON.stringify({
      tool: "json:parse",
      arguments: { input }
    })
  });
  return await response.json();
}

// ... one wrapper per relevant tool
`;

// Step 2: Prepend to user code
const fullCode = mcpClientCode + "\n\n" + agentCode;

// Step 3: Execute with network permission to localhost only
await sandbox.execute({
  code: fullCode,
  permissions: {
    net: ["localhost:9000"]  // Can only talk to gateway
  }
});
```

**Optimization: Semantic tool injection**

Don't inject all 687 tools â€” that would defeat the purpose of sandboxing. Use vector search to identify which tools the code will likely need:

```typescript
async function injectRelevantTools(agentCode: string): string {
  // Semantic analysis: which tools does this code need?
  const codeEmbedding = await embedder.embed(agentCode);

  const relevantTools = await vectorSearch.searchTools(
    codeEmbedding,
    limit = 20,      // Maximum 20 tools
    threshold = 0.7  // High confidence only
  );

  // Generate wrappers only for relevant tools
  const clientCode = generateMCPClient(relevantTools);

  return clientCode + "\n\n" + agentCode;
}
```

### The PII Detection Layer

Before returning sandbox results to the LLM context, scan for sensitive data:

```typescript
class PIIDetector {
  private patterns = [
    { name: "email", regex: /\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}\b/gi },
    { name: "ssn", regex: /\b\d{3}-\d{2}-\d{4}\b/g },
    { name: "credit_card", regex: /\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b/g },
    { name: "api_key", fn: this.detectAPIKey.bind(this) },
  ];

  scan(text: string): PIIFinding[] {
    // Detect all PII patterns
  }

  redact(text: string, findings: PIIFinding[]): string {
    // Replace with [REDACTED_EMAIL], [REDACTED_API_KEY], etc.
  }

  private detectAPIKey(text: string): PIIFinding[] {
    // Detect high-entropy strings (likely API keys)
    const words = text.split(/\s+/);
    return words
      .filter(word => word.length > 20 && this.calculateEntropy(word) > 4.5)
      .map(word => ({ type: "api_key", value: word }));
  }
}
```

This layer acts as a **data firewall** between the sandbox and the LLM context, preventing accidental leaks of sensitive data.

---

## Concept 4: Speculative Execution

### The Core Idea: Work While the Agent "Thinks"

DAG execution enables parallelization, but there's still latency: the agent must **build the DAG** before execution begins. What if we could start executing before the agent even decides what to do?

This is **speculative execution** â€” using the dependency graph and intent analysis to predict and pre-execute tool calls.

**Visual comparison:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRADITIONAL FLOW (Agent-driven)                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  User: "Read config.json and create a GitHub issue with version"       â”‚
â”‚                                                                         â”‚
â”‚  t=0.0s â”€â”€â”€â”€â–º Agent thinks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [500ms] â”€â”€â”                     â”‚
â”‚               "I need to read the file first"     â”‚                     â”‚
â”‚                                                   â”‚                     â”‚
â”‚  t=0.5s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â–º Execute           â”‚
â”‚                                                       read_file         â”‚
â”‚                                                       [800ms]           â”‚
â”‚                                                          â”‚              â”‚
â”‚  t=1.3s â”€â”€â”€â”€â–º Agent thinks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [200ms] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”          â”‚
â”‚               "Parse JSON to get version"                  â”‚          â”‚
â”‚                                                            â”‚          â”‚
â”‚  t=1.5s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â–º Exec    â”‚
â”‚                                                               parse    â”‚
â”‚                                                               [600ms]  â”‚
â”‚                                                                  â”‚     â”‚
â”‚  t=2.1s â”€â”€â”€â”€â–º Agent thinks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [150ms] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”  â”‚
â”‚               "Create the GitHub issue now"                        â”‚  â”‚
â”‚                                                                    â”‚  â”‚
â”‚  t=2.25s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â–º â”‚
â”‚                                                               create   â”‚
â”‚                                                               [1.2s]   â”‚
â”‚                                                                 â”‚      â”‚
â”‚  t=3.45s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                            DONE                        â”‚
â”‚                                                                         â”‚
â”‚  Total time: 3.45s                                                     â”‚
â”‚  - Agent thinking: 850ms (25%)                                         â”‚
â”‚  - Tool execution: 2,600ms (75%)                                       â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SPECULATIVE FLOW (Prediction-driven)                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  User: "Read config.json and create a GitHub issue with version"       â”‚
â”‚                                                                         â”‚
â”‚  t=0.0s â”€â”€â”€â”€â–º Gateway predicts DAG â”€â–º [100ms] â”€â”€â”                      â”‚
â”‚               Confidence: 0.89 (high)             â”‚                      â”‚
â”‚               DAG: read â†’ parse â†’ create          â”‚                      â”‚
â”‚                                                  â”‚                      â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚               â”‚  SPECULATIVE EXECUTION STARTS                           â”‚
â”‚               â”‚  (while agent thinks)                                   â”‚
â”‚               â–¼                                                         â”‚
â”‚  t=0.1s â”€â”€â”€â”€â–º Execute read_file â”€â”€â”€â”€â”€â–º [800ms] â”€â”€â”                     â”‚
â”‚               (cached for later)                   â”‚                     â”‚
â”‚                                                    â”‚                     â”‚
â”‚               â”Œâ”€ Agent thinks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                     â”‚
â”‚               â”‚  [500ms in background]             â”‚                     â”‚
â”‚               â”‚  "I need to read the file..."      â”‚                     â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                    â”‚                     â”‚
â”‚  t=0.5s â”€â”€â”€â”€â”€â–º Agent: "Read the file please"      â”‚                     â”‚
â”‚                Gateway: "Already done! âœ“"          â”‚                     â”‚
â”‚                Return cached result â”€â”€â”€â”€â”€â”€â”€â”€â–º[0ms - instant]            â”‚
â”‚                                                                         â”‚
â”‚  t=0.9s â”€â”€â”€â”€â”€â–º Execute json:parse â”€â”€â”€â”€â”€â”€â–º [200ms] â”€â”€â”                  â”‚
â”‚                (speculative, on cached data)          â”‚                  â”‚
â”‚                                                       â”‚                  â”‚
â”‚                â”Œâ”€ Agent thinks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
â”‚                â”‚  [100ms in background]               â”‚                  â”‚
â”‚                â”‚  "Parse to get version..."           â”‚                  â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                       â”‚                  â”‚
â”‚  t=1.0s â”€â”€â”€â”€â”€â–º Agent: "Parse please"                 â”‚                  â”‚
â”‚                Gateway: "Already done! âœ“"            â”‚                  â”‚
â”‚                Return cached result â”€â”€â”€â”€â”€â”€â”€â”€â–º[0ms - instant]            â”‚
â”‚                                                                         â”‚
â”‚  t=1.1s â”€â”€â”€â”€â”€â–º Agent: "Create the issue"                               â”‚
â”‚                Execute github:create_issue â”€â”€â–º [400ms]                  â”‚
â”‚                (NOT speculative - has side effects)   â”‚                 â”‚
â”‚                                                       â”‚                 â”‚
â”‚  t=1.5s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                            DONE                         â”‚
â”‚                                                                         â”‚
â”‚  Total time: 1.5s                                                       â”‚
â”‚  - Speculative overhead: 100ms (DAG prediction)                         â”‚
â”‚  - Wasted computation: 0ms (all predictions correct)                    â”‚
â”‚  - Time saved: 1.95s (56% reduction)                                    â”‚
â”‚                                                                         â”‚
â”‚  ğŸ¯ Result: Agent receives instant responses for predicted steps        â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How It Works: The Prediction Engine

Speculative execution relies on three components:

1. **GraphRAG**: The knowledge base that stores historical workflow patterns
2. **DAG Suggester**: The intelligence system that predicts which DAG to build based on intent
3. **Speculative Executor**: The engine that decides whether to execute the predicted DAG

**Confidence calculation:**

```typescript
class SpeculativeExecutor {
  async processIntent(intent: string): Promise<ExecutionMode> {
    // Step 1: Use GraphRAG to predict likely workflow
    const predictedDAG = await this.dagSuggester.suggestWorkflow(intent);

    // Step 2: Calculate confidence score
    const confidence = this.calculateConfidence(predictedDAG, intent);

    // Step 3: Decide execution strategy based on confidence
    if (confidence > 0.85) {
      // High confidence â†’ Execute speculatively
      const results = await this.dagExecutor.execute(predictedDAG);
      return { mode: "speculative", results, confidence };
    } else if (confidence > 0.65) {
      // Medium confidence â†’ Suggest DAG, let agent decide
      return { mode: "suggestion", dagStructure: predictedDAG, confidence };
    } else {
      // Low confidence â†’ Require explicit workflow
      return { mode: "explicit_required", confidence };
    }
  }

  private calculateConfidence(dag: DAGStructure, intent: string): number {
    // Factors affecting confidence:
    // 1. Semantic similarity between intent and predicted tools
    // 2. Historical accuracy (did similar intents lead to this DAG before?)
    // 3. DAG complexity (simpler DAGs = higher confidence)
    // 4. Dependency ambiguity (clear dependencies = higher confidence)

    let confidence = 0.5; // Base

    // Factor 1: Tool relevance
    const toolRelevance = this.measureToolRelevance(dag, intent);
    confidence += toolRelevance * 0.3;

    // Factor 2: Historical accuracy
    const historicalAccuracy = this.getHistoricalAccuracy(intent);
    confidence += historicalAccuracy * 0.2;

    // Factor 3: Simplicity bonus
    if (dag.tasks.length <= 5) {
      confidence += 0.1;
    }

    // Factor 4: Dependency certainty
    const dependencyCertainty = this.analyzeDependencies(dag);
    confidence += dependencyCertainty * 0.15;

    return Math.min(confidence, 0.99); // Capped at 99%
  }
}
```

### The Risk-Reward Tradeoff

Speculative execution is a gamble:

âœ… **When prediction is correct (>85% confidence):**
- Massive latency reduction (5-10x faster)
- Better user experience (instant responses)
- More efficient use of idle time (execute while agent thinks)

âŒ **When prediction is incorrect (<85% confidence):**
- Wasted computation (executed unnecessary tools)
- Potential side effects (if tools are not idempotent)
- Context pollution (wrong results in cache)

**Safety mechanisms:**

```typescript
class SpeculativeExecutor {
  // Only execute idempotent tools speculatively
  private readonly SAFE_TOOLS = [
    "filesystem:read_file",      // âœ… Read-only
    "filesystem:list_directory", // âœ… Read-only
    "json:parse",                // âœ… Pure function
    "yaml:load",                 // âœ… Pure function
    "github:get_issue",          // âœ… Read-only API
  ];

  private readonly UNSAFE_TOOLS = [
    "filesystem:write_file",     // âŒ Side effects
    "github:create_issue",       // âŒ Creates resources
    "database:execute",          // âŒ Mutates state
    "slack:send_message",        // âŒ External actions
  ];

  canExecuteSpeculatively(task: Task): boolean {
    if (this.UNSAFE_TOOLS.includes(task.tool)) {
      return false;
    }

    // Unknown tool â†’ check if it seems safe
    if (!this.SAFE_TOOLS.includes(task.tool)) {
      if (task.tool.includes("create") || task.tool.includes("delete")) {
        return false;
      }
    }

    return true;
  }
}
```

### Safe-to-Fail Branches: The Perfect Marriage with Speculation

**Sandbox tasks** are idempotent and isolated â€” they can fail or be discarded without consequences. This unlocks **aggressive speculation**:

```typescript
// âœ… SAFE: Speculative execution with sandbox branches

User intent: "Analyze commits and summarize trends"
Gateway predicts (confidence: 0.78):
  1. fetch_commits (MCP call)
  2. analyze_fast (sandbox) â† Safe to speculate
  3. analyze_ml (sandbox) â† Safe to speculate
  4. analyze_stats (sandbox) â† Safe to speculate

Gateway speculatively executes ALL approaches in parallel:
â†’ If predictions wrong: Discard results (no side effects)
â†’ If predictions correct: Agent gets instant multi-perspective analysis
â†’ Partial success: Keep what worked, ignore failures

Result: Aggressive speculation with zero risk
```

**Graceful degradation:**

```typescript
// Speculative execution with built-in fallbacks

Scenario: "Fast analysis needed, but thorough if time permits"

Gateway speculatively executes:
  t=0ms:  Launch fast analysis (timeout: 300ms)
  t=0ms:  Launch ML analysis (timeout: 2000ms)
  t=0ms:  Launch full analysis (no timeout)

Possible outcomes:
  â€¢ All succeed â†’ Return comprehensive results
  â€¢ ML timeout â†’ Use fast + full (partial win)
  â€¢ Only fast succeeds â†’ Return basic analysis (degraded but functional)

Agent gets: Best results available within time constraints
No rollback needed: Failed branches are simply ignored
```

---

## Unified Architecture: Everything Together

These four concepts aren't mutually exclusive â€” they're complementary optimization layers that work together:

**1. Semantic Gateway**: Reduces context by 15x by exposing only relevant tools
**2. DAG Execution**: Accelerates workflows by 4-6x via parallelization
**3. Speculative Execution**: Eliminates agent "thinking" time for 5-10x experience improvement
**4. Code Sandboxing**: Reduces context by 100x+ for data-heavy workloads

**Combined performance (real benchmark):**

```
Scenario: Process 50 JSON config files (total 2.1MB)
          Extract version numbers
          Create GitHub issue with summary

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Approach            â”‚ Context      â”‚ Total time  â”‚ Success  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Sequential MCP      â”‚ 187K tokens  â”‚ 42.3s       â”‚ âŒ Fail  â”‚
â”‚ (baseline)          â”‚ (>100% limit)â”‚             â”‚ (context)â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Gateway only        â”‚ 4.2K tokens  â”‚ 42.3s       â”‚ âœ… OK    â”‚
â”‚ (semantic search)   â”‚              â”‚             â”‚ (slow)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Gateway + DAG       â”‚ 4.2K tokens  â”‚ 8.7s        â”‚ âœ… OK    â”‚
â”‚ (parallel reads)    â”‚              â”‚             â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Gateway + Sandbox   â”‚ 1.8K tokens  â”‚ 2.1s        â”‚ âœ… OK    â”‚
â”‚ (local processing)  â”‚              â”‚             â”‚ (optimal)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Improvement over baseline:
- Context: 104x reduction (187K â†’ 1.8K)
- Speed: 20x faster (42.3s â†’ 2.1s)
```

The key insight: **these optimizations combine multiplicatively, not additively**.

---

## Implications for the MCP Ecosystem

### Is This a New Protocol Layer?

The gateway pattern is **middleware**, not a protocol replacement:

- âœ… Sits between LLMs and MCP servers (like nginx between clients and backends)
- âœ… Compatible with any existing MCP server (zero code changes required)
- âœ… Provides optimization without changing the MCP protocol
- âœ… Can be adopted incrementally (start with 1 server, add more)

**Analogy: HTTP Proxies**

Just as nginx provides caching, load balancing, and SSL termination without changing HTTP, MCP gateways provide context optimization, orchestration, and sandboxing without changing MCP.

The protocol remains simple. The complexity lives in one place (the gateway). Servers remain stateless and focused.

### Should These Concepts Be Part of the MCP Spec?

**Our position:**

> "These concepts should remain in the application layer (gateways, frameworks) for now. If they prove valuable across multiple implementations, future versions of MCP could standardize the interfaces. But premature standardization would stifle innovation."

The MCP protocol is young. Let a thousand flowers bloom. Standardize the patterns that prove universally useful.

### Open Questions for the Community

1. **Gateway discovery**: How should MCP clients know a gateway exists vs. direct servers?
2. **Cache semantics**: Should MCP have HTTP-style cache-control headers?
3. **Streaming partial results**: Can DAG execution stream results as layers complete?
4. **Security boundaries**: Who is responsible for sandboxing?
5. **Error handling in DAGs**: What happens when a task fails mid-workflow?
6. **Observability**: How do we debug complex gateway behaviors?

We don't have all the answers. These are areas for community experimentation and eventual standardization.

---

## Prior Art and Inspirations

These architectural concepts didn't emerge in a vacuum. AgentCards builds on pioneering work from the AI agent and MCP community:

**LLMCompiler**: Introduced the idea of treating agent workflows as computation graphs with parallel function calls

**AIRIS**: One of the first MCP gateways to attempt context optimization and multi-server consolidation

**Anthropic's article on code execution**: Demonstrated how code execution solves real agent problems (98.7% context reduction, privacy preservation)

**Our contribution is the synthesis**: Combining semantic gateways + DAG execution + speculative prediction + code sandboxing into a **unified MCP optimization layer** that works with any existing MCP server.

It's the integration that creates value â€” each concept amplifies the others.

---

## Conclusion

The Model Context Protocol enables composability. Hundreds of MCP servers can now connect AI agents to the world.

But composability without optimization leads to context saturation, sequential bottlenecks, and intermediate data bloat. At 15+ MCP servers, the direct-connect model breaks down.

In this two-article series, we've explored four architectural concepts to address these limitations:

1. **Semantic Gateway Pattern** â€” 15x context reduction
2. **DAG-Based Parallel Execution** â€” 4-6x latency reduction
3. **Speculative Execution** â€” 5-10x faster user experience
4. **Agent Code Sandboxing** â€” 100x+ context reduction for heavy workloads

These concepts transform the gateway from a simple router into an **intelligent orchestration system** that:
- Works ahead of the agent (speculative)
- Tries multiple approaches (resilient)
- Operates in isolated environments (safe)
- Returns only essential results (context-efficient)
- Degrades gracefully on failure (robust)

### The Vision

Imagine a future where:
- A single MCP config contains 50+ servers without context saturation
- Multi-tool workflows execute in sub-second latency via intelligent parallelization and prediction
- Results appear instantly when agents predict correctly (90%+ accuracy with historical learning)
- Agents process multi-gigabyte datasets locally, returning only insights to context
- All of this works with existing MCP servers, no code changes required

This is what these concepts enable.

### Try It Yourself

AgentCards implements these four concepts in open source. Join us in building the optimization layer that makes large-scale agent workflows practical.

---

**About AgentCards**: AgentCards is an open-source exploration of advanced architectural patterns for MCP agents. Full code and benchmarks are available on GitHub.

**Questions or feedback?** We'd love to hear your thoughts on these concepts. Should these patterns be part of the MCP protocol itself? Contact us on our GitHub repository.
