# Product Brief: AgentsCards

**Date:** 2025-11-03
**Author:** BMad
**Status:** Draft for PM Review
**Project Name:** AgentsCards

---

## Initial Context

**Origin Story:**
Le projet AgentsCards √©merge d'une triple motivation:
- Frustration personnelle avec Claude Code utilisant de nombreux MCP servers (explosion du contexte)
- Observation que tous les comp√©titeurs actuels (AIRIS, Smithery, Unla) ont rat√© l'opportunit√© du vrai lazy loading
- Inspiration de LLMCompiler pour apporter la parall√©lisation intelligente au monde MCP

**Core Problems Identified:**
1. **Explosion du contexte** - Les MCP servers actuels envoient tous les tools d'un coup, saturant la context window
2. **Lenteur des appels s√©quentiels** - Pas de parall√©lisation = latence cumulative (5 tools = 5x le temps)

**Target Users:**
- D√©veloppeurs utilisant Claude Code avec 10+ MCP servers
- Teams construisant des agents AI complexes n√©cessitant coordination multi-tools

**Input Sources:**
- Session de brainstorming intensive (2025-11-03) avec 50+ concepts g√©n√©r√©s
- Analyse comp√©titive approfondie (AIRIS, Smithery, Unla, LLMCompiler)
- First Principles thinking, Morphological Analysis, SCAMPER method

**Collaboration Mode:** Interactive (section par section)

---

## Executive Summary

**AgentCards** est une gateway MCP intelligente qui r√©sout les deux probl√®mes critiques bloquant l'adoption √† l'√©chelle de l'√©cosyst√®me Model Context Protocol: **l'explosion du contexte** (30-50% de la context window consomm√©e par les tool schemas) et **la latence cumulative** des appels s√©quentiels (5 tools = 5x le temps d'attente).

En appliquant **vector search s√©mantique** pour le chargement on-demand des tools et **DAG execution** pour la parall√©lisation intelligente, AgentCards permet aux d√©veloppeurs d'activer 15+ MCP servers simultan√©ment (vs 7-8 actuellement) tout en r√©duisant le contexte √† <5% et en acc√©l√©rant les workflows multi-tools de 5x. La plateforme se diff√©rencie des solutions existantes (AIRIS, Smithery, Unla) par une architecture **SQLite-first** zero-infrastructure et un **focus DX non-n√©gociable** (NPS >75 target).

**MVP 8 Semaines (Q1 2025):** Context Optimization Engine + DAG Execution + Zero-Config Auto-Discovery, d√©ploy√© local-first via Deno runtime. Target 200-500 power users ultra-satisfaits qui deviendront les √©vang√©listes naturels du produit. Succ√®s mesur√© par **3 KPIs critiques**: NPS >75, Context <5%, Retention 30-jours >70%. Projet open-source avec optionality future pour mon√©tisation (managed service, enterprise features, consulting) si product-market fit valid√©.

---

## Problem Statement

### L'√âcosyst√®me MCP Souffre d'un Probl√®me d'√âchelle Critique

L'√©cosyst√®me Model Context Protocol (MCP) conna√Æt une adoption explosive avec des centaines de servers disponibles. Cependant, les d√©veloppeurs et teams construisant des agents AI complexes se heurtent √† **deux goulots d'√©tranglement majeurs** qui limitent drastiquement l'utilisation r√©elle de MCP:

#### 1. Explosion du Contexte - La "Taxe Invisible" sur Chaque Interaction

**Impact Quantifi√©:**
- **30-50% du contexte LLM** est consomm√© uniquement par les schemas des tools MCP avant m√™me toute interaction utile
- Avec seulement **8 MCP servers** (configuration modeste), les schemas peuvent occuper 60K-100K tokens sur les ~200K disponibles
- Certains MCP servers particuli√®rement riches en fonctionnalit√©s consomment individuellement des dizaines de milliers de tokens

**Cons√©quence Directe:**
- Les d√©veloppeurs n'ont **"plus rien pour leur chat"** - la fen√™tre conversationnelle utile est r√©duite de moiti√©
- Les r√©ponses de Claude sont tronqu√©es ou refus√©es faute d'espace contextuel
- **Auto-limitation forc√©e**: les d√©veloppeurs √©vitent volontairement de tester ou activer certains MCP servers pourtant utiles

**Pourquoi les Solutions Actuelles √âchouent:**
- **AIRIS, Smithery, Unla**: Tous utilisent l'approche "all-at-once" - renvoient TOUS les tools d'un MCP server simultan√©ment
- Aucune solution de lazy loading r√©elle sur le march√©
- AIRIS a promis du lazy loading mais l'impl√©mentation est d√©faillante

#### 2. Latence Cumulative - L'Inefficacit√© des Appels S√©quentiels

**Impact Quotidien:**
- Les workflows multi-tools s'ex√©cutent **s√©quentiellement** sans parall√©lisation
- Pour une t√¢che typique n√©cessitant 5 outils MCP: attente cumulative de 5x la latence unitaire
- **Friction rencontr√©e tr√®s fr√©quemment** - plusieurs fois par session de travail
- Workflows simples (lecture ‚Üí parsing ‚Üí validation ‚Üí √©criture) deviennent p√©niblement lents

**Co√ªt en Productivit√©:**
- Temps d'attente "relou" qui brise le flow de d√©veloppement
- Impossible d'orchestrer efficacement des workflows complexes cross-MCP
- Les agents AI complexes ne peuvent pas coordonner intelligemment de multiples sources de donn√©es

#### 3. Le Co√ªt d'Opportunit√© - Innovation Brid√©e

**Ce Que le Probl√®me Emp√™che:**
- **Impossibilit√© d'utiliser 10+ MCP servers simultan√©ment** (limite pratique actuelle: ~8 servers)
- Les teams doivent **choisir entre MCP A et MCP B** au lieu de les combiner
- Cas d'usage avanc√©s bloqu√©s: coordination cross-domaines (GitHub + Slack + Database + Filesystem + ...)
- L'√©cosyst√®me MCP grandit mais l'utilisation r√©elle stagne

#### 4. Urgence - La Fen√™tre d'Opportunit√© Se Referme

**Pourquoi Maintenant:**
- Anthropic pousse massivement MCP avec Claude Code (adoption en croissance exponentielle)
- Tous les comp√©titeurs ont rat√© cette opportunit√© (solutions bugg√©es ou incompl√®tes)
- Les early adopters expriment la frustration mais continuent d'esp√©rer une solution
- Premier entrant avec une vraie solution de context optimization + parall√©lisation capture le march√©

**Validation du Probl√®me:**
- AIRIS a √©chou√© sur l'ex√©cution malgr√© la bonne vision (config bugs, lazy loading rat√©)
- LLMCompiler a prouv√© la faisabilit√© de la parall√©lisation intelligente (mais limit√© √† Python)
- Aucune solution edge-deployable avec zero-config disponible

Le march√© attend une gateway MCP qui r√©sout **simultan√©ment** l'√©chelle, le contexte et l'orchestration.

---

## Proposed Solution

### AgentCards: Gateway MCP Intelligente avec Context Optimization et Pr√©diction Adaptive

**Vision en Une Phrase:**
AgentCards est une gateway MCP qui charge les tools on-demand via vector search s√©mantique, ex√©cute les workflows en parall√®le via DAG, et apprend √† pr√©dire les outils suivants pour des performances quasi-instantan√©es.

#### Architecture Fond√©e sur 3 Piliers Interconnect√©s

**1. Context Optimization - Fin de l'Explosion du Contexte**

**Approche:**
- **Vector Search S√©mantique:** Recherche intelligente des tools pertinents plut√¥t que chargement massif
- **On-Demand Loading:** Schemas charg√©s uniquement au besoin, tool par tool (granularit√© maximale)
- **SQLite Vector Store:** Embeddings des tools pour d√©couverte s√©mantique ultra-rapide

**R√©sultat Concret:**
- Passage de **30-50% ‚Üí <5% de contexte** consomm√© par les tool schemas
- Support **illimit√© de MCP servers** sans saturation du contexte
- Les d√©veloppeurs r√©cup√®rent 90% de leur fen√™tre conversationnelle

**2. Orchestration Parall√®le - √âlimination de la Latence Cumulative**

**Approche:**
- **DAG Execution:** Construction automatique d'un graphe de d√©pendances entre tools (inspiration LLMCompiler)
- **Parall√©lisation Intelligente:** Ex√©cution simultan√©e des tools ind√©pendants
- **SSE Streaming:** R√©sultats stream√©s d√®s leur disponibilit√© pour feedback progressif

**R√©sultat Concret:**
- Workflows 5-outils passent de **5x latence ‚Üí 1x latence** (5x plus rapide)
- Coordination cross-MCP fluide (GitHub + Slack + Database en parall√®le)
- Flow de d√©veloppement pr√©serv√© (pas de "temps mort relou")

**3. √âchelle Illimit√©e - L'√âcosyst√®me MCP Sans Limites**

**Approche:**
- **Zero-Config Auto-Discovery:** D√©tection automatique des MCP servers disponibles
- **Edge-First Architecture:** D√©ployable sur Deno Deploy / Cloudflare Workers
- **SQLite Everything:** Un seul fichier .db portable (vector store + usage stats + cache)

**R√©sultat Concret:**
- Support de **dizaines, centaines de MCP servers** sans d√©gradation
- D√©ploiement trivial (pas de Redis/Postgres/Qdrant requis)
- Latence ultra-faible gr√¢ce au edge deployment

#### Le "Secret Sauce" - Tool Prediction Adaptive

**Innovation Cl√© qui Diff√©rencie AgentCards:**

AgentCards int√®gre un **syst√®me de pr√©diction des tools** bas√© sur les patterns d'utilisation r√©els:

**Comment √áa Marche:**
- **Usage Stats Learning:** Table SQLite trackant les s√©quences tool_A ‚Üí tool_B avec fr√©quences
- **Speculative Execution:** Lancement anticip√© des tools "probables" en arri√®re-plan
- **Smart Caching:** R√©sultats pr√©-calcul√©s disponibles instantan√©ment si demand√©s
- **Suggestion Engine:** Propositions de tools suivants probables envoy√©es √† Claude

**R√©sultat Magique:**
- **Capacit√©s quasi-instantan√©es** - R√©sultats d√©j√† pr√™ts quand Claude les demande
- **S'am√©liore avec l'usage** - Plus vous utilisez AgentCards, plus il devient rapide
- Exemple: "Apr√®s read_file ‚Üí 80% parse_json" ‚Üí parse_json d√©j√† pr√©-ex√©cut√©

**Impact UX:**
- Pattern "branch prediction" des CPUs modernes appliqu√© aux workflows MCP
- Zero overhead pour l'utilisateur (tout transparent)
- Performance qui s'am√©liore organiquement au fil du temps

#### Pourquoi AgentCards R√©ussira L√† O√π AIRIS a √âchou√©

| Dimension | AIRIS / Smithery / Unla | **AgentCards** |
|-----------|-------------------------|----------------|
| **Lazy Loading** | Promis mais rat√© (all-at-once) | ‚úÖ Vraie impl√©mentation granulaire (per-tool) |
| **Configuration** | Bugs constants, config manuelle | ‚úÖ Zero-config auto-discovery |
| **Parall√©lisation** | Aucune ou partielle | ‚úÖ DAG + Speculative execution |
| **Context Optimization** | Aucune (saturation) | ‚úÖ Vector search + on-demand (<5% contexte) |
| **Performance** | Latence cumulative (5x pour 5 tools) | ‚úÖ Latence constante + pr√©diction (quasi-instant) |
| **D√©ploiement** | Cloud traditionnel, complexe | ‚úÖ Edge-first, un fichier SQLite portable |
| **Intelligence** | Statique | ‚úÖ Adaptive (apprend des patterns d'utilisation) |

#### L'Exp√©rience Utilisateur Transform√©e

**Avant AgentCards (√âtat Actuel):**
- Configuration de 8 MCP servers ‚Üí 50% du contexte consomm√©
- Workflow 5-tools ‚Üí 30 secondes d'attente cumulative
- D√©cision douloureuse: "Je d√©sactive ce MCP server pourtant utile"

**Avec AgentCards:**
1. **Installation:** `npx agentcards` - auto-discovery automatique, zero config
2. **Premier Usage:** 15-20 MCP servers activ√©s, contexte <5%, workflows parall√©lis√©s
3. **Apr√®s Une Semaine:** Tool prediction apprend vos patterns ‚Üí r√©sultats quasi-instantan√©s
4. **Moment "Wow":** "J'ai oubli√© qu'il y avait une latence avant... c'est juste fluide maintenant"

#### Proposition de Valeur Unique

**Pour les D√©veloppeurs Claude Code:**
- Lib√©ration du contexte (90% r√©cup√©r√© pour conversations utiles)
- Performance 5-10x meilleure sur workflows multi-tools
- Acc√®s √† TOUT l'√©cosyst√®me MCP sans compromis

**Pour les Teams Agents AI:**
- Orchestration cross-MCP sophistiqu√©e enfin possible
- Coordination GitHub + Slack + Database + Custom APIs en parall√®le
- Base pour agents AI vraiment multi-domaines

**Pour l'√âcosyst√®me MCP:**
- D√©bloque l'adoption r√©elle (pas juste 2-3 MCP servers par user)
- Prouve que MCP scale (100+ servers support√©s)
- Acc√©l√®re la cr√©ation de nouveaux MCP servers (confiance dans l'infrastructure)

---

## Target Users

### Primary User Segment

**Persona: "Alex - Le Power User AI-Native Developer"**

**Profil D√©mographique:**
- **R√¥le:** Full-stack Developer / AI Engineer / Tech Lead dans startup/scale-up tech
- **Exp√©rience:** Senior (5-10 ans), early adopter de technologies AI
- **Contexte:** Remote/hybrid, side projects ambitieux, actif sur tech Twitter/Discord
- **Tech Stack:** TypeScript/Python, Claude Code comme IDE principal, 10-20+ MCP servers configur√©s

**Comportement Quotidien avec Claude Code:**
- **Usage Intensif:** 8-10 heures par jour dans Claude Code
- **Workflows Lourds:** Playwright pour testing, Serena pour code analysis, filesystem/git/database intensivement
- **Sessions Longues:** Conversations de 50-100+ messages avec contexte riche
- **Multi-Projets:** Jongle entre 3-5 projets simultan√©ment (work + side projects)

**Pain Points Sp√©cifiques:**
1. **Co√ªt de Productivit√© Quotidien:**
   - "Je perds 30-45 minutes par jour √† attendre des workflows s√©quentiels"
   - Contexte satur√© force √† red√©marrer les conversations ‚Üí perte de contexte pr√©cieux
   - Flow bris√© plusieurs fois par session ‚Üí impact mental/cognitif

2. **Auto-Limitation Frustrante:**
   - "J'ai 15 MCP servers install√©s mais j'en active que 7-8 maximum"
   - Doit choisir entre Playwright OU Serena pour une session (pas les deux)
   - Teste pas de nouveaux MCP int√©ressants par peur de saturer le contexte

3. **Workflows Sophistiqu√©s Bloqu√©s:**
   - Impossible de coordonner GitHub + Database + Slack + Testing dans un seul flow
   - Les agents "autonomes" qu'il veut construire sont brid√©s par les limites actuelles
   - Frustration face au potentiel inexploit√© de MCP

**Goals & Motivations:**
- **Productivit√© Maximale:** "Claude Code devrait √™tre 10x developer, pas un goulot"
- **Innovation AI:** Construire des agents vraiment sophistiqu√©s (multi-domaines, autonomes)
- **Exploration Sans Friction:** Tester TOUT l'√©cosyst√®me MCP sans compromis
- **Influence:** Partager ses d√©couvertes (tweets, blog posts, conf talks)

**Crit√®res de D√©cision d'Adoption:**
- ‚úÖ **Performance Tangible:** Doit voir 3-5x am√©lioration d√®s jour 1
- ‚úÖ **Zero Friction:** `npx install` et √ßa marche - pas de config complexe
- ‚úÖ **Fiabilit√©:** Doit √™tre rock-solid, pas de bugs bloquants (AIRIS = repoussoir)
- ‚úÖ **Open Source:** Pr√©f√®re solutions open-source, self-hostable
- ‚úÖ **Edge Cases Couverts:** Supporte ses workflows complexes existants

**D√©finition de Succ√®s:**
- "Je peux activer mes 15 MCP servers sans y penser"
- "Mes workflows multi-tools sont fluides, j'ai oubli√© la latence"
- "Je construis des agents AI que je n'aurais jamais pu faire avant"

**Taille du March√©:**
- **Early Adopters:** ~5,000-10,000 d√©veloppeurs worldwide (actifs sur Claude Code + MCP)
- **March√© Adressable:** ~50,000-100,000 dans 12-18 mois (adoption MCP croissante)
- **Influence:** Ratio 1:10 (1 power user influence 10 autres d√©veloppeurs)

### Secondary User Segment

**Persona: "Jordan - Le Curieux MCP Explorer"**

**Profil D√©mographique:**
- **R√¥le:** Mid-level Developer, Product Engineer, Indie Hacker
- **Exp√©rience:** 2-5 ans de d√©veloppement, nouveau sur Claude Code (<6 mois)
- **Contexte:** D√©couvre l'√©cosyst√®me MCP, excit√© par le potentiel, veut explorer
- **Tech Stack:** G√©n√©ralist (React/Node ou Python/Django), utilise Claude Code pour prototyping rapide

**Comportement avec Claude Code & MCP:**
- **Usage:** 3-5 heures par jour, principalement pour prototyping et learning
- **Approche:** "Je veux tester TOUT ce qui existe dans l'√©cosyst√®me MCP"
- **Installation Enthusiaste:** Ajoute 5-10 MCP servers d√®s les premi√®res semaines
- **Frustration Imm√©diate:** Se heurte au mur du contexte d√®s 5-8 MCP servers activ√©s

**Pain Points Sp√©cifiques:**
1. **D√©couverte Brid√©e:**
   - "J'ai vu 30 MCP servers cool sur Twitter mais je ne peux en utiliser que 5-6"
   - Doit d√©sactiver un MCP pour en tester un autre ‚Üí friction constante
   - Peur de "casser" sa config en ajoutant trop de MCP

2. **Complexit√© Technique:**
   - Pas expert en optimisation de contexte ou configuration avanc√©e
   - Veut que "√ßa marche direct" sans lire 20 pages de docs
   - Frustr√© par les solutions qui n√©cessitent de la configuration manuelle (AIRIS)

3. **Exp√©rimentation Limit√©e:**
   - Impossible de combiner librement diff√©rents MCP pour tester des id√©es
   - "Je voudrais essayer GitHub + Figma + Notion ensemble mais √ßa sature"
   - Abandonne certaines explorations faute d'infrastructure stable

**Goals & Motivations:**
- **Exploration Libre:** "Je veux pouvoir tester n'importe quel MCP sans me soucier des limites"
- **Apprentissage Rapide:** Comprendre le potentiel de MCP sans friction technique
- **Prototyping Agile:** Construire des POCs rapidement en combinant plusieurs MCP
- **Simplicit√©:** "npx install et √ßa marche" - pas de PhD en architecture distribu√©e requis

**Crit√®res de D√©cision d'Adoption:**
- ‚úÖ **Zero Configuration:** Doit marcher out-of-the-box
- ‚úÖ **Gratuit/Open Source:** Budget limit√© (indie hacker ou side project)
- ‚úÖ **Documentation Claire:** Quick start en <5 minutes
- ‚úÖ **Communaut√© Active:** Discord/Forum pour poser questions
- ‚úÖ **Pas de Lock-In:** Peut d√©sinstaller facilement si √ßa ne marche pas

**D√©finition de Succ√®s:**
- "J'ai install√© AgentCards, tous mes MCP marchent ensemble, je n'y pense plus"
- "Je peux tester librement de nouveaux MCP sans d√©sactiver les anciens"
- "Mes prototypes se construisent vite sans me battre avec la config"

**Taille du March√©:**
- **Early Explorers:** ~20,000-30,000 d√©veloppeurs d√©couvrant MCP
- **March√© Croissant:** +50% mensuel avec l'adoption de Claude Code
- **Conversion:** 10-20% deviendront power users dans 6-12 mois

**Relation avec Primary User:**
- Les power users (Alex) influencent les explorateurs (Jordan) via recommendations
- Jordan devient Alex avec le temps (pipeline naturel)
- AgentCards facilite cette transition (pas besoin de reconfigurer)

---

## Goals and Success Metrics

### Business Objectives

**Philosophie: Qualit√© > Quantit√© | DX Irr√©prochable > Growth Agressif**

AgentCards vise √† construire une **communaut√© ultra-engag√©e** d'utilisateurs satisfaits plut√¥t qu'une base massive d'utilisateurs frustr√©s. Le succ√®s se mesure √† la satisfaction profonde des early adopters qui deviennent ensuite les √©vang√©listes naturels du produit.

#### Objectifs 6 Mois Post-MVP (F√©vrier-Ao√ªt 2025)

**1. Communaut√© Qualitative**
- **200-500 utilisateurs actifs hebdomadaires** ultra-engag√©s
  - Priorit√©: Engagement profond > volume massif
  - Chaque utilisateur doit √™tre un potentiel ambassador
  - Ratio commits/users √©lev√© (communaut√© contributive)

**2. Adoption Organique via Word-of-Mouth**
- **20-30 mentions Twitter/semaine** par des power users influents
- **3-5 blog posts/tutorials** cr√©√©s par la communaut√© (non sollicit√©s)
- **10-20 GitHub contributors** actifs au-del√† du core team
- Apparition sur **1-2 newsletters tech** majeures (exemple: TLDR, ByteByteGo)

**3. Open Source Traction**
- **1,000-2,000 GitHub stars** (qualit√© communaut√© > vanity metric)
- **Pull Requests:** 50+ PR externes (communaut√© contributive)
- **Issues Resolution Time:** <48h pour bugs critiques (DX = prio)

**4. Market Penetration Cibl√©e**
- **2-5% des power users Claude Code** (segment primaire "Alex")
- **1-3% des explorateurs MCP** (segment secondaire "Jordan")
- Focus sur **top 100 early adopters MCP** plut√¥t que masse g√©n√©rique

### User Success Metrics

**Focus: DX Irr√©prochable = M√©trique #1 de Succ√®s**

#### Performance Technique D√©livr√©e (Validation de la Promesse)

**1. Context Optimization**
- **Target:** R√©duction de **30-50% ‚Üí <5%** du contexte consomm√© par tool schemas
- **Mesure:** Moyenne sur tous les utilisateurs actifs
- **Seuil de Succ√®s:** >90% des utilisateurs atteignent <10% de contexte utilis√©
- **Validation:** Telemetry automatique (opt-in, respecte privacy)

**2. Latency Improvement**
- **Target:** Workflows 5-tools passent de **5x latence ‚Üí 1x latence** (am√©lioration 5x)
- **Mesure:** P50 et P95 des temps d'ex√©cution workflows multi-tools
- **Seuil de Succ√®s:** P95 <3 secondes pour workflow 5-tools typique
- **Validation:** Built-in observability dashboard

**3. Scale Capability**
- **Target:** Moyenne MCP servers actifs passe de **7-8 ‚Üí 15+**
- **Mesure:** Nombre m√©dian de MCP servers activ√©s par utilisateur power
- **Seuil de Succ√®s:** >60% des power users utilisent 12+ MCP servers simultan√©ment
- **Validation:** Configuration snapshots anonymis√©s

#### Satisfaction Utilisateur (Non-N√©gociable)

**1. Net Promoter Score (NPS) - M√©trique Critique**
- **Target:** **NPS >75** (excellent) avec objectif stretch **>80** (world-class)
- **Mesure:** Survey mensuel apr√®s 2+ semaines d'usage
- **Benchmark:** Outils dev best-in-class (Vercel ~70, Raycast ~75)
- **Seuil d'Alerte:** Si NPS <65, freeze features et focus DX fixes

**2. Retention √† 30 Jours**
- **Target:** **>70%** des utilisateurs encore actifs √† J30
- **Mesure:** Utilisateurs ayant 1+ session active au jour 30 post-installation
- **Benchmark:** Excellent pour dev tools (typical ~40-50%)
- **Indicateur:** DX tellement bon que les users ne partent pas

**3. Time to "Aha Moment"**
- **Target:** <10 minutes de l'installation au premier "wow"
- **Mesure:** Temps entre `npx agentcards` et premi√®re ex√©cution workflow parall√©lis√© r√©ussi
- **Seuil de Succ√®s:** >80% des users atteignent "aha" en <10 min
- **Validation:** DX frictionless = adoption imm√©diate

#### Comportements Cibles (Adoption Profonde)

**1. Workflows Cross-MCP Sophistiqu√©s**
- **Target:** >40% des power users cr√©ent workflows 3+ MCP servers coordonn√©s
- **Mesure:** Workflows d√©tect√©s via DAG execution logs
- **Indicateur:** AgentCards d√©bloque vraiment de nouveaux use cases

**2. Tool Prediction Hit Rate**
- **Target:** >70% de pr√©dictions correctes apr√®s 1 semaine d'usage
- **Mesure:** % de tools sp√©culatifs effectivement utilis√©s
- **Indicateur:** Learning engine performant et utile

**3. Community Contribution Rate**
- **Target:** >15% des utilisateurs contribuent (code, docs, plugins, support)
- **Mesure:** % users avec 1+ contribution GitHub ou Discord help
- **Indicateur:** Communaut√© engag√©e et ownership partag√©

### Key Performance Indicators (KPIs)

**Les 3 M√©triques Non-N√©gociables pour Valider le Succ√®s d'AgentCards**

Si AgentCards ne peut tracker que 3 m√©triques, ce sont celles-ci. Toutes les autres sont secondaires.

#### üéØ KPI #1: Net Promoter Score (NPS) >75

**Pourquoi C'est Critique:**
- DX irr√©prochable = utilisateurs qui recommandent passionn√©ment
- Indicateur direct de satisfaction profonde
- Pr√©dicteur de word-of-mouth organique

**Target & Thresholds:**
- ‚úÖ **Success:** NPS >75 (excellent, top 10% dev tools)
- üéâ **Stretch:** NPS >80 (world-class, top 1% dev tools)
- üö® **Alert:** NPS <65 ‚Üí FREEZE features, fix DX imm√©diatement

**Mesure:**
- Survey mensuel automatique apr√®s 2+ semaines d'usage
- Question: "Recommanderiez-vous AgentCards √† un coll√®gue dev? (0-10)"
- Segmentation: Power users vs Explorers

**Impact sur Roadmap:**
- Si NPS <target: Roadmap bloqu√©e jusqu'√† r√©solution des pain points
- Feedback qualitatif analys√© chaque semaine pour prioriser fixes

---

#### ‚ö° KPI #2: Context Reduction Moyenne <5%

**Pourquoi C'est Critique:**
- Core value prop technique d'AgentCards
- Mesure si la promesse principale est tenue
- Impact direct sur UX quotidienne (r√©cup√©ration de 90% du contexte)

**Target & Thresholds:**
- ‚úÖ **Success:** <5% contexte consomm√© en moyenne
- üéâ **Stretch:** <3% contexte consomm√©
- üö® **Alert:** >10% ‚Üí Investigation architecture imm√©diate

**Mesure:**
- Telemetry opt-in (respecte privacy, anonymis√©)
- Calcul: (tokens_tool_schemas / tokens_total_available) √ó 100
- Tracking: P50, P75, P95 pour identifier outliers

**Validation du Succ√®s:**
- >90% des utilisateurs sous <10% de contexte
- Am√©lioration mesur√©e vs baseline (30-50% actuel)

---

#### üîÑ KPI #3: Retention √† 30 Jours >70%

**Pourquoi C'est Critique:**
- Preuve de satisfaction durable (pas juste buzz initial)
- Indicateur que AgentCards devient indispensable
- 70% = exceptionnel pour dev tools (2x la norme ~35-40%)

**Target & Thresholds:**
- ‚úÖ **Success:** >70% retention J30
- üéâ **Stretch:** >80% retention J30
- üö® **Alert:** <60% ‚Üí Churn analysis critique

**Mesure:**
- Cohorte analysis mensuelle
- D√©finition "actif": 1+ session avec AgentCards au jour 30
- Segmentation: Installation source, user type, MCP count

**Signal Qualitatif:**
- Interviews exit si churn pour comprendre "why"
- Corr√©lation avec NPS pour identifier patterns

---

#### üìä KPIs Secondaires (Tracked mais Non-Bloquants)

**4. Utilisateurs Actifs Hebdomadaires: 200-500**
- Croissance organique saine
- Qualit√© communaut√© > volume

**5. GitHub Stars Growth Rate: +50-100/mois**
- Indicateur de buzz et d√©couvrabilit√©
- Pas vanity metric si corr√©l√© avec NPS √©lev√©

---

### Dashboard de Suivi

**Weekly Check:**
- NPS trend (semaine glissante)
- Context reduction moyenne
- Retention cohort actuelle

**Monthly Review:**
- Deep dive sur les 3 KPIs + feedback qualitatif
- D√©cision: Continue roadmap ou pivot vers DX fixes
- Prioritization bas√©e sur impact NPS

**Principe de D√©cision:**
> **"Si un choix doit √™tre fait entre feature et DX, DX gagne toujours."**

---

## MVP Scope

**Philosophie: Foundation Solide > Feature Bloat | Valider Hypoth√®ses > Promises Non-Test√©es**

### MVP Definition (8 Semaines - Production Ready)

Le MVP AgentCards d√©livre les **2 promesses fondamentales** qui r√©solvent les pain points critiques identifi√©s:
1. **Context Optimization** - Lib√©rer 90% du contexte
2. **Parall√©lisation Basique** - Workflows 5x plus rapides

**Crit√®re de Succ√®s MVP:**
> Un power user peut activer 15+ MCP servers, ex√©cuter un workflow cross-MCP parall√©lis√©, et atteindre son "aha moment" en <10 minutes post-installation.

---

### Core Features (MUST HAVE - Semaines 1-6)

**1. Context Optimization Engine** ‚≠ê‚≠ê‚≠ê
- **Vector Search S√©mantique:**
  - SQLite + sqlite-vec extension pour embeddings storage
  - Recherche s√©mantique des tools pertinents via cosine similarity
  - API: `search_tools(query: string, top_k: number)` ‚Üí tool_ids + scores
- **On-Demand Schema Loading:**
  - Chargement granulaire tool-by-tool (pas server-by-server)
  - Cache SQLite des schemas MCP
  - API: `get_tool_schema(tool_id: string)` ‚Üí schema JSON
- **R√©sultat Mesurable:** Context <5% (vs 30-50% baseline)

**Effort:** 2-3 semaines | **Priorit√©:** P0 - Bloquant

---

**2. DAG Execution Engine (Parall√©lisation Basique)** ‚≠ê‚≠ê‚≠ê
- **Dependency Graph Construction:**
  - Parsing automatique input/output schemas pour construire DAG
  - D√©tection des outils ex√©cutables en parall√®le vs s√©quentiel
  - Topological sort custom (100-150 LOC, zero dependency externe)
- **Parallel Executor:**
  - Ex√©cution simultan√©e des branches ind√©pendantes du DAG
  - Wait-all pattern + agr√©gation r√©sultats
  - Gestion d'erreurs: retourner succ√®s ET √©checs avec codes
- **SSE Streaming:**
  - Stream r√©sultats d√®s disponibilit√© (feedback progressif)
  - Format event: `task_complete`, `execution_complete`, `error`
- **R√©sultat Mesurable:** Latence 5x ‚Üí 1x pour workflows multi-tools

**Effort:** 2-3 semaines | **Priorit√©:** P0 - Bloquant

---

**3. Zero-Config Auto-Discovery** ‚≠ê‚≠ê
- **MCP Server Detection:**
  - Scan automatique des MCP servers disponibles (stdio, SSE)
  - Health checks automatiques au d√©marrage
  - Convention over configuration (sensible defaults)
- **Embeddings Generation:**
  - G√©n√©ration automatique des embeddings au premier lancement
  - Support API (OpenAI/Anthropic) OU local (transformers.js)
  - Stockage dans SQLite vector store
- **R√©sultat Mesurable:** Time to "aha moment" <10 min

**Effort:** 3-5 jours | **Priorit√©:** P0 - DX critique

---

**4. SQLite-Powered Storage** ‚≠ê‚≠ê
- **Unified Database:**
  - Vector store (sqlite-vec pour embeddings)
  - Schema cache (MCP tool schemas)
  - Usage stats table (foundation pour speculative execution future)
  - Configuration metadata
- **Single File Portability:**
  - Tout dans un fichier `.agentcards.db`
  - Pas de Redis/Postgres/Qdrant requis
  - Simplicit√© d√©ploiement = avantage AIRIS rat√©
- **R√©sultat Mesurable:** Installation <2 minutes

**Effort:** 1 semaine int√©gr√© avec #1 | **Priorit√©:** P0 - Foundation

---

**5. Basic Observability (Telemetry Backend)** ‚≠ê
- **Metrics Collection:**
  - Context usage tracking (opt-in, anonymis√©)
  - Latency measurements (P50/P95)
  - DAG execution success/failure rates
  - Stockage dans SQLite (table `metrics`)
- **Structured Logging:**
  - JSON logs avec pino/winston
  - Niveaux: error, warn, info, debug
- **NO visual dashboard** (defer to v1.1)
- **R√©sultat Mesurable:** Donn√©es pour valider KPIs (NPS, context, retention)

**Effort:** 3-4 jours | **Priorit√©:** P1 - Important pour validation

---

### Out of Scope for MVP (Defer to v1.1+)

**‚ùå Speculative Execution & Tool Prediction**
- **Rationale:** Besoin de valider que √ßa marche vraiment en pratique
- **Approche:** Foundations d'abord (DAG + usage stats table)
- **Condition pour inclusion:** Tests concluants post-MVP prouvant efficacit√© >70%
- **Si valid√©:** Peut √™tre "quick win" car graph d√©pendances d√©j√† pr√©sent
- **Timeline si valid√©:** +2-3 semaines post-MVP

**‚ùå Plugin System pour API Translation**
- **Rationale:** Pas de cas d'usage bloquants sans plugins day-1
- **Approche:** MCP natif suffit pour MVP
- **Timeline:** v1.1 (+1 semaine)

**‚ùå Visual Observability Dashboard**
- **Rationale:** Telemetry backend suffit pour KPIs validation
- **Approche:** Logs + SQLite metrics queries manuels acceptable MVP
- **Timeline:** v1.2 (+1-2 semaines) si demand utilisateur

**‚ùå Edge Deployment (Deno Deploy/Cloudflare Workers)**
- **Rationale:** Local-first simplifie debugging et d√©veloppement MVP
- **Approche:** Deno runtime local via `npx agentcards`
- **Architecture prep:** Code Deno-compatible d√®s le d√©but (edge-ready)
- **Timeline:** v1.1 (+1 semaine deploy config)

**‚ùå Advanced Caching (Event-Based Invalidation)**
- **Rationale:** Basic cache suffit MVP
- **Approche:** Simple TTL-based cache pour schemas
- **Timeline:** v2 (+2 semaines) si usage stats montrent besoin

---

### MVP Success Criteria

**Technical Validation:**
- ‚úÖ Context reduction <5% mesur√©e sur >10 power users beta
- ‚úÖ Latency 5x‚Üí1x pour workflow 5-tools typique (P95 <3s)
- ‚úÖ Zero bugs critiques bloquants (AIRIS lesson learned)
- ‚úÖ Installation + premier workflow <10 minutes

**User Validation:**
- ‚úÖ 20-50 beta users actifs (power users segment)
- ‚úÖ NPS >70 sur beta cohort
- ‚úÖ >60% beta users activent 12+ MCP servers
- ‚úÖ 3-5 testimonials organiques positifs

---

### Timeline D√©taill√©e (8 Semaines)

**Semaines 1-2: Foundation + Context Optimization**
- Setup projet Deno + architecture
- SQLite + sqlite-vec integration
- Vector search implementation
- On-demand schema loading

**Semaines 3-4: DAG Execution + Parall√©lisation**
- Dependency graph construction
- Parallel executor implementation
- SSE streaming setup
- **Checkpoint Semaine 4:** MVP demo-able avec 2-3 MCP servers

**Semaines 5-6: Polish + Auto-Discovery**
- Zero-config auto-discovery
- Embeddings generation automatique
- Error handling robuste
- Basic telemetry backend
- **Checkpoint Semaine 6:** Feature-complete, testing intensif

**Semaines 7-8: Beta Testing + Production Hardening**
- Beta deployment avec 20-50 power users
- Bug fixes critiques bas√©s sur feedback
- Documentation (README, quick start)
- Performance optimization
- **Checkpoint Semaine 8:** Production-ready release

---

### Post-MVP Roadmap (Conditional on Validation)

**v1.1 (Semaines 9-11) - Extension Pragmatique:**
- Edge deployment si demand
- Plugin system si cas d'usage √©mergent
- Visual dashboard si friction metrics analysis

**v1.2-v2 (Semaines 12-20) - Innovation Layer:**
- **Speculative execution** (SI valid√© techniquement)
- Advanced caching avec event-based invalidation
- Multi-tenancy support (si teams demand)

**Principe de D√©cision Post-MVP:**
> **Features prioritized by: 1) User feedback intensity, 2) NPS impact potential, 3) Technical validation**

---

## Strategic Alignment and Financial Impact

### Financial Impact

**Nature du Projet:** Open-Source Passion Project (pas de revenue model direct MVP)

#### Investissement en Temps (Principale "Currency")

**Phase MVP (8 Semaines):**
- **D√©veloppement Full-Time:** ~320 heures (8 semaines √ó 40h)
- **Valeur Temps D√©veloppeur Senior:** ~‚Ç¨25,000-35,000 (market rate √©quivalent)
- **Temps R√©el Investi:** Variable selon side-project vs full-time

**Co√ªt d'Opportunit√©:**
- **Alternative A:** Consulting contracts (‚Ç¨500-800/jour √ó 40 jours = ‚Ç¨20,000-32,000)
- **Alternative B:** Employment salaire (2 mois = ~‚Ç¨8,000-12,000 net)
- **Alternative C:** Autres side projects avec revenue plus court terme

**Justification de l'Investissement:**
- **ROI Non-Financier:** Portfolio piece exceptionnel (technical depth + market impact)
- **Learning Value:** Ma√Ætrise approfondie de MCP, Deno, vector search, DAG execution
- **Positioning Strat√©gique:** √âtablir thought leadership dans l'√©cosyst√®me MCP
- **Long-term Optionality:** Fondation pour opportunit√©s futures (consulting, speaking, employment offers)

#### Co√ªts Infrastructure (Minimaux par Design)

**D√©veloppement & MVP:**
- **Hosting:** ‚Ç¨0 (local-first deployment)
- **Database:** ‚Ç¨0 (SQLite)
- **CI/CD:** ‚Ç¨0 (GitHub Actions free tier)
- **Domain/Site:** ‚Ç¨15-30/an (optionnel)
- **Embeddings:** ‚Ç¨0 (BGE-Large-EN-v1.5 local, zero API costs)

**Total Co√ªts Directs MVP:** <‚Ç¨50

**Philosophie:**
> **"Frugalit√© par Design = Freedom to Fail Fast"**
> SQLite-first architecture √©limine infrastructure costs, permettant iteration rapide sans burning cash.

#### Retour sur Investissement (Non-Traditionnel)

**ROI Direct (Improbable Court Terme):**
- Pas de revenue model MVP
- Open-source = free usage
- Mon√©tisation future possible mais non-prioritaire

**ROI Indirect (Strat√©gique):**

**1. Career Capital (Valeur Estim√©e: ‚Ç¨50,000-100,000)**
- Portfolio showcase technique de niveau "staff engineer"
- Proof of capability: architecture distribu√©e, performance optimization, DX focus
- Diff√©renciation forte vs autres candidats dans interviews
- Potentiel speaking engagements (‚Ç¨1,000-3,000 per talk)

**2. Network Effects (Valeur Inestimable)**
- Connexions avec top 100 MCP early adopters (influencers tech)
- Reconnaissance dans communaut√© Anthropic/Claude
- Opportunit√©s collaboration avec companies buildant sur MCP
- Insider knowledge √©cosyst√®me AI tooling

**3. Thought Leadership (Valeur Long-Terme)**
- √âtablir expertise reconnue en AI tooling infrastructure
- Blog posts / technical content g√©n√©rant audience
- Potentiel book/course sur MCP architecture
- Consulting opportunities organiques (inbound)

**4. Optionality Creation (Valeur Strat√©gique)**
- **Option A:** Consulting sp√©cialis√© MCP/AI tooling (‚Ç¨800-1,200/jour)
- **Option B:** Acquisition par company buildant AI devtools
- **Option C:** Foundation pour startup si product-market fit exceptionnel
- **Option D:** Employment offers de companies impressed (Anthropic, Vercel, etc.)

**Sc√©nario ROI Positif (12-24 Mois):**
- 1 speaking engagement (‚Ç¨2,000) + 5 consulting days (‚Ç¨4,000) + job offer premium (‚Ç¨10,000-20,000) = **‚Ç¨16,000-26,000**
- ROI: ~50-80% vs investissement temps √©quivalent
- SANS compter network/learning/positioning value (inestimable)

### Company Objectives Alignment

**Context:** Projet personnel (pas d'entreprise existante), donc alignement = Personal & Professional Goals

#### Objectifs Personnels Align√©s

**1. Ma√Ætrise Technique Approfondie ‚≠ê‚≠ê‚≠ê**
- **Goal:** Devenir expert reconnu en AI tooling infrastructure
- **Alignment:** AgentCards couvre vector search, DAG execution, MCP protocol, performance optimization
- **Outcome:** Technical skills transf√©rables valorisables √† ‚Ç¨800-1,200/jour consulting rate

**2. Impact Mesurable sur √âcosyst√®me ‚≠ê‚≠ê‚≠ê**
- **Goal:** Cr√©er des outils qui am√©liorent quotidien des d√©veloppeurs
- **Alignment:** AgentCards r√©sout pain points quotidiens (10h/jour Claude Code = impact direct)
- **Outcome:** Satisfaction de r√©soudre probl√®mes r√©els, testimonials authentiques

**3. Thought Leadership & Recognition ‚≠ê‚≠ê**
- **Goal:** √ätre reconnu comme thought leader AI/dev tools
- **Alignment:** Projet innovant (speculative execution appliqu√© √† MCP), solvant probl√®me que AIRIS/Smithery ont rat√©
- **Outcome:** Invitations speaking, blog audience, network quality

**4. Autonomie & Ownership ‚≠ê‚≠ê**
- **Goal:** Contr√¥le total sur vision produit et d√©cisions techniques
- **Alignment:** Open-source = pas de investors/stakeholders contraignants
- **Outcome:** Creative freedom totale, apprentissage self-directed

**5. Portfolio Building (Career Insurance) ‚≠ê‚≠ê**
- **Goal:** S√©curiser options professionnelles futures
- **Alignment:** AgentCards = flagship portfolio piece (technical depth + market relevance)
- **Outcome:** Leverage dans n√©gociations employment/consulting

#### Alignement avec Trajectoire Professionnelle

**Phase Actuelle:** Senior Developer / AI Engineer (10h/jour Claude Code)

**Phase Cible (12-24 Mois):**
- **Path A:** Staff/Principal Engineer dans AI devtools company
- **Path B:** Independent Consultant sp√©cialis√© AI tooling (‚Ç¨150,000-200,000/an)
- **Path C:** Technical Co-Founder AI infrastructure startup

**Comment AgentCards Facilite:**
- Proof of capability architecture distribu√©e (Staff Engineer skill)
- Network avec decision makers AI tooling ecosystem
- Expertise MCP = rare & valuable (early mover advantage)
- Track record shipping production-grade open source

### Strategic Initiatives

#### Initiative #1: Capturer le Market Timing Optimal (Q1-Q2 2025)

**Contexte Strat√©gique:**
- MCP adoption en croissance exponentielle (Claude Code push d'Anthropic)
- AIRIS/Smithery/Unla ont √©chou√© sur ex√©cution (bugs, lazy loading rat√©)
- Fen√™tre d'opportunit√© 6-9 mois avant qu'une big tech r√©solve le probl√®me

**Strat√©gie:**
- **Ship MVP Q1 2025** avant que quelqu'un d'autre r√©solve context optimization
- Early mover advantage = capture des top 100 early adopters influencers
- √âtablir AgentCards comme "de facto solution" avant concurrence s√©rieuse

**Risque de D√©lai:**
- Anthropic pourrait int√©grer solution native dans Claude Code (likelihood: mod√©r√©e)
- Autre indie hacker/team pourrait ship solution similaire
- Fen√™tre se referme si trop lent ‚Üí urgence justifi√©e

#### Initiative #2: Construire Communaut√© Quality-First (pas Growth-at-All-Costs)

**Philosophie:**
- 500 utilisateurs ultra-satisfaits > 50,000 utilisateurs frustr√©s
- NPS >75 non-n√©gociable = ambassadors naturels via word-of-mouth
- Croissance organique durable vs spike hype puis churn

**Tactiques:**
- Beta priv√©e avec 20-50 power users hand-picked (influencers MCP)
- Discord/GitHub community moderation active (response time <24h)
- Feedback loop direct: weekly user interviews pour capturer pain points
- Public roadmap driven par user feedback intensity

**Diff√©renciation vs AIRIS:**
- AIRIS a privil√©gi√© growth ‚Üí bugs critiques non-resolus ‚Üí bad reputation
- AgentCards privil√©gie satisfaction ‚Üí slow growth mais sustainable

**Mesure de Succ√®s:**
- Ratio contributeurs/users √©lev√© (>15% contribute code/docs/support)
- Testimonials organiques non-sollicit√©s (Twitter, blog posts)
- Inbound demandes collaboration (companies voulant int√©grer)

#### Initiative #3: √âtablir Thought Leadership via Technical Content

**Objectif:**
- Positionner AgentCards (et BMad) comme r√©f√©rence technique MCP infrastructure
- √âduquer l'√©cosyst√®me sur context optimization & parallelization

**Content Strategy:**

**Blog Posts Techniques (4-6 sur 6 mois):**
1. "Why MCP Context Optimization Matters: The 30-50% Tax Nobody Talks About"
2. "Applying CPU Branch Prediction to AI Tool Workflows: Speculative Execution Explained"
3. "Building a Vector Search Engine with SQLite + sqlite-vec: A Practical Guide"
4. "DAG Execution for MCP: From 5x Latency to 1x in 200 Lines of Code"
5. "Why AIRIS Failed and What AgentCards Does Differently"
6. "The Economics of Edge-First Architecture: SQLite vs Redis/Postgres"

**Speaking Opportunities:**
- DevoxxFR, dotJS, JSConf EU (target Q3-Q4 2025)
- MCP community meetups (online + Paris/London)
- Anthropic developer events (si opportunit√©)

**Open Source Best Practices:**
- Transparent roadmap public (GitHub Projects)
- Weekly changelog d√©taill√©
- Architecture Decision Records (ADRs) publics
- Livestream coding sessions (optionnel, si demand)

**Outcome Strat√©gique:**
- AgentCards devient "case study" de comment faire open source dev tools correctement
- Inbound traffic organique via content SEO
- Invitation collaborations/partnerships

#### Initiative #4: Cr√©er Optionality pour Mon√©tisation Future (Sans Compromettre MVP)

**Principe:**
> **"Build for love now, optionality for money later"**

**Options de Mon√©tisation (Post-MVP, Conditional on Success):**

**Option A: Managed Service (SaaS)**
- AgentCards Cloud - hosted version avec zero-ops
- Target: Teams/enterprises voulant managed solution
- Pricing: ‚Ç¨29-99/user/mois
- Timeline: v2+ (semaines 20-30) si demand valid√©e

**Option B: Enterprise Features**
- Multi-tenancy, SSO, audit logs, SLA guarantees
- Open core model: MVP open-source, enterprise features payantes
- Target: Companies avec compliance requirements
- Pricing: ‚Ç¨5,000-15,000/an per team

**Option C: Consulting & Support**
- Custom MCP integration development
- Architecture consulting pour AI tooling
- Priority support contracts
- Pricing: ‚Ç¨800-1,200/jour OU retainers ‚Ç¨3,000-8,000/mois

**Option D: Acquisition**
- Exit strategy si product-market fit exceptionnel
- Target acquirers: Anthropic, Vercel, companies buildant AI dev platforms
- Valuation hypoth√©tique: ‚Ç¨200,000-1,000,000 (d√©pend traction)

**Approche Imm√©diate:**
- MVP reste 100% gratuit open-source (pas de paywall)
- Foundations architecturales permettent future SaaS (multi-tenancy ready)
- Pas de pivot monetization avant validation product-market fit solide

**D√©cision Point:**
- SI NPS >80 ET 500+ active users ET inbound demand enterprise ‚Üí Explorer Option A/B
- SI consulting inbound >5 demandes/mois ‚Üí Formaliser Option C
- SINON ‚Üí Continuer open-source, focus growth & impact

---

## Technical Considerations

### Platform Requirements

**Environnement d'Ex√©cution:**
- **Runtime Principal:** Deno 1.40+ (JavaScript/TypeScript moderne)
  - Rationale: Zero-config, secure by default, excellent DX, edge-ready
  - Alternative consid√©r√©e: Node.js (rejected: npm ecosystem overhead, config complexity)
- **D√©ploiement MVP:** Local-first (`npx agentcards` ou global install)
- **Post-MVP:** Edge deployment ready (Deno Deploy, Cloudflare Workers)

**Compatibilit√© OS:**
- **Supported:** macOS, Linux, Windows (via WSL2 recommand√©)
- **Minimum:** macOS 10.15+, Ubuntu 20.04+, Windows 10+ with WSL2
- **Architectures:** x64, ARM64 (Apple Silicon native support)

**MCP Protocol Requirements:**
- **MCP Spec Version:** Compatible 1.0+ (tracking Anthropic spec √©volutions)
- **Transport Protocols:** stdio (primary), SSE (secondary)
- **Server Discovery:** Auto-discovery via Claude Code config files + manual config override

**Contraintes Performance:**
- **Latency Target:** P95 <3 secondes pour workflow 5-tools
- **Memory Footprint:** <200MB RAM pour usage typique (8-15 MCP servers)
- **Startup Time:** <2 secondes cold start, <500ms warm start

**Browser/Client Compatibility:**
- **Primary Client:** Claude Code (VS Code extension)
- **Secondary Clients:** Terminal CLI, HTTP API (future)
- **No Browser UI** pour MVP (backend-only)

### Technology Preferences

**Stack Core (Non-N√©gociable MVP):**

**1. Deno Runtime** ‚≠ê‚≠ê‚≠ê
- **Version:** Deno 1.40+ (latest stable)
- **Rationale:**
  - Zero-config: Pas de package.json, node_modules, build step complexe
  - Security first: Permissions explicites (network, file system, env)
  - TypeScript native: Pas de transpilation setup
  - Edge-ready: Deploy direct sur Deno Deploy (future)
  - Excellent DX: Fast iteration, clear error messages
- **Trade-off Accept√©:** √âcosyst√®me plus petit que Node.js (non-bloquant pour ce use case)

**2. SQLite + sqlite-vec Extension** ‚≠ê‚≠ê‚≠ê
- **Version:** SQLite 3.44+, sqlite-vec 0.1+
- **Rationale:**
  - Single-file database: Portabilit√© totale (.agentcards.db)
  - Vector search int√©gr√©: Pas besoin Qdrant/Pinecone/Weaviate s√©par√©
  - Zero-ops: Pas de serveur externe √† g√©rer
  - Performance excellente: Suffisant pour <10,000 tools vectoris√©s
  - Edge-compatible: Peut run sur Cloudflare Workers/Deno Deploy
- **Usage:**
  - Vector store (embeddings des MCP tools)
  - Schema cache (tool definitions)
  - Usage stats (foundation speculative execution)
  - Configuration metadata

**3. TypeScript (Strict Mode)** ‚≠ê‚≠ê
- **Version:** TypeScript 5.3+ (via Deno)
- **Configuration:** Strict mode enabled (null checks, no implicit any)
- **Rationale:** Type safety critique pour reliability (DX non-n√©gociable)

**Stack Secondaire (Important mais Flexible):**

**4. Embeddings Generation**
- **MVP Approach:** BGE-Large-EN-v1.5 (local, open-source) ‚≠ê
  - Model: BAAI/bge-large-en-v1.5 (1024 dimensions)
  - Quality: ‚â• OpenAI text-embedding-3-small (benchmark validated)
  - Size: 330MB download, ~60s first-time generation
  - Cost: ‚Ç¨0, zero API keys required
  - Implementation: @xenova/transformers (transformers.js)
  - License: MIT
  - **Rationale:** Align√© avec zero-config promise, √©vite friction API keys, qualit√© production-ready d√®s MVP

**5. Testing Framework**
- **Preferred:** Deno.test (built-in, zero config)
- **Coverage:** deno coverage (built-in)
- **E2E:** Playwright (optionnel, post-MVP)

**6. Logging & Observability**
- **Logging:** std/log (Deno standard library) OU pino (si besoin perf)
- **Metrics:** SQLite table (custom metrics storage)
- **Tracing:** Console structured logs MVP, OpenTelemetry future

**Technologies Explicitement √âvit√©es (MVP):**

**‚ùå Redis/Postgres/MongoDB**
- Rationale: Infrastructure overhead vs SQLite simplicity
- SQLite suffisant pour MVP scale (<10,000 users)

**‚ùå Kubernetes/Docker**
- Rationale: Local-first MVP, over-engineering
- Deno binary direct suffit

**‚ùå Frameworks Web (Express/Fastify/Hono)**
- Rationale: std/http suffisant pour MVP API simple
- Peut introduire si routing complexity justifie

**‚ùå GraphQL**
- Rationale: REST/JSON-RPC suffit MCP protocol
- Over-engineering pour ce use case

### Architecture Considerations

#### Pattern Architectural Principal: MCP Gateway avec Context Intelligence

**High-Level Architecture:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Claude Code (Client)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ MCP Protocol (stdio/SSE)
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         AgentCards Gateway (Deno)               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Vector Search Layer                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Semantic tool discovery                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - On-demand schema loading               ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  DAG Execution Engine                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Dependency graph construction          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Parallel orchestration                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  SQLite Storage (.agentcards.db)          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Vector embeddings (sqlite-vec)         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Schema cache                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Usage stats                            ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ MCP Protocol
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    MCP Servers (8-15+ servers)                  ‚îÇ
‚îÇ  - GitHub, Slack, Filesystem, Database, ...     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Composants Cl√©s:**

**1. Vector Search Layer (Context Optimization Core)**
- **Input:** User query/intent (natural language)
- **Process:**
  1. Generate embedding du query (cosine similarity search)
  2. Retrieve top_k tools pertinents (k=3-10 dynamic)
  3. Load schemas on-demand uniquement pour matched tools
- **Output:** Minimal tool schemas (<5% context)
- **Performance:** <100ms latency (SQLite index optimis√©)

**2. DAG Execution Engine (Orchestration Core)**
- **Input:** Tool execution plan avec dependencies
- **Process:**
  1. Parse input/output schemas ‚Üí construct dependency graph
  2. Topological sort ‚Üí identify parallel execution opportunities
  3. Execute independent branches concurrently (Promise.all)
  4. Aggregate results + stream via SSE
- **Output:** Results avec latency optimis√©e (5x ‚Üí 1x)
- **Failure Handling:** Partial success (return succ√®s + errors)

**3. SQLite Storage (Single Source of Truth)**
- **Tables:**
  - `tool_embeddings` (tool_id, embedding_vector, metadata)
  - `tool_schemas` (tool_id, schema_json, server_id, cached_at)
  - `usage_stats` (tool_a, tool_b, frequency, last_used) [foundation speculative]
  - `config` (key-value metadata)
- **Indexes:**
  - Vector index (sqlite-vec HNSW pour fast similarity search)
  - B-tree indexes sur tool_id, server_id
- **Size:** ~10-50MB pour 1,000-5,000 tools vectoris√©s

**D√©cisions Architecturales Critiques:**

**Decision #1: Gateway Pattern vs Proxy Pattern**
- **Choix:** Gateway (intelligent layer) > Proxy (dumb passthrough)
- **Rationale:** Gateway permet context optimization + orchestration
- **Trade-off:** Latency overhead (+50-100ms) vs gains massifs parall√©lisation

**Decision #2: SQLite vs Vector Database D√©di√©**
- **Choix:** SQLite + sqlite-vec > Qdrant/Pinecone/Weaviate
- **Rationale:**
  - Simplicit√© d√©ploiement (single file)
  - Performance suffisante (<10,000 vectors)
  - Zero infrastructure costs
  - Edge-compatible (critical future)
- **Trade-off:** Scale limit√© √† ~100,000 vectors (non-bloquant MVP)

**Decision #3: Local-First vs Cloud-First MVP**
- **Choix:** Local-first (`npx agentcards`)
- **Rationale:**
  - Debugging facilit√© (developers run locally)
  - Zero infrastructure setup (AIRIS lesson learned)
  - Privacy (data reste local)
- **Prep Future:** Architecture edge-ready d√®s day 1

**Decision #4: Local Embeddings avec BGE-Large-EN-v1.5**
- **Choix:** BGE-Large-EN-v1.5 local (1024-dim)
- **Rationale:**
  - Quality ‚â• OpenAI API (benchmark validated)
  - Zero-config promise respect√©e (no API keys required)
  - Zero cost (‚Ç¨0 vs ‚Ç¨50-100 API)
  - 330MB + ~60s init acceptable pour power users
- **Implementation:** @xenova/transformers via transformers.js

**Scalability Considerations (Post-MVP):**

**Current Architecture Limits:**
- **Vector Store:** ~100,000 tools (SQLite + sqlite-vec suffisant)
- **Concurrent Requests:** ~100-500 req/sec (Deno async I/O)
- **Memory:** Linear growth ~20KB per tool cached

**Scale Plan (si demand):**
- **10,000+ users:** Consid√©rer Redis cache layer (hot schemas)
- **100,000+ tools:** Migration vers Qdrant/Weaviate (optionnel)
- **1,000+ req/sec:** Horizontal scaling via edge deployment

**Security Considerations:**

**Data Privacy:**
- Embeddings stock√©s localement (pas cloud)
- Telemetry opt-in (explicit user consent)
- Pas de tracking usage sans permission

**Deno Security Model:**
- Permissions explicites requises (--allow-net, --allow-read, etc.)
- Sandboxed execution (pas d'acc√®s filesystem non-autoris√©)

**MCP Server Trust:**
- AgentCards proxy MCP calls (pas d'ex√©cution arbitrary code)
- Health checks pour detect malicious servers
- User control total sur servers activ√©s

---

## Constraints and Assumptions

### Constraints

**1. Timeline & Delivery (Hard Constraint)**
- **8 Semaines MVP Deadline** - Q1 2025 target pour capturer market timing optimal
- **Cons√©quence:** Scope MVP rigoureux, pas de feature creep
- **Mitigation:** Speculative execution d√©f√©r√©, focus sur 2 core problems

**2. Ressources Humaines (Solo Developer)**
- **√âquipe:** 1 personne (BMad) - d√©veloppement + product + design
- **Cons√©quence:** Pas de parall√©lisation des tracks (frontend/backend simultan√©s)
- **Mitigation:**
  - Backend-only MVP (pas de visual dashboard)
  - Leverage Deno DX pour v√©locit√© maximale
  - Community beta testing pour UX feedback (20-50 users)

**3. Budget Infrastructure (Frugalit√© Stricte)**
- **Budget Total:** <‚Ç¨200 pour MVP
- **Cons√©quence:** Pas de cloud costs (Redis, Postgres, Qdrant, hosting)
- **Mitigation:**
  - SQLite-first architecture (zero infrastructure)
  - Local-first deployment (pas de hosting requis)
  - GitHub Actions free tier pour CI/CD

**4. D√©pendances Externes (MCP Spec √âvolution)**
- **Anthropic MCP Protocol** en √©volution active (spec pas finalis√©e)
- **Cons√©quence:** Breaking changes possibles durant d√©veloppement MVP
- **Mitigation:**
  - Version pinning conservative (MCP 1.0 baseline)
  - Adapter layer pour absorber future changes
  - Active monitoring des MCP spec releases

**5. Technical Stack (Deno Ecosystem Maturity)**
- **Deno SQLite Bindings** moins matures que Node.js √©quivalents
- **sqlite-vec Extension** relativement nouveau (0.1.x)
- **Cons√©quence:** Possibles bugs/limitations d√©couverts durant dev
- **Mitigation:**
  - Prototyping pr√©coce (semaine 1) pour valider feasibility
  - Fallback plan: Node.js si Deno blockers insurmontables
  - Contribution upstream si bugs critiques d√©couverts

**6. Market Window (Urgence Strat√©gique)**
- **6-9 mois** avant qu'un comp√©titeur s√©rieux ou Anthropic int√®gre solution native
- **Cons√©quence:** Pression delivery rapide vs qualit√©
- **Mitigation:**
  - DX non-n√©gociable (NPS >75) m√™me avec urgence
  - MVP scope minimal mais excellente ex√©cution
  - It√©ration post-MVP rapide bas√©e feedback beta

### Key Assumptions

**Assumptions March√© & Adoption:**

**A1: MCP Adoption Continue (Confidence: Haute)**
- **Assumption:** L'√©cosyst√®me MCP grandit avec 20-50%+ mensuel via Claude Code
- **Validation:**
  - Anthropic push marketing MCP activement
  - Centaines de MCP servers cr√©√©s en Q4 2024
- **Risque si Faux:** Market trop petit pour justifier effort
- **Mitigation:** Monitoring adoption metrics mensuellement (GitHub stars MCP servers)

**A2: Context Optimization = Killer Feature (Confidence: Tr√®s Haute)**
- **Assumption:** R√©duire context 30-50% ‚Üí <5% est suffisamment impactant pour adoption
- **Validation:**
  - Pain point v√©cu personnellement (BMad + discussions communaut√©)
  - AIRIS a promis mais rat√© = demand valid√©e
- **Risque si Faux:** Users ne valorisent pas assez le gain
- **Mitigation:** Beta testing pr√©coce (semaine 6) pour valider value prop

**A3: DAG Parall√©lisation D√©livre 3-5x Speedup (Confidence: Moyenne-Haute)**
- **Assumption:** Workflows typiques ont suffisamment d'ind√©pendance pour parall√©lisation
- **Validation:** LLMCompiler a prouv√© faisabilit√© (mais limit√© Python)
- **Risque si Faux:** Speedup r√©el <2x = promesse non tenue
- **Mitigation:**
  - Prototype DAG execution semaine 3 avec workflows r√©els
  - Mesures P50/P95 sur beta users (validation empirique)

**Assumptions Techniques:**

**A4: Deno Stable & Production-Ready (Confidence: Haute)**
- **Assumption:** Deno 1.40+ suffisamment mature pour production deployment
- **Validation:** Deno Deploy utilis√© par companies (Supabase, etc.)
- **Risque si Faux:** Bugs critiques bloquants d√©couverts
- **Mitigation:** Fallback vers Node.js si blockers (architecture agnostic)

**A5: SQLite + sqlite-vec Scale √† 10,000 Tools (Confidence: Haute)**
- **Assumption:** Performance vector search acceptable jusqu'√† 10K vectors
- **Validation:** sqlite-vec benchmarks publi√©s (sub-100ms queries)
- **Risque si Faux:** Latency >500ms = UX d√©grad√©e
- **Mitigation:** Load testing semaine 4-5 avec synthetic data

**A6: BGE-Large Init Time Acceptable (Confidence: Haute)**
- **Assumption:** 330MB download + ~60s first-time generation acceptable pour power users
- **Validation:** One-time setup, quality production-ready (‚â• OpenAI)
- **Risque si Faux:** Users impatients abandon setup
- **Mitigation:** Progress bar + caching, amortized over hundreds of uses

**Assumptions Utilisateur:**

**A7: Power Users Pr√™ts Beta Test (Confidence: Haute)**
- **Assumption:** 20-50 early adopters disponibles pour beta priv√©e
- **Validation:** Network personnel (Twitter, Discord MCP communities)
- **Risque si Faux:** Pas assez feedback qualit√© pour valider MVP
- **Mitigation:** Outreach proactive semaine 5-6 pour recruiting beta

**A8: Zero-Config = Differentiation Forte (Confidence: Haute)**
- **Assumption:** AIRIS config bugs = repoussoir, zero-config = competitive advantage
- **Validation:** Frustration AIRIS document√©e (GitHub issues, Twitter)
- **Risque si Faux:** Config pas si important que pr√©vu
- **Mitigation:** DX focus g√©n√©ral (pas uniquement config) assure valeur

**A9: Open Source = Growth Driver (Confidence: Moyenne-Haute)**
- **Assumption:** Open source g√©n√®re contributions + word-of-mouth vs closed source
- **Validation:** Succ√®s d'autres dev tools open-source (Vite, Biome, etc.)
- **Risque si Faux:** Faible contribution rate, slow growth
- **Mitigation:** Community building actif (Discord, documentation excellente)

**Assumptions Strat√©giques:**

**A10: Anthropic N'Int√©grera Pas Solution Native Court Terme (Confidence: Moyenne)**
- **Assumption:** Anthropic focus sur LLM core vs tooling infrastructure (6-12 mois)
- **Validation:** Historique - Anthropic laisse ecosystem builder sur tooling
- **Risque si Faux:** Claude Code int√®gre context optimization = AgentCards obsol√®te
- **Mitigation:**
  - Ship rapide (8 semaines) pour √©tablir position avant
  - Diff√©renciation via speculative execution (post-MVP) si native solution arrive
  - Possibilit√© collaboration/acquisition si Anthropic int√©ress√©

**A11: Consulting Opportunities √âmergent Naturellement (Confidence: Faible-Moyenne)**
- **Assumption:** Succ√®s MVP ‚Üí inbound consulting demandes (‚Ç¨800-1,200/jour)
- **Validation:** Pattern observ√© avec autres dev tools creators
- **Risque si Faux:** Pas de mon√©tisation court/moyen terme
- **Mitigation:** ROI non-financier suffit (career capital, learning, network)

**Assumptions Testing Strategy:**

**Critiques (Valider Semaines 1-4):**
- A2: Context optimization value (prototype + user interviews)
- A3: DAG speedup r√©el (benchmarks avec workflows r√©els)
- A5: SQLite scale (load testing)

**Importantes (Valider Semaines 5-8):**
- A1: MCP adoption trend (monitoring metrics)
- A7: Beta recruitment (outreach active)
- A6: BGE-Large init time UX (beta feedback)

**Secondaires (Observer Post-MVP):**
- A9: Open source contribution rate
- A10: Anthropic roadmap
- A11: Consulting inbound

---

## Appendices

### A. Research Summary

**Session de Brainstorming (2025-11-03):**
- Document: [docs/brainstorming-session-results-2025-11-03.md](docs/brainstorming-session-results-2025-11-03.md)
- M√©thodes appliqu√©es: First Principles Thinking, Morphological Analysis, SCAMPER, Reverse Brainstorming
- R√©sultats: 50+ concepts g√©n√©r√©s, convergence sur "Gateway Stupide" + Context Optimization + DAG Execution
- Insights cl√©s:
  - SQLite Foundation comme killer decision (zero-ops, portability, edge-ready)
  - D-D-D-B configuration pattern (Discover-Describe-Deploy-Build)
  - Speculative Execution comme innovation diff√©renciante (post-MVP validation)
  - 8-week timeline r√©aliste pour MVP scope d√©fini

**Competitive Analysis:**
- **AIRIS:** Lazy loading promis mais rat√©, config bugs constants ‚Üí bad reputation
- **Smithery:** All-at-once schema loading, pas de parall√©lisation
- **Unla:** Approche proxy simple, pas d'optimization contextuelle
- **LLMCompiler:** Proof of concept DAG execution (Python-only, inspiration directe)

**Market Validation:**
- Pain point v√©cu personnellement (BMad: 10h/jour Claude Code, 8+ MCP servers)
- Discussions communaut√© MCP: frustration contexte + latence r√©currente
- GitHub issues AIRIS: nombreux users bloqu√©s par config + bugs

### B. Stakeholder Input

**Primary Stakeholder: BMad (Product Creator & Primary User)**

**Inputs Cl√©s Fournis Durant Workflow Interactif:**
1. **Vision Produit:** "Context opti et parall√©lisation minimum" pour MVP
2. **Priorit√©s:** "DX c'est ma prio", "tr√®s tr√®s bon NPS je veux non n√©gociable"
3. **Scope Decisions:**
   - Speculative execution d√©f√©r√©: "pas s√ªr que √ßa fonctionne en vrai, √† v√©rifier"
   - Tech stack: "On va utiliser Deno je pense"
   - User primaire: Power user (10h/jour Claude Code) vs noob secondary
4. **Success Criteria:** NPS >75 comme KPI #1, qualit√© communaut√© > quantit√© users
5. **Pragmatisme:** Validation empirique avant promesses (test speculative post-MVP)

**Validation Points:**
- Confirmation target users (Power User primary apr√®s analyse strat√©gique)
- Approbation MVP scope (context opt + DAG, defer speculative)
- Validation metrics focus (NPS, DX, retention > vanity metrics)

### C. References

**MCP Protocol & Ecosystem:**
- [Anthropic MCP Specification](https://github.com/anthropics/mcp) (v1.0+)
- [Claude Code Documentation](https://docs.claude.com/en/docs/claude-code)
- MCP Server Directory: [github.com/punkpeye/awesome-mcp-servers](https://github.com/punkpeye/awesome-mcp-servers)

**Technical Inspiration:**
- LLMCompiler Paper: "An LLM Compiler for Parallel Function Calling" (Berkeley, 2024)
- sqlite-vec: [github.com/asg017/sqlite-vec](https://github.com/asg017/sqlite-vec)
- Deno Runtime: [deno.land](https://deno.land)

**Competitive Products:**
- AIRIS: [airis.com](https://airis.com)
- Smithery: [smithery.ai](https://smithery.ai)
- Unla: [unla.dev](https://unla.dev)

**Architectural Patterns:**
- Gateway Pattern (Microservices Architecture)
- DAG Execution (Task Scheduling, Apache Airflow)
- Vector Search (Semantic Similarity, FAISS, Pinecone)
- Branch Prediction (CPU Architecture, Speculative Execution)

**Developer Tools Benchmarks:**
- Vercel NPS: ~70 (excellent dev tools)
- Raycast NPS: ~75 (world-class DX)
- Vite GitHub Stars Growth: +50-100/semaine (healthy open source)

---

_This Product Brief serves as the foundational input for Product Requirements Document (PRD) creation._

_Next Steps: Handoff to Product Manager for PRD development using the `/bmad:bmm:workflows:prd` command._
