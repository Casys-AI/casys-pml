## Epic 10: DAG Capability Learning & Unified APIs

> **Tech-Spec:** [tech-spec-dag-capability-learning.md](./tech-specs/tech-spec-dag-capability-learning.md)
> **Status:** Proposed (2025-12-17)
> **Author:** Erwan + Claude
> **Depends on:** Epic 7 (Emergent Capabilities), HIL Phase 2 (Permission Escalation)

**Expanded Goal (2-3 sentences):**

Unifier les deux modÃ¨les d'exÃ©cution (DAG explicite et Code libre) en un systÃ¨me d'apprentissage cohÃ©rent oÃ¹ **tout passe par les mÃªmes mÃ©canismes**. ImplÃ©menter la reconstruction de DAG depuis les traces de code, permettant au systÃ¨me d'apprendre des workflows qu'il soit exprimÃ© en DAG ou en code TypeScript. Simplifier les APIs en deux points d'entrÃ©e : `pml_discover` (exploration intelligente) et `pml_execute` (exÃ©cution unifiÃ©e).

**ProblÃ¨mes RÃ©solus:**

| ProblÃ¨me | Solution |
|----------|----------|
| Parallel tracking - pas d'edges crÃ©Ã©s | DÃ©tection via timestamps `ts` + `durationMs` |
| DAG â†’ Capability - pas de gÃ©nÃ©ration | Capability unifiÃ©e `source: code \| dag` |
| Edge types confus (sequence vs dependency) | Clarification: Definition view vs Invocation view |
| Manque de `provides` edge | Nouveau type pour data flow (strict/partial/optional) |
| APIs fragmentÃ©es (5 tools) | Unification: `pml_discover` + `pml_execute` |

**Value Delivery:**

- âœ… **Apprentissage unifiÃ©** - Code ET DAG crÃ©ent des capabilities
- âœ… **Reconstruction DAG** - Le code peut Ãªtre "rejouÃ©" comme DAG
- âœ… **APIs simplifiÃ©es** - 2 tools au lieu de 5 pour l'IA
- âœ… **Preview intelligent** - `resultPreview` + `pml_get_task_result` pour AIL
- âœ… **Provides edges** - ChaÃ®nage data explicite entre tools

---

### Unified Learning Model (Philosophy)

> **Principe fondamental:** Le CODE est le chemin principal. Les DAGs Ã©mergent de l'exÃ©cution,
> ils ne sont pas dÃ©finis Ã  priori. Une Capability est un workflow validÃ© par l'usage.

**Le flow d'apprentissage:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. INTENT                                                               â”‚
â”‚     "Analyser ce fichier JSON et crÃ©er un ticket GitHub"                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. CAPABILITY EXISTS?                                                   â”‚
â”‚     Recherche GraphRAG: intent â†’ capabilities existantes                â”‚
â”‚     Match > 0.85 ? â†’ Replay capability (skip to step 6)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚ NO MATCH
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. CODE GENERATION                                                      â”‚
â”‚     L'IA gÃ©nÃ¨re du TypeScript qui appelle des MCP tools                 â”‚
â”‚     ```typescript                                                        â”‚
â”‚     const content = await mcp.fs.read({ path: "data.json" });           â”‚
â”‚     const parsed = JSON.parse(content);                                 â”‚
â”‚     await mcp.github.createIssue({ title: parsed.summary, ... });       â”‚
â”‚     ```                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. CODE EXECUTION (Sandbox)                                             â”‚
â”‚     - Traces capturÃ©es: tool_start, tool_end + result                   â”‚
â”‚     - Timestamps pour dÃ©tection parallÃ©lisme                            â”‚
â”‚     - HIL si tools sensibles dÃ©tectÃ©s                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. DAG RECONSTRUCTION (POST-EXEC)                                       â”‚
â”‚     Traces â†’ DAGStructure:                                              â”‚
â”‚     - Tasks: fs:read â†’ json:parse â†’ github:createIssue                  â”‚
â”‚     - Dependencies: data flow dÃ©tectÃ© via result â†’ args                 â”‚
â”‚     - Parallel: timestamps overlapping = pas de dÃ©pendance              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. CAPABILITY CREATED/UPDATED                                           â”‚
â”‚     Le DAG reconstruit devient une Capability rÃ©utilisable              â”‚
â”‚     StockÃ©e avec: intent_embedding, source (code ou dag), success_rate  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. NEXT TIME: REPLAY                                                    â”‚
â”‚     Intent similaire â†’ Capability matchÃ©e â†’ ExÃ©cution sans regÃ©nÃ©ration â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Capabilities = Tools abstraits:**

Une Capability n'est pas forcÃ©ment un DAG interne. Elle peut Ãªtre:

| Type | Exemple | ExÃ©cution |
|------|---------|-----------|
| **DAG interne** | `fs:read â†’ json:parse â†’ github:createIssue` | PML exÃ©cute les tasks |
| **Code snippet** | TypeScript avec logique complexe | Sandbox PML |
| **Tool externe** | Temporal workflow, Airflow DAG | DÃ©lÃ©gation Ã  l'orchestrateur |

**Exemple Temporal:**

```typescript
// Capability apprise: "deploy_to_production"
// Au lieu de reconstruire le DAG, on dÃ©lÃ¨gue Ã  Temporal
{
  type: "external_tool",
  tool: "temporal:startWorkflow",
  workflowId: "deploy-prod-v2",
  args: { version: "{{input.version}}" }
}
```

â†’ PML apprend que pour "deploy to production", le meilleur chemin est d'appeler Temporal,
pas d'exÃ©cuter 15 tools MCP sÃ©quentiellement.

**Implications pour l'implÃ©mentation:**

1. **Story 10.7 `pml_execute`**: L'option `implementation.type = "dag"` est pour **replay**,
   pas pour l'exÃ©cution normale. Le chemin par dÃ©faut = code â†’ traces â†’ learning.

2. **Capability.source** peut Ãªtre:
   - `{ type: "code", code: string }` - Code TypeScript
   - `{ type: "dag", dagStructure: DAGStructure }` - DAG interne reconstruit
   - `{ type: "tool", toolId: string, args: Record }` - DÃ©lÃ©gation Ã  un tool (ex: Temporal)

3. **Learning continu**: Chaque exÃ©cution rÃ©ussie amÃ©liore la capability
   (success_rate++, structure raffinÃ©e).

4. **Gestion des conditionnels (KISS):**
   - On capture **ce qui s'est passÃ©** (traces rÃ©elles), pas ce qui pourrait se passer
   - La capability reprÃ©sente le **pattern dominant** (happy path)
   - Si les arguments changent le chemin d'exÃ©cution â†’ on trace la variante
   - **Future:** Merge des branches si le besoin est prouvÃ© (pas dans Epic 10)

   ```
   ExÃ©cution 1: args={exists:true}  â†’ trace [fs:read]           â†’ count++
   ExÃ©cution 2: args={exists:false} â†’ trace [fs:create,fs:write] â†’ variant tracked
   ExÃ©cution 3: args={exists:true}  â†’ trace [fs:read]           â†’ count++

   â†’ Capability.dominantPath = [fs:read] (66% des exÃ©cutions)
   â†’ Capability.variants = [{ path: [fs:create,fs:write], count: 1 }]
   ```

---

**Architecture UnifiÃ©e:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  pml_execute({ intent: "..." })                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Implementation      â”‚     â”‚ Recherche GraphRAG   â”‚            â”‚
â”‚  â”‚ fournie par l'IA?   â”‚ NO  â”‚ - Tools matching     â”‚            â”‚
â”‚  â”‚                     â”‚â”€â”€â”€â”€â–¶â”‚ - Capabilities       â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚            â”‚ YES                        â”‚                        â”‚
â”‚            â–¼                            â–¼                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  EXECUTION (Sandbox)                                 â”‚        â”‚
â”‚  â”‚  - Traces: tool_start/end + result                  â”‚        â”‚
â”‚  â”‚  - Timestamps pour parallel detection               â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  LEARNING                                            â”‚        â”‚
â”‚  â”‚  - Reconstruction DAG depuis traces                  â”‚        â”‚
â”‚  â”‚  - CrÃ©ation/update Capability                        â”‚        â”‚
â”‚  â”‚  - Edges: provides (definition) + sequence (invoc)   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Estimation:** 10 stories (9 MVP + 1 optional), ~3-4 semaines MVP

---

### Story Breakdown - Epic 10

**Story 10.1: Static Code Analysis - DAG Preview (PRE-EXECUTION)** âˆ¥ PARALLEL avec Track A

As an execution system, I want to parse code statically to generate a DAG preview BEFORE execution,
So that I can validate permissions, detect tools, and enable proper HIL/AIL approval flows.

**Position dans l'Epic:**
- Peut Ãªtre dÃ©veloppÃ©e **en parallÃ¨le** avec Track A (10.2 â†’ 10.3 â†’ 10.4)
- N'est PAS un prÃ©requis pour 10.2-10.4 (contrairement Ã  ce qui Ã©tait indiquÃ© avant)
- Devient nÃ©cessaire pour 10.5 (unified capability) et 10.7 (pml_execute avec HIL)

**Context:**
C'est le **chaÃ®non manquant** entre le code et la validation par layer. Sans parsing statique :
- On ne peut pas savoir quels tools seront appelÃ©s avant d'exÃ©cuter
- L'AIL/HIL doit attendre l'Ã©chec au lieu de prÃ©venir
- `per_layer_validation` ne peut pas calculer `requiresValidation()` correctement

**DiffÃ©rence avec Story 10.4 (Reconstruction POST-exec):**

| Aspect | 10.1 Static (PRE) | 10.4 Traces (POST) |
|--------|--------------------|--------------------|
| **Quand** | Avant exÃ©cution | AprÃ¨s exÃ©cution |
| **Input** | Code source (AST) | Traces d'exÃ©cution |
| **PrÃ©cision** | Approximatif (code dynamique) | Exact (ce qui s'est passÃ©) |
| **Use case** | Validation, HIL preview | Learning, replay |

**RÃ©utilisation de l'existant (pas une rÃ©Ã©criture !):**

On a DÃ‰JÃ€ tout le pipeline SWC :
- `SchemaInferrer` (726 LOC, 19 tests) â†’ parse AST, trouve `args.xxx`, infÃ¨re types
- `PermissionInferrer` (510 LOC) â†’ parse AST, dÃ©tecte patterns dangereux
- `tool_schema` table â†’ schemas input/output des MCP tools
- `workflow_pattern` table â†’ schemas des capabilities

**Story 10.1 = Extension de ~100-150 LOC**, pas 250 LOC from scratch.

**Architecture:**
```
Code TypeScript
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SWC AST Parser (RÃ‰UTILISE SchemaInferrer/PermissionInferrer)â”‚
â”‚  - MÃªme parse(), mÃªme traversÃ©e AST                          â”‚
â”‚  - Extension: chercher `mcp.*.*()` ET `capabilities.*()`    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Call Detector (Tools + Capabilities)                        â”‚
â”‚  - `mcp.server.tool()` â†’ lookup tool_schema                 â”‚
â”‚  - `capabilities.name()` â†’ lookup workflow_pattern           â”‚
â”‚  - `await` â†’ dÃ©pendance sÃ©quentielle                        â”‚
â”‚  - `Promise.all()` â†’ parallÃ©lisme                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Schema Validation (provides edges)                          â”‚
â”‚  - tool A output â†’ tool B input : types compatibles ?       â”‚
â”‚  - capability output â†’ tool input : chaÃ®nage valide ?       â”‚
â”‚  - Utilise les schemas qu'on a DÃ‰JÃ€ en DB                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DAG Preview Generator                                       â”‚
â”‚  - Tasks: tools ET capabilities dÃ©tectÃ©s                    â”‚
â”‚  - dependsOn infÃ©rÃ© depuis variables + schemas              â”‚
â”‚  - Flag: preview: true (peut Ãªtre incomplet si dynamique)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
Validation permissions â†’ HIL si nÃ©cessaire â†’ ExÃ©cution
```

**Patterns Ã  dÃ©tecter:**

```typescript
// Pattern 1: Appel MCP tool simple
const result = await mcp.fs.read({ path: "config.json" });
// â†’ Task { type: "tool", tool: "fs:read", dependsOn: [] }

// Pattern 2: Appel capability
const summary = await capabilities.summarize({ text: content });
// â†’ Task { type: "capability", capability: "summarize", dependsOn: [] }

// Pattern 3: SÃ©quence avec validation schema
const config = await mcp.fs.read({ path: "config.json" });
const data = await mcp.json.parse({ json: config });
// â†’ fs:read.output.content â†’ json:parse.input.json âœ“ (via schemas)
// â†’ Task json:parse dependsOn: [fs:read]

// Pattern 4: ChaÃ®nage capability â†’ tool
const summary = await capabilities.summarize({ text: args.input });
const translated = await mcp.translate.text({ content: summary });
// â†’ summarize.output â†’ translate.input âœ“ (via workflow_pattern + tool_schema)

// Pattern 5: ParallÃ¨le
const [a, b] = await Promise.all([
  mcp.api.fetch({ url: urlA }),
  mcp.api.fetch({ url: urlB }),
]);
// â†’ Task api:fetch_1, Task api:fetch_2, pas de dependsOn entre eux

// Pattern 6: Conditionnel â†’ dÃ©tectÃ© comme appel potentiel
if (condition) {
  await mcp.db.write({ data });
}

// Pattern 7: Loop â†’ dÃ©tectÃ© comme appel potentiel
for (const item of items) {
  await mcp.process.run({ item });
}
```

**Gestion des Loops et Conditions - Approche minimaliste:**

On ne stocke PAS si c'est loop/conditionnel. Pourquoi ?

| Vue | Ce qu'on voit | Suffisant ? |
|-----|---------------|-------------|
| **HIL pre-approval** | "db:write peut Ãªtre appelÃ©" | âœ… Oui |
| **Invocation** | Traces rÃ©elles (N appels si loop) | âœ… Oui |
| **Definition** | Tool existe dans le graphe | âœ… Oui |

**Conclusion** : Le parsing dÃ©tecte TOUS les appels potentiels â†’ HIL approuve â†’ traces montrent la rÃ©alitÃ©.

**Acceptance Criteria:**

1. `CodeToDAGParser` class crÃ©Ã©e, **Ã©tend les patterns de SchemaInferrer**
2. RÃ©utilise le mÃªme `parse()` SWC et la mÃªme traversÃ©e AST que SchemaInferrer/PermissionInferrer
3. Method `parseToDAGPreview(code: string, db: PGliteClient)` â†’ `DAGPreview`:
   ```typescript
   interface DAGPreview {
     tasks: PreviewTask[];
     isComplete: boolean;        // false si code dynamique dÃ©tectÃ©
     dynamicSections: string[];  // ["line 15: conditional", "line 23: loop"]
     detectedTools: string[];    // Liste unique des tools
     detectedCapabilities: string[];  // Liste des capabilities appelÃ©es
     schemaValidation: SchemaValidationResult[];  // ChaÃ®nages validÃ©s
   }

   interface PreviewTask {
     id: string;
     type: "tool" | "capability";
     name: string;               // tool_id ou capability name
     dependsOn: string[];
     sourceLocation: { line: number; column: number };
   }

   // Note: Pas de `certainty` - on dÃ©tecte TOUS les appels potentiels.
   // Les traces POST-exec montrent ce qui s'est vraiment passÃ©.

   interface SchemaValidationResult {
     from: string;
     to: string;
     valid: boolean;
     matchedFields: string[];    // Quels champs outputâ†’input matchent
   }
   ```
4. DÃ©tection des appels:
   - `mcp.*.*()` â†’ lookup `tool_schema` pour validation
   - `capabilities.*()` â†’ lookup `workflow_pattern` pour validation
5. Validation des chaÃ®nages via schemas:
   - Variable assignment tracking (comme SchemaInferrer fait dÃ©jÃ )
   - Lookup schemas en DB pour valider outputâ†’input compatibility
6. DÃ©tection control flow (pour dependsOn):
   - `await` sÃ©quentiel â†’ dÃ©pendance
   - `Promise.all/allSettled` â†’ parallÃ©lisme (pas de dependsOn entre eux)
   - Traverser `if/else`, `for/while/map` pour trouver les appels Ã  l'intÃ©rieur
7. **IntÃ©gration avec `requiresValidation()`:**
   - Avant exÃ©cution, parse le code
   - Extraire `detectedTools` + `detectedCapabilities`
   - VÃ©rifier permissions via `getToolPermissionConfig()`
8. **IntÃ©gration avec HIL:**
   - Si tool avec `approvalMode: "hil"` dÃ©tectÃ© â†’ preview AVANT exÃ©cution
9. Tests: code avec tools â†’ dÃ©tection correcte
10. Tests: code avec capabilities â†’ dÃ©tection correcte
11. Tests: chaÃ®nage toolâ†’tool â†’ validation schema
12. Tests: chaÃ®nage capabilityâ†’tool â†’ validation schema
13. Tests: code avec if/loop â†’ tous les appels internes dÃ©tectÃ©s

**Files to Create:**
- `src/capabilities/code-to-dag-parser.ts` (~100-150 LOC, Ã©tend patterns existants)

**Files to Modify:**
- `src/capabilities/schema-inferrer.ts` - Extraire mÃ©thodes communes si besoin (~20 LOC)
- `src/mcp/handlers/code-execution-handler.ts` - IntÃ©grer preview (~30 LOC)

**Prerequisites:** Story 7.2b (SWC parsing - DONE)

**Estimation:** 2-3 jours

**Lien avec HIL Phase 4:**
Cette story est le **enabler** pour le vrai HIL per-task (Option B de la tech spec HIL).
Avec le DAG preview, on peut demander l'approbation AVANT d'exÃ©cuter, pas aprÃ¨s l'Ã©chec.

---

**Story 10.2: Result Tracing - Capture des RÃ©sultats d'ExÃ©cution** â­ FONDATION - START HERE

As a learning system, I want to capture the `result` of each tool and capability execution,
So that I can reconstruct data dependencies and create `provides` edges.

**Position dans l'Epic:**
- **VRAIE FONDATION** du Track A (Learning)
- Doit Ãªtre faite EN PREMIER (quick win : ~5-10 LOC)
- DÃ©bloque 10.3 (provides edges) et 10.4 (DAG reconstruction)

**Context:**
Actuellement on trace `args` mais pas `result`. Sans le result,
impossible de dÃ©tecter si "le rÃ©sultat de A est utilisÃ© dans les args de B".

**Acceptance Criteria:**

1. `tool_end` event inclut `result` dans `worker-bridge.ts` (~ligne 426):
   ```typescript
   this.traces.push({
     type: "tool_end",
     tool: toolId,
     traceId: id,
     ts: endTime,
     success: !isToolError,
     durationMs: durationMs,
     parentTraceId: parentTraceId,
     result: result,  // â† NOUVEAU
   });
   ```
2. `capability_end` event inclut `result` dans `code-generator.ts` (~ligne 104):
   ```typescript
   __trace({
     type: "capability_end",
     capability: "${name}",
     capabilityId: "${capability.id}",
     success: __capSuccess,
     error: __capError?.message,
     result: __capResult,  // â† NOUVEAU
   });
   ```
3. Types mis Ã  jour dans `src/dag/types.ts`:
   - `TraceEvent.tool_end.result?: unknown`
   - `TraceEvent.capability_end.result?: unknown`
4. `resultPreview` dÃ©jÃ  implÃ©mentÃ© (task_complete) - vÃ©rifier cohÃ©rence
5. Tests: exÃ©cuter code avec 2 tools â†’ vÃ©rifier result prÃ©sent dans les deux traces
6. Tests: result tronquÃ© si > 10KB (Ã©viter explosion mÃ©moire)

**Files to Modify:**
- `src/sandbox/worker-bridge.ts` (~5 LOC)
- `src/capabilities/code-generator.ts` (~3 LOC)
- `src/dag/types.ts` (~4 LOC)

**Prerequisites:** Story 7.1b (Worker RPC Bridge)

**Estimation:** 0.5-1 jour

---

**Story 10.3: Provides Edge Type - Data Flow Relationships**

As a graph learning system, I want a `provides` edge type that captures data flow between tools,
So that I can understand which tools can feed data to which other tools.

**Context:**
Le `provides` edge est pour la vue **Definition** (structure abstraite). Il indique que
les outputs de A peuvent alimenter les inputs de B, basÃ© sur les schemas.

**Edge Coverage Types:**
```typescript
type ProvidesCoverage =
  | "strict"     // R âŠ† O (tous les required inputs couverts)
  | "partial"    // R âˆ© O â‰  âˆ… (intersection non-vide)
  | "optional";  // Que des inputs optionnels couverts
```

**Acceptance Criteria:**

1. **Cleanup EdgeType** dans `edge-weights.ts`:
   - Ajouter `provides`
   - Retirer `alternative` (non utilisÃ©, pas dans ADR-050)
   - `EdgeType` final : `"dependency" | "contains" | "sequence" | "provides"`
2. Weight configurÃ©: `provides: 0.7` dans `EDGE_TYPE_WEIGHTS`
3. Interface `ProvidesEdge` dÃ©finie avec **schemas exposÃ©s**:
   ```typescript
   interface ProvidesEdge {
     from: string;              // Tool/capability provider
     to: string;                // Tool/capability consumer
     type: "provides";
     coverage: ProvidesCoverage;

     // Schemas exposÃ©s pour que l'IA sache remplir les args
     providerOutputSchema: JSONSchema;   // Ce que A produit
     consumerInputSchema: JSONSchema;    // Ce que B attend (required + optional)
     fieldMapping: Array<{               // Correspondances champ par champ
       fromField: string;       // e.g., "content"
       toField: string;         // e.g., "json"
       typeCompatible: boolean; // Types compatibles ?
     }>;
   }
   ```
4. `computeCoverage()` function implÃ©mentÃ©e:
   - Input: `providerOutputs: Set<string>`, `consumerInputs: { required, optional }`
   - Output: `ProvidesCoverage | null`
   - Retourne `null` si aucune intersection
5. `createProvidesEdges()` calculÃ© depuis les MCP tool schemas:
   - Pour chaque paire de tools, calculer coverage
   - CrÃ©er edge si coverage !== null
6. Stockage en DB: column `edge_type` dÃ©jÃ  TEXT, pas de migration
7. Tests: fs:read (output: content) â†’ json:parse (input: json) â†’ coverage = "strict"
8. Tests: json:parse â†’ http:post (need url, body) â†’ coverage = "partial"

**Files to Create:**
- `src/graphrag/provides-edge-calculator.ts` (~100 LOC)

**Files to Modify:**
- `src/graphrag/edge-weights.ts` (~5 LOC)
- `src/graphrag/types.ts` (~15 LOC)

**Prerequisites:** Story 10.2 (result tracing)

**Estimation:** 1-2 jours

---

**Story 10.4: DAG Reconstruction from Traces (POST-EXECUTION)**

As a learning system, I want to reconstruct a DAGStructure from code execution traces,
So that code-based workflows can be replayed as DAGs.

**Context:**
Phase 2 de la tech spec. Avec les traces enrichies (result), on peut dÃ©tecter les
dÃ©pendances data rÃ©elles: "si args de B contient result de A, alors B dÃ©pend de A".

**Algorithm:**
```typescript
function detectDataDependencies(traces: TraceEvent[]): string[] {
  for (const prevTrace of traces) {
    if (containsValue(currentTrace.args, prevTrace.result)) {
      dependsOn.push(prevTrace.traceId);
    }
  }
}

function containsValue(args, result): boolean {
  // Match exact ou partiel (champs extraits d'un objet)
}
```

**Acceptance Criteria:**

1. `DAGReconstructor` class crÃ©Ã©e (`src/graphrag/dag-reconstruction.ts`)
2. Method `reconstructFromTraces(traces: TraceEvent[])` â†’ `DAGStructure`
3. DÃ©tection dÃ©pendances data:
   - Match exact: `JSON.stringify(args).includes(JSON.stringify(result))`
   - Match partiel: champs individuels d'un objet result
4. DÃ©tection parallÃ©lisme via timestamps:
   - Si `endTime(A) < startTime(B)` â†’ sÃ©quence
   - Si timestamps overlap â†’ parallel (pas d'edge)

   > **BUG FIX:** Actuellement `execution-learning.ts` crÃ©e des edges `sequence`
   > basÃ©s uniquement sur l'**ordre dans l'array**, ce qui est incorrect pour les
   > exÃ©cutions parallÃ¨les. Le fix utilise **timestamps (ts + durationMs) EN DUO
   > avec l'ordre array**:
   > - `ts + durationMs` â†’ dÃ©termine si overlap (parallel) ou sÃ©quence
   > - `ordre array` â†’ dÃ©termine la direction de l'edge quand sÃ©quence
   >   (A avant B dans l'array ET pas d'overlap â†’ edge Aâ†’B)
5. `inferredStructure` ajoutÃ© Ã  `Capability`:
   ```typescript
   inferredStructure: {
     tools: string[];
     edges: Array<{ from, to, type }>;
     executionOrder: ExecutionOrder;  // â† NOUVEAU
   }
   ```
6. **`executionOrder` structure** - Capture sÃ©quence ET parallÃ©lisme en une structure nested:
   ```typescript
   // Type: (string | ExecutionOrder[])[]
   // Exemples:
   ["A", "B", "C"]           // SÃ©quence simple
   ["A", ["B", "C"], "D"]    // A â†’ (B || C) â†’ D (fan-out/fan-in)
   ["fs:read", ["fs:read", "http:get"], "json:parse"]  // Same tool 2x = position implicite
   ```
   - CalculÃ© UNE fois Ã  l'exÃ©cution (via ts + durationMs)
   - StockÃ© dans `dag_structure.execution_order` (JSONB)
   - Pas de recalcul Ã  chaque lecture
   - Same tool appelÃ© 2x â†’ position dans l'array = identifiant implicite, dÃ©tails dans traces
7. Method `buildExecutionOrder(traces: TraceEvent[])` â†’ `ExecutionOrder`:
   - Trier traces par `ts` (start time)
   - Calculer `endTime = ts + durationMs` pour chaque trace
   - Grouper les traces dont timestamps overlap â†’ array nested
   - Les autres â†’ string simple dans l'ordre
8. Tests: trace sÃ©quence Aâ†’Bâ†’C â†’ `executionOrder: ["A", "B", "C"]`
9. Tests: trace parallÃ¨le [A, B]â†’C â†’ `executionOrder: ["A", ["B", "C"]]` + edges Aâ†’C, Bâ†’C
10. Tests: trace avec result utilisÃ© partiellement (result.data.id) â†’ dÃ©pendance dÃ©tectÃ©e
11. Tests: same tool 2x sÃ©quentiel â†’ `["fs:read", "fs:read"]`, distinguÃ©s par position

**Files to Create:**
- `src/graphrag/dag-reconstruction.ts` (~200 LOC, inclut `buildExecutionOrder`)

**Files to Modify:**
- `src/capabilities/types.ts` (~30 LOC, ajout `ExecutionOrder` type)
- `src/capabilities/capability-store.ts` (~10 LOC, stockage `execution_order`)

**Prerequisites:** Story 10.2, Story 10.3

**Estimation:** 2-3 jours (inchangÃ©, `executionOrder` est ~0.5j inclus)

---

**Story 10.5: Unified Capability Model (Code, DAG, or Tool)**

As a capability storage system, I want capabilities to support code, DAG, and external tool sources,
So that any successful execution becomes a reusable capability, including delegation to orchestrators like Temporal.

**Context:**
Phase 3 de la tech spec. Actuellement les capabilities stockent uniquement du code.
On veut pouvoir stocker aussi des DAGStructures ET des rÃ©fÃ©rences Ã  des tools externes.

**Breaking Change:**
```typescript
// AVANT
interface Capability {
  code: string;
}

// APRÃˆS
interface Capability {
  source:
    | { type: "code"; code: string }
    | { type: "dag"; dagStructure: DAGStructure }
    | { type: "tool"; toolId: string; defaultArgs?: Record<string, unknown> };
}
```

**Exemple Tool Externe (Temporal):**
```typescript
// Capability apprise: pour "deploy to production", dÃ©lÃ©guer Ã  Temporal
{
  id: "cap_deploy_prod",
  intent: "deploy to production",
  source: {
    type: "tool",
    toolId: "temporal:startWorkflow",
    defaultArgs: { workflowId: "deploy-prod-v2" }
  },
  success_rate: 0.98
}
```

**Acceptance Criteria:**

1. `Capability.source` remplace `Capability.code`:
   ```typescript
   source:
     | { type: "code"; code: string }
     | { type: "dag"; dagStructure: DAGStructure }
     | { type: "tool"; toolId: string; defaultArgs?: Record<string, unknown> };
   ```
2. `Capability.inferredStructure` ajoutÃ© (from Story 10.4)
3. Migration DB: transformer `code` â†’ `source` JSON column
4. `CapabilityStore.saveCapability()` updated:
   - Accepte `source` au lieu de `code`
   - Appelle `DAGReconstructor` si type=code pour gÃ©nÃ©rer `inferredStructure`
5. `CapabilityStore.findById()` retourne le nouveau format
6. **DAG execution creates capability:**
   - AprÃ¨s succÃ¨s `execute_dag` â†’ crÃ©er capability `{ type: "dag" }`
   - Intent extrait du premier message ou paramÃ¨tre
7. Helper `getCapabilityCode()` pour backward compat:
   ```typescript
   function getCapabilityCode(cap: Capability): string | null {
     return cap.source.type === "code" ? cap.source.code : null;
   }
   ```
8. Tous les usages de `capability.code` migrÃ©s
9. Tests: sauvegarder capability code â†’ retrieve â†’ source.type === "code"
10. Tests: sauvegarder capability dag â†’ retrieve â†’ source.type === "dag"
11. Tests: sauvegarder capability tool â†’ retrieve â†’ source.type === "tool"
12. Tests: execute_dag success â†’ capability crÃ©Ã©e avec type=dag
13. Tests: capability type=tool â†’ exÃ©cution dÃ©lÃ¨gue au tool rÃ©fÃ©rencÃ©

**Files to Modify:**
- `src/capabilities/types.ts` (~30 LOC)
- `src/capabilities/capability-store.ts` (~50 LOC)
- `src/db/migrations/` - New migration (~40 LOC)
- All files using `capability.code` (grep and update)

**Prerequisites:** Story 10.4 (DAG reconstruction)

**Estimation:** 2-3 jours

---

**Story 10.6: pml_discover - Unified Discovery API**

As an AI agent, I want a single `pml_discover` tool to search both tools and capabilities,
So that I have a simplified API for finding what I need.

**Context:**
Phase 4 de la tech spec. Remplace `pml_search_tools`, `pml_search_capabilities`, `pml_find_capabilities`.

**API Design:**
```typescript
pml_discover({
  intent: "lire et parser un fichier JSON",
  filter?: {
    type?: "tool" | "capability" | "all",  // default: "all"
    minScore?: number,
  },
  limit?: number,  // default: 10
})

// Response
{
  results: [
    { type: "capability", id: "cap_123", score: 0.92, source: {...} },
    { type: "tool", id: "fs:read", score: 0.85 },
    { type: "capability", id: "cap_456", score: 0.78, source: {...} },
  ]
}
```

**Acceptance Criteria:**

1. Handler `pml_discover` crÃ©Ã© dans `src/mcp/handlers/`
2. Recherche unifiÃ©e:
   - Vector search sur tools (`tool_graph.intent_embedding`)
   - Vector search sur capabilities (`workflow_pattern.intent_embedding`)
   - Merge et sort par score
3. Input validation avec JSON Schema
4. Filter par type: `tool`, `capability`, ou `all`
5. Pagination: `limit` + `offset`
6. Response inclut pour chaque rÃ©sultat:
   - `type`: "tool" | "capability"
   - `id`: tool_id ou capability_id
   - `score`: similarity score
   - `source`: (pour capabilities) code ou dag preview
   - `toolSchemas`: (pour tools) input/output schemas
7. **DÃ©prÃ©ciation** des anciens tools:
   - `pml_search_tools` â†’ deprecated, redirige vers pml_discover
   - `pml_search_capabilities` â†’ deprecated
   - `pml_find_capabilities` â†’ deprecated
8. System prompt updated pour mentionner pml_discover
9. Tests: search "read file" â†’ retourne mix tools + capabilities
10. Tests: filter type="tool" â†’ que des tools
11. Tests: filter type="capability" â†’ que des capabilities

**Files to Create:**
- `src/mcp/handlers/discover-handler.ts` (~150 LOC)

**Files to Modify:**
- `src/mcp/gateway-server.ts` - Register new handler
- `src/mcp/handlers/search-handler.ts` - Add deprecation notice

**Prerequisites:** Story 10.5 (unified capability model)

**Estimation:** 2-3 jours

---

**Story 10.7: pml_execute - Unified Execution API**

As an AI agent, I want a single `pml_execute` tool that handles both DAG and code execution,
So that I have a simplified API and the system always learns from my executions.

**Context:**
Phase 5 de la tech spec. Remplace `pml_execute_dag` et `pml_execute_code`.

**API Design:**
```typescript
pml_execute({
  intent: "analyser ce fichier JSON",

  // Optionnel - si l'IA veut forcer une implÃ©mentation
  implementation?: {
    type: "code" | "dag",
    code?: string,
    dagStructure?: DAGStructure,
  }
})
```

**Execution Flow:**
```
Intent â†’ Implementation fournie?
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    YES           NO
    â”‚              â”‚
    â–¼              â–¼
  Execute    Search graphe
  provided   (tools + caps)
    â”‚              â”‚
    â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      Confiance       Confiance
    â”‚      haute           basse
    â”‚      â”‚               â”‚
    â”‚      â–¼               â–¼
    â”‚    EXECUTE        RETURN
    â”‚    (speculation)  suggestions
    â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                   â–¼
                            After success:
                            - Create/update capability
                            - Update graph edges
```

**Acceptance Criteria:**

1. Handler `pml_execute` crÃ©Ã© dans `src/mcp/handlers/`
2. Si `implementation` fournie â†’ exÃ©cute directement (code ou dag)
3. Si pas d'implementation:
   - Appelle `pml_discover` en interne
   - Si confidence > seuil â†’ exÃ©cute en speculation
   - Si confidence < seuil â†’ retourne suggestions
4. AprÃ¨s succÃ¨s (code ou dag):
   - CrÃ©e/update capability via `CapabilityStore`
   - Update graph edges
   - Trace structure (parallel, sÃ©quence)
5. Support `per_layer_validation` pour DAGs avec tools Ã©levÃ©s
6. **DÃ©prÃ©ciation** des anciens tools:
   - `pml_execute_dag` â†’ deprecated
   - `pml_execute_code` â†’ deprecated
7. Response unifiÃ©e:
   ```typescript
   {
     status: "success" | "approval_required" | "suggestions",
     result?: unknown,
     suggestions?: DiscoverResult[],
     capabilityId?: string,  // Si capability crÃ©Ã©e/updated
   }
   ```
8. Tests: execute avec intent seul â†’ recherche + suggestion/execution
9. Tests: execute avec implementation code â†’ exÃ©cute le code
10. Tests: execute avec implementation dag â†’ exÃ©cute le dag
11. Tests: succÃ¨s â†’ capability crÃ©Ã©e avec inferredStructure

**Files to Create:**
- `src/mcp/handlers/execute-handler.ts` (~200 LOC)

**Files to Modify:**
- `src/mcp/gateway-server.ts` - Register new handler
- `src/mcp/handlers/workflow-execution-handler.ts` - Add deprecation

**Prerequisites:** Story 10.6 (pml_discover)

**Estimation:** 3-5 jours

---

**Story 10.8: pml_get_task_result - Result Fetching Meta-Tool**

As an AI agent reviewing DAG execution results, I want to fetch the full result of a specific task,
So that I can make informed decisions when the preview isn't sufficient.

**Context:**
ComplÃ©mente le `resultPreview` (240 chars) dÃ©jÃ  implÃ©mentÃ©. Si l'IA a besoin de plus
de contexte pour dÃ©cider, elle peut demander le rÃ©sultat complet.

**API Design:**
```typescript
pml_get_task_result({
  workflow_id: string;
  task_id: string;
  offset?: number;      // Pour pagination (grands rÃ©sultats)
  limit?: number;       // Longueur max Ã  retourner
  format?: "raw" | "pretty";  // Formatage JSON
})
```

**Acceptance Criteria:**

1. Handler `pml_get_task_result` crÃ©Ã©
2. Stockage des rÃ©sultats complets:
   - Nouveau champ `fullResult` dans execution traces
   - Ou table sÃ©parÃ©e `task_results` (workflow_id, task_id, result)
3. RÃ©cupÃ©ration avec pagination:
   - `offset` pour commencer Ã  un point
   - `limit` pour limiter la taille
4. Formatage:
   - `raw`: JSON tel quel
   - `pretty`: JSON.stringify avec indentation
5. TTL sur les rÃ©sultats stockÃ©s (configurable, default 1h)
6. Tests: execute dag â†’ get_task_result â†’ retourne rÃ©sultat complet
7. Tests: pagination fonctionne sur grand rÃ©sultat
8. Tests: rÃ©sultat expirÃ© â†’ erreur appropriÃ©e

**Files to Create:**
- `src/mcp/handlers/task-result-handler.ts` (~80 LOC)

**Files to Modify:**
- `src/mcp/gateway-server.ts` - Register handler
- `src/dag/controlled-executor.ts` - Store full results

**Prerequisites:** Story 10.7 (pml_execute)

**Estimation:** 1-2 jours

---

**Story 10.9: Definition vs Invocation Views (Cytoscape)**

As a dashboard user, I want to toggle between Definition and Invocation views,
So that I can see either the abstract workflow structure or the actual execution.

**Context:**
Phase 6 de la tech spec. La vue Definition montre les nÅ“uds dÃ©dupliquÃ©s (chaque tool une fois),
la vue Invocation montre chaque appel rÃ©el avec timestamps.

**View Differences:**

| Vue | NÅ“uds | Edges | Exemple |
|-----|-------|-------|---------|
| **Definition** | DÃ©dupliquÃ©s | dependency, provides, contains | `fs:read` (1 nÅ“ud) |
| **Invocation** | Par appel | sequence, contains | `fs:read_1`, `fs:read_2` |

**Acceptance Criteria:**

1. Toggle button dans dashboard: `[Definition] [Invocation]`
2. **Vue Definition:**
   - NÅ“uds dÃ©dupliquÃ©s par tool/capability type
   - Edges: `dependency`, `provides`, `contains`, `alternative`
   - Layout optimisÃ© pour structure
3. **Vue Invocation:**
   - Un nÅ“ud par appel rÃ©el (suffixe `_1`, `_2`, etc.)
   - Timestamps affichÃ©s sur les nÅ“uds
   - Edges: `sequence` (basÃ© sur ordre temporel)
   - Parallel visible par timestamps qui overlap
4. Table `capability_invocations` crÃ©Ã©e:
   ```typescript
   {
     id: string;
     capabilityId: string;
     timestamp: Date;
     arguments: Record<string, unknown>;
     results: TaskResult[];
     success: boolean;
     durationMs: number;
   }
   ```
5. API endpoint `/api/invocations/:capabilityId`
6. Cytoscape layout adaptÃ© par vue:
   - Definition: dagre/hierarchical
   - Invocation: timeline/temporal
7. Tests: mÃªme capability, 3 exÃ©cutions â†’ Definition (1 nÅ“ud) vs Invocation (3 nÅ“uds)
8. Tests: exÃ©cution avec parallÃ©lisme visible en Invocation view

**Files to Create:**
- `src/db/migrations/XXX_capability_invocations.ts` (~40 LOC)
- `src/web/islands/DefinitionInvocationToggle.tsx` (~80 LOC)

**Files to Modify:**
- `src/web/routes/dashboard.tsx` - Add toggle
- `src/visualization/hypergraph-builder.ts` - Support both views

**Prerequisites:** Story 10.8, Epic 8 (Hypergraph visualization)

**Estimation:** 2-3 jours

---

**Story 10.10: Dry Run Mode with Mocks (Connector Debugging)** ğŸ”® FUTURE - Post-MVP

As a workflow developer, I want to dry-run code with mocked MCP responses,
So that I can debug and validate complex workflows without real side effects, especially for connector MCPs.

**Position dans l'Epic:**
- **NON NÃ‰CESSAIRE pour le MVP** - Le parsing statique (10.1) suffit pour HIL/permissions
- Utile uniquement pour des cas avancÃ©s : estimation coÃ»t API, debug complexe, test connecteurs
- Ã€ implÃ©menter SI et QUAND le besoin se prÃ©sente

**Pourquoi le parsing statique suffit pour HIL:**
| Question HIL | Parsing statique | Dry run |
|--------------|------------------|---------|
| "Quels tools PEUVENT Ãªtre appelÃ©s ?" | âœ… DÃ©tectÃ© | Idem |
| "Quelles permissions nÃ©cessaires ?" | âœ… DÃ©tectÃ© | Idem |
| "Y a-t-il des side effects ?" | âœ… DÃ©tectÃ© | Idem |
| "Combien de fois exactement ?" | âŒ Inconnu | âœ… Avec mocks |

â†’ Les 3 premiÃ¨res questions suffisent pour HIL. La 4Ã¨me est un nice-to-have.

**Context:**
Le parsing statique (Story 10.1) suffit pour HIL/permissions, mais pour le **debugging** de workflows
complexes utilisant des MCP connecteurs (APIs externes, bases de donnÃ©es), on veut pouvoir :
- Voir exactement ce qui VA se passer avant de le faire
- Tester sans appeler les vraies APIs (coÃ»t, rate limits, effets de bord)
- Valider les donnÃ©es intermÃ©diaires

**Use Cases spÃ©cifiques:**

| Use Case | Parsing Statique | Dry Run |
|----------|------------------|---------|
| HIL permissions | âœ… Suffit | Overkill |
| Estimation coÃ»t API | âŒ Approximatif | âœ… Exact (N appels) |
| Debug data flow | âŒ Types only | âœ… Vraies valeurs mockÃ©es |
| Test workflow sans side effects | âŒ Impossible | âœ… Full simulation |
| Validation avant prod | âŒ Statique | âœ… Comportement rÃ©el |

**Quand utiliser Dry Run vs Parsing:**
- **Parsing (10.1)** : Validation rapide, HIL, permissions â†’ **toujours**
- **Dry Run (10.10)** : Debugging, estimation, test connecteurs â†’ **opt-in depuis dashboard**

**Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dashboard: "Test Workflow" button                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mock MCP Proxy                                              â”‚
â”‚  - Intercepte tous les appels mcp.*.*()                     â”‚
â”‚  - Retourne mock responses basÃ©es sur output schemas        â”‚
â”‚  - Log chaque appel avec timestamp, args, mock result       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sandbox Execution (mode: dry_run)                          â”‚
â”‚  - ExÃ©cute le vrai code                                     â”‚
â”‚  - Mais avec mcp = mockMcpProxy                             â”‚
â”‚  - Capture le flow rÃ©el d'exÃ©cution                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dry Run Report                                              â”‚
â”‚  - Liste exacte des appels qui seraient faits              â”‚
â”‚  - DonnÃ©es mockÃ©es Ã  chaque Ã©tape                          â”‚
â”‚  - Warnings si comportement dÃ©pend des donnÃ©es rÃ©elles     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Mock Response Generation:**
```typescript
// GÃ©nÃ¨re mock response depuis le schema MCP
function generateMockResponse(toolSchema: ToolSchema): unknown {
  // Utilise le output_schema pour gÃ©nÃ©rer des donnÃ©es rÃ©alistes
  // Ex: { type: "string" } â†’ "mock_string_value"
  // Ex: { type: "object", properties: { id: { type: "number" } } } â†’ { id: 12345 }
}

// Pour les connecteurs connus, on peut avoir des mocks plus intelligents
const CONNECTOR_MOCKS: Record<string, MockGenerator> = {
  "github:api": generateGitHubMock,      // Retourne des PRs, issues mockÃ©s
  "slack:post": generateSlackMock,       // Retourne { ok: true, ts: "..." }
  "postgres:query": generatePostgresMock, // Retourne rows mockÃ©es
};
```

**Acceptance Criteria:**

1. `MockMcpProxy` class crÃ©Ã©e:
   ```typescript
   interface MockMcpProxy {
     onToolCall(server: string, tool: string, args: unknown): Promise<unknown>;
     getCapturedCalls(): CapturedCall[];
     reset(): void;
   }

   interface CapturedCall {
     server: string;
     tool: string;
     args: unknown;
     mockResponse: unknown;
     timestamp: number;
     durationMs: number;
   }
   ```
2. GÃ©nÃ©ration de mock responses depuis `tool_schema.output_schema`
3. Support pour mocks custom par connecteur (GitHub, Slack, DB, etc.)
4. IntÃ©gration sandbox: `execute(code, { mode: "dry_run" })`
5. `DryRunReport` gÃ©nÃ©rÃ© aprÃ¨s exÃ©cution:
   ```typescript
   interface DryRunReport {
     capturedCalls: CapturedCall[];
     executionTimeMs: number;
     warnings: string[];           // "Response depends on real data"
     estimatedApiCalls: number;
     estimatedCost?: number;       // Si on a des infos de pricing
   }
   ```
6. UI Dashboard: bouton "Test Workflow" sur les capabilities
7. UI Dashboard: affichage du DryRunReport (timeline des appels)
8. Tests: dry run avec 3 tools sÃ©quentiels
9. Tests: dry run avec boucle â†’ capture tous les appels
10. Tests: mock custom pour connecteur GitHub

**Files to Create:**
- `src/sandbox/mock-mcp-proxy.ts` (~150 LOC)
- `src/sandbox/mock-generators.ts` (~100 LOC)
- `src/web/islands/DryRunReport.tsx` (~120 LOC)

**Files to Modify:**
- `src/sandbox/worker-bridge.ts` - Support mode dry_run (~30 LOC)
- `src/web/routes/dashboard.tsx` - Add "Test Workflow" button (~20 LOC)

**Prerequisites:** Story 10.7 (pml_execute), Epic 8 (Dashboard)

**Estimation:** 3-4 jours

**Note:** Cette story est **optionnelle pour le MVP**. Le parsing statique (10.1) suffit
pour le HIL. Le dry run est un nice-to-have pour le debugging avancÃ© de workflows
avec des MCP connecteurs externes.

---

### Epic 10 Breaking Changes Summary

| Phase | Change | Breaking? | Impact |
|-------|--------|-----------|--------|
| 1 | `result` in traces | âŒ No | Additive |
| 2 | `provides` EdgeType | âŒ No | Additive |
| 3 | Capability `source: code \| dag` | âš ï¸ **Yes** | Schema change |
| 4 | Deprecate `pml_search_*` | âš ï¸ **Yes** | MCP APIs |
| 5 | Deprecate `pml_execute_*` | âš ï¸ **Yes** | MCP APIs |
| 6 | New table `capability_invocations` | âŒ No | Additive |

**Migration Strategy:** Breaking changes in Phase 3-5. No transition period - clean cut.

---

### Epic 10 Dependencies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DEUX TRACKS PARALLÃˆLES                                          â”‚
â”‚                                                                  â”‚
â”‚  Track A (Learning - POST-exec):    Track B (HIL - PRE-exec):   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚                                                                  â”‚
â”‚  â˜… Story 10.2 (result tracing)      Story 10.1 (static analysis)â”‚
â”‚        â”‚  â† VRAIE FONDATION              â”‚                      â”‚
â”‚        â”‚                                 â”‚  (indÃ©pendant)       â”‚
â”‚        â–¼                                 â”‚                      â”‚
â”‚  Story 10.3 (provides edge)              â”‚                      â”‚
â”‚        â”‚                                 â”‚                      â”‚
â”‚        â–¼                                 â”‚                      â”‚
â”‚  Story 10.4 (DAG reconstruction)         â”‚                      â”‚
â”‚        â”‚                                 â”‚                      â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                     â–¼                                            â”‚
â”‚              Story 10.5 (unified capability)                     â”‚
â”‚                     â”‚  â† Merge 10.1 + 10.4                      â”‚
â”‚                     â–¼                                            â”‚
â”‚              Story 10.6 (pml_discover)                           â”‚
â”‚                     â”‚                                            â”‚
â”‚                     â–¼                                            â”‚
â”‚              Story 10.7 (pml_execute) â† IntÃ¨gre 10.1 pour HIL   â”‚
â”‚                     â”‚                                            â”‚
â”‚                     â–¼                                            â”‚
â”‚              Story 10.8 (pml_get_task_result)                    â”‚
â”‚                     â”‚                                            â”‚
â”‚                     â–¼                                            â”‚
â”‚              Story 10.9 (Definition/Invocation views)            â”‚
â”‚                     â”‚                                            â”‚
â”‚                     â–¼                                            â”‚
â”‚              Story 10.10 (Dry Run) â† Optional                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ordre d'implÃ©mentation recommandÃ©:**

| Ordre | Story | Justification |
|-------|-------|---------------|
| 1 | **10.2** Result Tracing | Vraie fondation - sans `result` dans traces, rien ne marche |
| 2 | **10.3** Provides Edge | Utilise les traces enrichies |
| 3 | **10.4** DAG Reconstruction | Reconstruction POST-exec |
| âˆ¥ | **10.1** Static Analysis | **En parallÃ¨le** avec 10.2-10.4, ou aprÃ¨s |
| 4 | **10.5** Unified Capability | Merge 10.1 (PRE) + 10.4 (POST) |
| 5 | **10.6** pml_discover | API unifiÃ©e de dÃ©couverte |
| 6 | **10.7** pml_execute | API unifiÃ©e d'exÃ©cution |
| 7 | **10.8** pml_get_task_result | ComplÃ©ment pour AIL |
| 8 | **10.9** Views | UI Cytoscape |
| 9 | **10.10** Dry Run | Optional, pour debug connecteurs |

**Note sur Story 10.1 (Static Analysis):**
- N'est PAS un prÃ©requis pour 10.2-10.4 (contrairement Ã  ce qui Ã©tait indiquÃ© avant)
- Peut Ãªtre fait en parallÃ¨le ou aprÃ¨s le Track A
- Devient nÃ©cessaire pour 10.5 (unified capability) et 10.7 (pml_execute avec HIL)

**External Dependencies:**
- Epic 7 Story 7.1b (Worker RPC Bridge)
- HIL Phase 2 (per_layer_validation, resultPreview)
- Epic 8 (Hypergraph visualization for Story 10.9)

---

### Epic 10 FR Coverage

| FR | Description | Story |
|----|-------------|-------|
| **FR1** | **DAG Preview prÃ©-exÃ©cution (parsing statique)** | **10.1** |
| **FR1b** | **Validation permissions avant exÃ©cution** | **10.1** |
| **FR1c** | **HIL pre-execution approval flow** | **10.1** |
| FR2 | Tracer `result` des tools et capabilities | 10.2 |
| FR3 | Edge type `provides` avec coverage | 10.3 |
| FR4 | Reconstruction DAG depuis traces code | 10.4 |
| FR5 | Capability unifiÃ©e (code OU dag) | 10.5 |
| FR6 | API `pml_discover` unifiÃ©e | 10.6 |
| FR7 | API `pml_execute` unifiÃ©e | 10.7 |
| FR8 | `pml_get_task_result` pour rÃ©sultats complets | 10.8 |
| FR9 | Vue Definition vs Invocation | 10.9 |
| FR10 | DÃ©prÃ©ciation anciennes APIs | 10.6, 10.7 |
| FR11 | Learning automatique aprÃ¨s succÃ¨s | 10.7 |
| FR12 | Dry Run avec Mocks pour connecteurs (optional) | 10.10 |

### Epic 10 â†’ PRD FR Traceability Matrix

> **Note:** Cette table lie les FRs locaux de l'Epic 10 aux FRs globaux du PRD pour assurer la traÃ§abilitÃ©.

| Epic 10 FR | PRD FR | PRD Requirement | Relation |
|------------|--------|-----------------|----------|
| FR1 | FR005 | Analyser dÃ©pendances input/output pour construire graphe DAG | **Implements** |
| FR1 | FR006 | Identifier automatiquement tools parallÃ¨les vs sÃ©quentiels | **Implements** |
| FR1b | FR017 | ExÃ©cution TypeScript dans Deno sandbox isolÃ© | **Extends** |
| FR1c | FR018 | Branches DAG safe-to-fail (resilient workflows) | **Extends** |
| FR2 | FR014 | Tracker mÃ©triques contexte et latence (opt-in) | **Extends** |
| FR2 | FR015 | GÃ©nÃ©rer logs structurÃ©s pour debugging | **Extends** |
| FR3 | FR005 | Analyser dÃ©pendances input/output pour construire graphe DAG | **Extends** |
| FR4 | FR005 | Analyser dÃ©pendances input/output pour construire graphe DAG | **Implements** |
| FR4 | FR006 | Identifier automatiquement tools parallÃ¨les vs sÃ©quentiels | **Implements** |
| FR5 | FR017 | ExÃ©cution TypeScript dans Deno sandbox isolÃ© | **Extends** |
| FR5 | FR019 | Injecter MCP tools dans contexte sandbox via vector search | **Extends** |
| FR6 | FR002 | Recherche sÃ©mantique pour identifier top-k tools pertinents | **Unifies** |
| FR6 | FR003 | Charger tool schemas on-demand pour tools pertinents | **Unifies** |
| FR7 | FR007 | ExÃ©cuter simultanÃ©ment branches indÃ©pendantes du DAG | **Unifies** |
| FR7 | FR017 | ExÃ©cution TypeScript dans Deno sandbox isolÃ© | **Unifies** |
| FR8 | FR008 | Streamer rÃ©sultats via SSE pour feedback progressif | **Extends** |
| FR9 | FR014 | Tracker mÃ©triques contexte et latence (opt-in) | **Extends** |
| FR10 | - | N/A (internal cleanup) | **Internal** |
| FR11 | - | N/A (Epic 7 extension) | **Epic 7** |
| FR12 | FR017 | ExÃ©cution TypeScript dans Deno sandbox isolÃ© | **Optional** |

**Legend:**
- **Implements**: ImplÃ©mentation directe du FR PRD
- **Extends**: Ã‰tend/amÃ©liore un FR PRD existant
- **Unifies**: Unifie plusieurs FRs PRD en une seule API
- **Internal**: Nettoyage interne sans FR PRD correspondant
- **Optional**: Feature optionnelle

---

### Epic 10 Estimation Summary

| Ordre | Story | Description | Effort | Cumulative |
|-------|-------|-------------|--------|------------|
| 1 | **10.2** | **Result Tracing** â­ FONDATION | **0.5-1j** | **1j** |
| 2 | 10.3 | Provides Edge | 1-2j | 3j |
| 3 | 10.4 | DAG Reconstruction (POST-exec) | 2-3j | 6j |
| âˆ¥ | 10.1 | Static Analysis (PRE-exec) ~100-150 LOC | 2-3j | âˆ¥ |
| 4 | 10.5 | Unified Capability | 2-3j | 9j |
| 5 | 10.6 | pml_discover | 2-3j | 12j |
| 6 | 10.7 | pml_execute | 3-5j | 16j |
| 7 | 10.8 | pml_get_task_result | 1-2j | 18j |
| 8 | 10.9 | Definition/Invocation | 2-3j | 21j |
| 9 | 10.10 | Dry Run + Mocks (optional) | 3-4j | 25j |

**Total MVP (10.1-10.9): ~3-4 semaines**
**Total avec 10.10: ~4-5 semaines**

**ğŸ¯ Story 10.2 (Result Tracing) est la vraie fondation car:**
1. Sans `result` dans les traces, impossible de dÃ©tecter les dÃ©pendances data
2. DÃ©bloque 10.3 (provides edges) et 10.4 (DAG reconstruction)
3. Quick win : ~5-10 LOC Ã  modifier dans worker-bridge.ts et code-generator.ts

**ğŸ“ Story 10.1 (Static Analysis) est importante mais pas bloquante:**
1. Peut Ãªtre faite en parallÃ¨le avec Track A (10.2 â†’ 10.3 â†’ 10.4)
2. RÃ©utilise l'existant : SchemaInferrer (726 LOC), PermissionInferrer (510 LOC)
3. Devient nÃ©cessaire pour 10.5 (unified capability) et 10.7 (HIL pre-execution)

**ğŸ“‹ Story 10.10 (Dry Run) est optionnelle car:**
- Le parsing statique (10.1) suffit pour HIL/permissions
- Dry run = nice-to-have pour debugging de workflows avec connecteurs
- Utile quand on a des MCP APIs externes (GitHub, Slack, DB, etc.)
