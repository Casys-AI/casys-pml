## Epic 10: DAG Capability Learning & Unified APIs

> **Tech-Spec:** [tech-spec-dag-capability-learning.md](./tech-specs/tech-spec-dag-capability-learning.md)
> **Status:** Proposed (2025-12-17)
> **Author:** Erwan + Claude
> **Depends on:** Epic 7 (Emergent Capabilities), HIL Phase 2 (Permission Escalation)

**Expanded Goal (2-3 sentences):**

Unifier les deux modÃ¨les d'exÃ©cution (DAG explicite et Code libre) en un systÃ¨me d'apprentissage cohÃ©rent oÃ¹ **tout passe par les mÃªmes mÃ©canismes**. ImplÃ©menter la reconstruction de DAG depuis les traces de code, permettant au systÃ¨me d'apprendre des workflows qu'il soit exprimÃ© en DAG ou en code TypeScript. Simplifier les APIs en deux points d'entrÃ©e : `pml_discover` (exploration intelligente) et `pml_execute` (exÃ©cution unifiÃ©e).

**ProblÃ¨mes RÃ©solus:**

| ProblÃ¨me | Solution |
|----------|----------|
| Parallel tracking - pas d'edges crÃ©Ã©s | DÃ©tection via timestamps `ts` + `durationMs` |
| DAG â†’ Capability - pas de gÃ©nÃ©ration | Capability unifiÃ©e `source: code \| dag` |
| Edge types confus (sequence vs dependency) | Clarification: Definition view vs Invocation view |
| Manque de `provides` edge | Nouveau type pour data flow (strict/partial/optional) |
| APIs fragmentÃ©es (5 tools) | Unification: `pml_discover` + `pml_execute` |

**Value Delivery:**

- âœ… **Apprentissage unifiÃ©** - Code ET DAG crÃ©ent des capabilities
- âœ… **Reconstruction DAG** - Le code peut Ãªtre "rejouÃ©" comme DAG
- âœ… **APIs simplifiÃ©es** - 2 tools au lieu de 5 pour l'IA
- âœ… **Preview intelligent** - `resultPreview` + `pml_get_task_result` pour AIL
- âœ… **Provides edges** - ChaÃ®nage data explicite entre tools

**Architecture UnifiÃ©e:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  pml_execute({ intent: "..." })                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Implementation      â”‚     â”‚ Recherche GraphRAG   â”‚            â”‚
â”‚  â”‚ fournie par l'IA?   â”‚ NO  â”‚ - Tools matching     â”‚            â”‚
â”‚  â”‚                     â”‚â”€â”€â”€â”€â–¶â”‚ - Capabilities       â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚            â”‚ YES                        â”‚                        â”‚
â”‚            â–¼                            â–¼                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  EXECUTION (Sandbox)                                 â”‚        â”‚
â”‚  â”‚  - Traces: tool_start/end + result                  â”‚        â”‚
â”‚  â”‚  - Timestamps pour parallel detection               â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  LEARNING                                            â”‚        â”‚
â”‚  â”‚  - Reconstruction DAG depuis traces                  â”‚        â”‚
â”‚  â”‚  - CrÃ©ation/update Capability                        â”‚        â”‚
â”‚  â”‚  - Edges: provides (definition) + sequence (invoc)   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Estimation:** 10 stories (9 MVP + 1 optional), ~3-4 semaines MVP

---

### Story Breakdown - Epic 10

**Story 10.1: Static Code Analysis - DAG Preview (PRE-EXECUTION)** â­ FIRST

As an execution system, I want to parse code statically to generate a DAG preview BEFORE execution,
So that I can validate permissions, detect tools, and enable proper HIL/AIL approval flows.

**Context:**
C'est le **chaÃ®non manquant** entre le code et la validation par layer. Sans parsing statique :
- On ne peut pas savoir quels tools seront appelÃ©s avant d'exÃ©cuter
- L'AIL/HIL doit attendre l'Ã©chec au lieu de prÃ©venir
- `per_layer_validation` ne peut pas calculer `requiresValidation()` correctement

**DiffÃ©rence avec Story 10.4 (Reconstruction POST-exec):**

| Aspect | 10.1 Static (PRE) | 10.4 Traces (POST) |
|--------|--------------------|--------------------|
| **Quand** | Avant exÃ©cution | AprÃ¨s exÃ©cution |
| **Input** | Code source (AST) | Traces d'exÃ©cution |
| **PrÃ©cision** | Approximatif (code dynamique) | Exact (ce qui s'est passÃ©) |
| **Use case** | Validation, HIL preview | Learning, replay |

**RÃ©utilisation de l'existant (pas une rÃ©Ã©criture !):**

On a DÃ‰JÃ€ tout le pipeline SWC :
- `SchemaInferrer` (726 LOC, 19 tests) â†’ parse AST, trouve `args.xxx`, infÃ¨re types
- `PermissionInferrer` (510 LOC) â†’ parse AST, dÃ©tecte patterns dangereux
- `tool_schema` table â†’ schemas input/output des MCP tools
- `workflow_pattern` table â†’ schemas des capabilities

**Story 10.1 = Extension de ~100-150 LOC**, pas 250 LOC from scratch.

**Architecture:**
```
Code TypeScript
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SWC AST Parser (RÃ‰UTILISE SchemaInferrer/PermissionInferrer)â”‚
â”‚  - MÃªme parse(), mÃªme traversÃ©e AST                          â”‚
â”‚  - Extension: chercher `mcp.*.*()` ET `capabilities.*()`    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Call Detector (Tools + Capabilities)                        â”‚
â”‚  - `mcp.server.tool()` â†’ lookup tool_schema                 â”‚
â”‚  - `capabilities.name()` â†’ lookup workflow_pattern           â”‚
â”‚  - `await` â†’ dÃ©pendance sÃ©quentielle                        â”‚
â”‚  - `Promise.all()` â†’ parallÃ©lisme                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Schema Validation (provides edges)                          â”‚
â”‚  - tool A output â†’ tool B input : types compatibles ?       â”‚
â”‚  - capability output â†’ tool input : chaÃ®nage valide ?       â”‚
â”‚  - Utilise les schemas qu'on a DÃ‰JÃ€ en DB                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DAG Preview Generator                                       â”‚
â”‚  - Tasks: tools ET capabilities dÃ©tectÃ©s                    â”‚
â”‚  - dependsOn infÃ©rÃ© depuis variables + schemas              â”‚
â”‚  - Flag: preview: true (peut Ãªtre incomplet si dynamique)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
Validation permissions â†’ HIL si nÃ©cessaire â†’ ExÃ©cution
```

**Patterns Ã  dÃ©tecter:**

```typescript
// Pattern 1: Appel MCP tool simple
const result = await mcp.fs.read({ path: "config.json" });
// â†’ Task { type: "tool", tool: "fs:read", dependsOn: [] }

// Pattern 2: Appel capability
const summary = await capabilities.summarize({ text: content });
// â†’ Task { type: "capability", capability: "summarize", dependsOn: [] }

// Pattern 3: SÃ©quence avec validation schema
const config = await mcp.fs.read({ path: "config.json" });
const data = await mcp.json.parse({ json: config });
// â†’ fs:read.output.content â†’ json:parse.input.json âœ“ (via schemas)
// â†’ Task json:parse dependsOn: [fs:read]

// Pattern 4: ChaÃ®nage capability â†’ tool
const summary = await capabilities.summarize({ text: args.input });
const translated = await mcp.translate.text({ content: summary });
// â†’ summarize.output â†’ translate.input âœ“ (via workflow_pattern + tool_schema)

// Pattern 5: ParallÃ¨le
const [a, b] = await Promise.all([
  mcp.api.fetch({ url: urlA }),
  mcp.api.fetch({ url: urlB }),
]);
// â†’ Task api:fetch_1, Task api:fetch_2, pas de dependsOn entre eux

// Pattern 6: Conditionnel â†’ certainty: "conditional"
if (condition) {
  await mcp.db.write({ data });
}

// Pattern 7: Loop â†’ certainty: "loop"
for (const item of items) {
  await mcp.process.run({ item });
}
```

**Acceptance Criteria:**

1. `CodeToDAGParser` class crÃ©Ã©e, **Ã©tend les patterns de SchemaInferrer**
2. RÃ©utilise le mÃªme `parse()` SWC et la mÃªme traversÃ©e AST que SchemaInferrer/PermissionInferrer
3. Method `parseToDAGPreview(code: string, db: PGliteClient)` â†’ `DAGPreview`:
   ```typescript
   interface DAGPreview {
     tasks: PreviewTask[];
     isComplete: boolean;        // false si code dynamique dÃ©tectÃ©
     dynamicSections: string[];  // ["line 15: conditional", "line 23: loop"]
     detectedTools: string[];    // Liste unique des tools
     detectedCapabilities: string[];  // Liste des capabilities appelÃ©es
     schemaValidation: SchemaValidationResult[];  // ChaÃ®nages validÃ©s
   }

   interface PreviewTask {
     id: string;
     type: "tool" | "capability";
     name: string;               // tool_id ou capability name
     dependsOn: string[];
     certainty: "definite" | "conditional" | "loop";
     sourceLocation: { line: number; column: number };
   }

   interface SchemaValidationResult {
     from: string;
     to: string;
     valid: boolean;
     matchedFields: string[];    // Quels champs outputâ†’input matchent
   }
   ```
4. DÃ©tection des appels:
   - `mcp.*.*()` â†’ lookup `tool_schema` pour validation
   - `capabilities.*()` â†’ lookup `workflow_pattern` pour validation
5. Validation des chaÃ®nages via schemas:
   - Variable assignment tracking (comme SchemaInferrer fait dÃ©jÃ )
   - Lookup schemas en DB pour valider outputâ†’input compatibility
6. DÃ©tection control flow:
   - `await` â†’ sÃ©quence
   - `Promise.all/allSettled` â†’ parallÃ©lisme
   - `if/else` â†’ conditional
   - `for/while/map` â†’ loop
7. **IntÃ©gration avec `requiresValidation()`:**
   - Avant exÃ©cution, parse le code
   - Extraire `detectedTools` + `detectedCapabilities`
   - VÃ©rifier permissions via `getToolPermissionConfig()`
8. **IntÃ©gration avec HIL:**
   - Si tool avec `approvalMode: "hil"` dÃ©tectÃ© â†’ preview AVANT exÃ©cution
9. Tests: code avec tools â†’ dÃ©tection correcte
10. Tests: code avec capabilities â†’ dÃ©tection correcte
11. Tests: chaÃ®nage toolâ†’tool â†’ validation schema
12. Tests: chaÃ®nage capabilityâ†’tool â†’ validation schema
13. Tests: code dynamique â†’ flags appropriÃ©s

**Files to Create:**
- `src/capabilities/code-to-dag-parser.ts` (~100-150 LOC, Ã©tend patterns existants)

**Files to Modify:**
- `src/capabilities/schema-inferrer.ts` - Extraire mÃ©thodes communes si besoin (~20 LOC)
- `src/mcp/handlers/code-execution-handler.ts` - IntÃ©grer preview (~30 LOC)

**Prerequisites:** Story 7.2b (SWC parsing - DONE)

**Estimation:** 2-3 jours

**Lien avec HIL Phase 4:**
Cette story est le **enabler** pour le vrai HIL per-task (Option B de la tech spec HIL).
Avec le DAG preview, on peut demander l'approbation AVANT d'exÃ©cuter, pas aprÃ¨s l'Ã©chec.

---

**Story 10.2: Result Tracing - Capture des RÃ©sultats d'ExÃ©cution**

As a learning system, I want to capture the `result` of each tool and capability execution,
So that I can reconstruct data dependencies and create `provides` edges.

**Context:**
Actuellement on trace `args` mais pas `result`. Sans le result,
impossible de dÃ©tecter si "le rÃ©sultat de A est utilisÃ© dans les args de B".

**Acceptance Criteria:**

1. `tool_end` event inclut `result` dans `worker-bridge.ts` (~ligne 426):
   ```typescript
   this.traces.push({
     type: "tool_end",
     tool: toolId,
     traceId: id,
     ts: endTime,
     success: !isToolError,
     durationMs: durationMs,
     parentTraceId: parentTraceId,
     result: result,  // â† NOUVEAU
   });
   ```
2. `capability_end` event inclut `result` dans `code-generator.ts` (~ligne 104):
   ```typescript
   __trace({
     type: "capability_end",
     capability: "${name}",
     capabilityId: "${capability.id}",
     success: __capSuccess,
     error: __capError?.message,
     result: __capResult,  // â† NOUVEAU
   });
   ```
3. Types mis Ã  jour dans `src/dag/types.ts`:
   - `TraceEvent.tool_end.result?: unknown`
   - `TraceEvent.capability_end.result?: unknown`
4. `resultPreview` dÃ©jÃ  implÃ©mentÃ© (task_complete) - vÃ©rifier cohÃ©rence
5. Tests: exÃ©cuter code avec 2 tools â†’ vÃ©rifier result prÃ©sent dans les deux traces
6. Tests: result tronquÃ© si > 10KB (Ã©viter explosion mÃ©moire)

**Files to Modify:**
- `src/sandbox/worker-bridge.ts` (~5 LOC)
- `src/capabilities/code-generator.ts` (~3 LOC)
- `src/dag/types.ts` (~4 LOC)

**Prerequisites:** Story 7.1b (Worker RPC Bridge)

**Estimation:** 0.5-1 jour

---

**Story 10.3: Provides Edge Type - Data Flow Relationships**

As a graph learning system, I want a `provides` edge type that captures data flow between tools,
So that I can understand which tools can feed data to which other tools.

**Context:**
Le `provides` edge est pour la vue **Definition** (structure abstraite). Il indique que
les outputs de A peuvent alimenter les inputs de B, basÃ© sur les schemas.

**Edge Coverage Types:**
```typescript
type ProvidesCoverage =
  | "strict"     // R âŠ† O (tous les required inputs couverts)
  | "partial"    // R âˆ© O â‰  âˆ… (intersection non-vide)
  | "optional";  // Que des inputs optionnels couverts
```

**Acceptance Criteria:**

1. `provides` ajoutÃ© Ã  `EdgeType` dans `edge-weights.ts` ligne 18
2. Weight configurÃ©: `provides: 0.7` dans `EDGE_TYPE_WEIGHTS`
3. Interface `ProvidesEdge` dÃ©finie avec **schemas exposÃ©s**:
   ```typescript
   interface ProvidesEdge {
     from: string;              // Tool/capability provider
     to: string;                // Tool/capability consumer
     type: "provides";
     coverage: ProvidesCoverage;

     // Schemas exposÃ©s pour que l'IA sache remplir les args
     providerOutputSchema: JSONSchema;   // Ce que A produit
     consumerInputSchema: JSONSchema;    // Ce que B attend (required + optional)
     fieldMapping: Array<{               // Correspondances champ par champ
       fromField: string;       // e.g., "content"
       toField: string;         // e.g., "json"
       typeCompatible: boolean; // Types compatibles ?
     }>;
   }
   ```
4. `computeCoverage()` function implÃ©mentÃ©e:
   - Input: `providerOutputs: Set<string>`, `consumerInputs: { required, optional }`
   - Output: `ProvidesCoverage | null`
   - Retourne `null` si aucune intersection
5. `createProvidesEdges()` calculÃ© depuis les MCP tool schemas:
   - Pour chaque paire de tools, calculer coverage
   - CrÃ©er edge si coverage !== null
6. Stockage en DB: column `edge_type` dÃ©jÃ  TEXT, pas de migration
7. Tests: fs:read (output: content) â†’ json:parse (input: json) â†’ coverage = "strict"
8. Tests: json:parse â†’ http:post (need url, body) â†’ coverage = "partial"

**Files to Create:**
- `src/graphrag/provides-edge-calculator.ts` (~100 LOC)

**Files to Modify:**
- `src/graphrag/edge-weights.ts` (~5 LOC)
- `src/graphrag/types.ts` (~15 LOC)

**Prerequisites:** Story 10.2 (result tracing)

**Estimation:** 1-2 jours

---

**Story 10.4: DAG Reconstruction from Traces (POST-EXECUTION)**

As a learning system, I want to reconstruct a DAGStructure from code execution traces,
So that code-based workflows can be replayed as DAGs.

**Context:**
Phase 2 de la tech spec. Avec les traces enrichies (result), on peut dÃ©tecter les
dÃ©pendances data rÃ©elles: "si args de B contient result de A, alors B dÃ©pend de A".

**Algorithm:**
```typescript
function detectDataDependencies(traces: TraceEvent[]): string[] {
  for (const prevTrace of traces) {
    if (containsValue(currentTrace.args, prevTrace.result)) {
      dependsOn.push(prevTrace.traceId);
    }
  }
}

function containsValue(args, result): boolean {
  // Match exact ou partiel (champs extraits d'un objet)
}
```

**Acceptance Criteria:**

1. `DAGReconstructor` class crÃ©Ã©e (`src/graphrag/dag-reconstruction.ts`)
2. Method `reconstructFromTraces(traces: TraceEvent[])` â†’ `DAGStructure`
3. DÃ©tection dÃ©pendances data:
   - Match exact: `JSON.stringify(args).includes(JSON.stringify(result))`
   - Match partiel: champs individuels d'un objet result
4. DÃ©tection parallÃ©lisme via timestamps:
   - Si `endTime(A) < startTime(B)` â†’ sÃ©quence
   - Si timestamps overlap â†’ parallel (pas d'edge)
5. `inferredStructure` ajoutÃ© Ã  `Capability`:
   ```typescript
   inferredStructure: {
     tools: string[];
     edges: Array<{ from, to, type }>;
   }
   ```
6. Tests: trace sÃ©quence Aâ†’Bâ†’C â†’ DAG avec dependsOn correct
7. Tests: trace parallÃ¨le [A, B]â†’C â†’ A et B sans edge entre eux, C dÃ©pend des deux
8. Tests: trace avec result utilisÃ© partiellement (result.data.id) â†’ dÃ©tectÃ©

**Files to Create:**
- `src/graphrag/dag-reconstruction.ts` (~150 LOC)

**Files to Modify:**
- `src/capabilities/types.ts` (~20 LOC)

**Prerequisites:** Story 10.2, Story 10.3

**Estimation:** 2-3 jours

---

**Story 10.5: Unified Capability Model (Code OR DAG)**

As a capability storage system, I want capabilities to support both code and DAG sources,
So that any successful execution becomes a reusable capability.

**Context:**
Phase 3 de la tech spec. Actuellement les capabilities stockent uniquement du code.
On veut pouvoir stocker aussi des DAGStructures.

**Breaking Change:**
```typescript
// AVANT
interface Capability {
  code: string;
}

// APRÃˆS
interface Capability {
  source:
    | { type: "code"; code: string }
    | { type: "dag"; dagStructure: DAGStructure };
}
```

**Acceptance Criteria:**

1. `Capability.source` remplace `Capability.code`:
   ```typescript
   source:
     | { type: "code"; code: string }
     | { type: "dag"; dagStructure: DAGStructure };
   ```
2. `Capability.inferredStructure` ajoutÃ© (from Story 10.4)
3. Migration DB: transformer `code` â†’ `source` JSON column
4. `CapabilityStore.saveCapability()` updated:
   - Accepte `source` au lieu de `code`
   - Appelle `DAGReconstructor` si type=code pour gÃ©nÃ©rer `inferredStructure`
5. `CapabilityStore.findById()` retourne le nouveau format
6. **DAG execution creates capability:**
   - AprÃ¨s succÃ¨s `execute_dag` â†’ crÃ©er capability `{ type: "dag" }`
   - Intent extrait du premier message ou paramÃ¨tre
7. Helper `getCapabilityCode()` pour backward compat:
   ```typescript
   function getCapabilityCode(cap: Capability): string | null {
     return cap.source.type === "code" ? cap.source.code : null;
   }
   ```
8. Tous les usages de `capability.code` migrÃ©s
9. Tests: sauvegarder capability code â†’ retrieve â†’ source.type === "code"
10. Tests: sauvegarder capability dag â†’ retrieve â†’ source.type === "dag"
11. Tests: execute_dag success â†’ capability crÃ©Ã©e avec type=dag

**Files to Modify:**
- `src/capabilities/types.ts` (~30 LOC)
- `src/capabilities/capability-store.ts` (~50 LOC)
- `src/db/migrations/` - New migration (~40 LOC)
- All files using `capability.code` (grep and update)

**Prerequisites:** Story 10.4 (DAG reconstruction)

**Estimation:** 2-3 jours

---

**Story 10.6: pml_discover - Unified Discovery API**

As an AI agent, I want a single `pml_discover` tool to search both tools and capabilities,
So that I have a simplified API for finding what I need.

**Context:**
Phase 4 de la tech spec. Remplace `pml_search_tools`, `pml_search_capabilities`, `pml_find_capabilities`.

**API Design:**
```typescript
pml_discover({
  intent: "lire et parser un fichier JSON",
  filter?: {
    type?: "tool" | "capability" | "all",  // default: "all"
    minScore?: number,
  },
  limit?: number,  // default: 10
})

// Response
{
  results: [
    { type: "capability", id: "cap_123", score: 0.92, source: {...} },
    { type: "tool", id: "fs:read", score: 0.85 },
    { type: "capability", id: "cap_456", score: 0.78, source: {...} },
  ]
}
```

**Acceptance Criteria:**

1. Handler `pml_discover` crÃ©Ã© dans `src/mcp/handlers/`
2. Recherche unifiÃ©e:
   - Vector search sur tools (`tool_graph.intent_embedding`)
   - Vector search sur capabilities (`workflow_pattern.intent_embedding`)
   - Merge et sort par score
3. Input validation avec JSON Schema
4. Filter par type: `tool`, `capability`, ou `all`
5. Pagination: `limit` + `offset`
6. Response inclut pour chaque rÃ©sultat:
   - `type`: "tool" | "capability"
   - `id`: tool_id ou capability_id
   - `score`: similarity score
   - `source`: (pour capabilities) code ou dag preview
   - `toolSchemas`: (pour tools) input/output schemas
7. **DÃ©prÃ©ciation** des anciens tools:
   - `pml_search_tools` â†’ deprecated, redirige vers pml_discover
   - `pml_search_capabilities` â†’ deprecated
   - `pml_find_capabilities` â†’ deprecated
8. System prompt updated pour mentionner pml_discover
9. Tests: search "read file" â†’ retourne mix tools + capabilities
10. Tests: filter type="tool" â†’ que des tools
11. Tests: filter type="capability" â†’ que des capabilities

**Files to Create:**
- `src/mcp/handlers/discover-handler.ts` (~150 LOC)

**Files to Modify:**
- `src/mcp/gateway-server.ts` - Register new handler
- `src/mcp/handlers/search-handler.ts` - Add deprecation notice

**Prerequisites:** Story 10.5 (unified capability model)

**Estimation:** 2-3 jours

---

**Story 10.7: pml_execute - Unified Execution API**

As an AI agent, I want a single `pml_execute` tool that handles both DAG and code execution,
So that I have a simplified API and the system always learns from my executions.

**Context:**
Phase 5 de la tech spec. Remplace `pml_execute_dag` et `pml_execute_code`.

**API Design:**
```typescript
pml_execute({
  intent: "analyser ce fichier JSON",

  // Optionnel - si l'IA veut forcer une implÃ©mentation
  implementation?: {
    type: "code" | "dag",
    code?: string,
    dagStructure?: DAGStructure,
  }
})
```

**Execution Flow:**
```
Intent â†’ Implementation fournie?
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    YES           NO
    â”‚              â”‚
    â–¼              â–¼
  Execute    Search graphe
  provided   (tools + caps)
    â”‚              â”‚
    â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      Confiance       Confiance
    â”‚      haute           basse
    â”‚      â”‚               â”‚
    â”‚      â–¼               â–¼
    â”‚    EXECUTE        RETURN
    â”‚    (speculation)  suggestions
    â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                   â–¼
                            After success:
                            - Create/update capability
                            - Update graph edges
```

**Acceptance Criteria:**

1. Handler `pml_execute` crÃ©Ã© dans `src/mcp/handlers/`
2. Si `implementation` fournie â†’ exÃ©cute directement (code ou dag)
3. Si pas d'implementation:
   - Appelle `pml_discover` en interne
   - Si confidence > seuil â†’ exÃ©cute en speculation
   - Si confidence < seuil â†’ retourne suggestions
4. AprÃ¨s succÃ¨s (code ou dag):
   - CrÃ©e/update capability via `CapabilityStore`
   - Update graph edges
   - Trace structure (parallel, sÃ©quence)
5. Support `per_layer_validation` pour DAGs avec tools Ã©levÃ©s
6. **DÃ©prÃ©ciation** des anciens tools:
   - `pml_execute_dag` â†’ deprecated
   - `pml_execute_code` â†’ deprecated
7. Response unifiÃ©e:
   ```typescript
   {
     status: "success" | "approval_required" | "suggestions",
     result?: unknown,
     suggestions?: DiscoverResult[],
     capabilityId?: string,  // Si capability crÃ©Ã©e/updated
   }
   ```
8. Tests: execute avec intent seul â†’ recherche + suggestion/execution
9. Tests: execute avec implementation code â†’ exÃ©cute le code
10. Tests: execute avec implementation dag â†’ exÃ©cute le dag
11. Tests: succÃ¨s â†’ capability crÃ©Ã©e avec inferredStructure

**Files to Create:**
- `src/mcp/handlers/execute-handler.ts` (~200 LOC)

**Files to Modify:**
- `src/mcp/gateway-server.ts` - Register new handler
- `src/mcp/handlers/workflow-execution-handler.ts` - Add deprecation

**Prerequisites:** Story 10.6 (pml_discover)

**Estimation:** 3-5 jours

---

**Story 10.8: pml_get_task_result - Result Fetching Meta-Tool**

As an AI agent reviewing DAG execution results, I want to fetch the full result of a specific task,
So that I can make informed decisions when the preview isn't sufficient.

**Context:**
ComplÃ©mente le `resultPreview` (240 chars) dÃ©jÃ  implÃ©mentÃ©. Si l'IA a besoin de plus
de contexte pour dÃ©cider, elle peut demander le rÃ©sultat complet.

**API Design:**
```typescript
pml_get_task_result({
  workflow_id: string;
  task_id: string;
  offset?: number;      // Pour pagination (grands rÃ©sultats)
  limit?: number;       // Longueur max Ã  retourner
  format?: "raw" | "pretty";  // Formatage JSON
})
```

**Acceptance Criteria:**

1. Handler `pml_get_task_result` crÃ©Ã©
2. Stockage des rÃ©sultats complets:
   - Nouveau champ `fullResult` dans execution traces
   - Ou table sÃ©parÃ©e `task_results` (workflow_id, task_id, result)
3. RÃ©cupÃ©ration avec pagination:
   - `offset` pour commencer Ã  un point
   - `limit` pour limiter la taille
4. Formatage:
   - `raw`: JSON tel quel
   - `pretty`: JSON.stringify avec indentation
5. TTL sur les rÃ©sultats stockÃ©s (configurable, default 1h)
6. Tests: execute dag â†’ get_task_result â†’ retourne rÃ©sultat complet
7. Tests: pagination fonctionne sur grand rÃ©sultat
8. Tests: rÃ©sultat expirÃ© â†’ erreur appropriÃ©e

**Files to Create:**
- `src/mcp/handlers/task-result-handler.ts` (~80 LOC)

**Files to Modify:**
- `src/mcp/gateway-server.ts` - Register handler
- `src/dag/controlled-executor.ts` - Store full results

**Prerequisites:** Story 10.7 (pml_execute)

**Estimation:** 1-2 jours

---

**Story 10.9: Definition vs Invocation Views (Cytoscape)**

As a dashboard user, I want to toggle between Definition and Invocation views,
So that I can see either the abstract workflow structure or the actual execution.

**Context:**
Phase 6 de la tech spec. La vue Definition montre les nÅ“uds dÃ©dupliquÃ©s (chaque tool une fois),
la vue Invocation montre chaque appel rÃ©el avec timestamps.

**View Differences:**

| Vue | NÅ“uds | Edges | Exemple |
|-----|-------|-------|---------|
| **Definition** | DÃ©dupliquÃ©s | dependency, provides, contains | `fs:read` (1 nÅ“ud) |
| **Invocation** | Par appel | sequence, contains | `fs:read_1`, `fs:read_2` |

**Acceptance Criteria:**

1. Toggle button dans dashboard: `[Definition] [Invocation]`
2. **Vue Definition:**
   - NÅ“uds dÃ©dupliquÃ©s par tool/capability type
   - Edges: `dependency`, `provides`, `contains`, `alternative`
   - Layout optimisÃ© pour structure
3. **Vue Invocation:**
   - Un nÅ“ud par appel rÃ©el (suffixe `_1`, `_2`, etc.)
   - Timestamps affichÃ©s sur les nÅ“uds
   - Edges: `sequence` (basÃ© sur ordre temporel)
   - Parallel visible par timestamps qui overlap
4. Table `capability_invocations` crÃ©Ã©e:
   ```typescript
   {
     id: string;
     capabilityId: string;
     timestamp: Date;
     arguments: Record<string, unknown>;
     results: TaskResult[];
     success: boolean;
     durationMs: number;
   }
   ```
5. API endpoint `/api/invocations/:capabilityId`
6. Cytoscape layout adaptÃ© par vue:
   - Definition: dagre/hierarchical
   - Invocation: timeline/temporal
7. Tests: mÃªme capability, 3 exÃ©cutions â†’ Definition (1 nÅ“ud) vs Invocation (3 nÅ“uds)
8. Tests: exÃ©cution avec parallÃ©lisme visible en Invocation view

**Files to Create:**
- `src/db/migrations/XXX_capability_invocations.ts` (~40 LOC)
- `src/web/islands/DefinitionInvocationToggle.tsx` (~80 LOC)

**Files to Modify:**
- `src/web/routes/dashboard.tsx` - Add toggle
- `src/visualization/hypergraph-builder.ts` - Support both views

**Prerequisites:** Story 10.8, Epic 8 (Hypergraph visualization)

**Estimation:** 2-3 jours

---

**Story 10.10: Dry Run Mode with Mocks (Connector Debugging)**

As a workflow developer, I want to dry-run code with mocked MCP responses,
So that I can debug and validate complex workflows without real side effects, especially for connector MCPs.

**Context:**
Le parsing statique (Story 10.1) suffit pour HIL/permissions, mais pour le **debugging** de workflows
complexes utilisant des MCP connecteurs (APIs externes, bases de donnÃ©es), on veut pouvoir :
- Voir exactement ce qui VA se passer avant de le faire
- Tester sans appeler les vraies APIs (coÃ»t, rate limits, effets de bord)
- Valider les donnÃ©es intermÃ©diaires

**Use Cases spÃ©cifiques:**

| Use Case | Parsing Statique | Dry Run |
|----------|------------------|---------|
| HIL permissions | âœ… Suffit | Overkill |
| Estimation coÃ»t API | âŒ Approximatif | âœ… Exact (N appels) |
| Debug data flow | âŒ Types only | âœ… Vraies valeurs mockÃ©es |
| Test workflow sans side effects | âŒ Impossible | âœ… Full simulation |
| Validation avant prod | âŒ Statique | âœ… Comportement rÃ©el |

**Quand utiliser Dry Run vs Parsing:**
- **Parsing (10.1)** : Validation rapide, HIL, permissions â†’ **toujours**
- **Dry Run (10.10)** : Debugging, estimation, test connecteurs â†’ **opt-in depuis dashboard**

**Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dashboard: "Test Workflow" button                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mock MCP Proxy                                              â”‚
â”‚  - Intercepte tous les appels mcp.*.*()                     â”‚
â”‚  - Retourne mock responses basÃ©es sur output schemas        â”‚
â”‚  - Log chaque appel avec timestamp, args, mock result       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sandbox Execution (mode: dry_run)                          â”‚
â”‚  - ExÃ©cute le vrai code                                     â”‚
â”‚  - Mais avec mcp = mockMcpProxy                             â”‚
â”‚  - Capture le flow rÃ©el d'exÃ©cution                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dry Run Report                                              â”‚
â”‚  - Liste exacte des appels qui seraient faits              â”‚
â”‚  - DonnÃ©es mockÃ©es Ã  chaque Ã©tape                          â”‚
â”‚  - Warnings si comportement dÃ©pend des donnÃ©es rÃ©elles     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Mock Response Generation:**
```typescript
// GÃ©nÃ¨re mock response depuis le schema MCP
function generateMockResponse(toolSchema: ToolSchema): unknown {
  // Utilise le output_schema pour gÃ©nÃ©rer des donnÃ©es rÃ©alistes
  // Ex: { type: "string" } â†’ "mock_string_value"
  // Ex: { type: "object", properties: { id: { type: "number" } } } â†’ { id: 12345 }
}

// Pour les connecteurs connus, on peut avoir des mocks plus intelligents
const CONNECTOR_MOCKS: Record<string, MockGenerator> = {
  "github:api": generateGitHubMock,      // Retourne des PRs, issues mockÃ©s
  "slack:post": generateSlackMock,       // Retourne { ok: true, ts: "..." }
  "postgres:query": generatePostgresMock, // Retourne rows mockÃ©es
};
```

**Acceptance Criteria:**

1. `MockMcpProxy` class crÃ©Ã©e:
   ```typescript
   interface MockMcpProxy {
     onToolCall(server: string, tool: string, args: unknown): Promise<unknown>;
     getCapturedCalls(): CapturedCall[];
     reset(): void;
   }

   interface CapturedCall {
     server: string;
     tool: string;
     args: unknown;
     mockResponse: unknown;
     timestamp: number;
     durationMs: number;
   }
   ```
2. GÃ©nÃ©ration de mock responses depuis `tool_schema.output_schema`
3. Support pour mocks custom par connecteur (GitHub, Slack, DB, etc.)
4. IntÃ©gration sandbox: `execute(code, { mode: "dry_run" })`
5. `DryRunReport` gÃ©nÃ©rÃ© aprÃ¨s exÃ©cution:
   ```typescript
   interface DryRunReport {
     capturedCalls: CapturedCall[];
     executionTimeMs: number;
     warnings: string[];           // "Response depends on real data"
     estimatedApiCalls: number;
     estimatedCost?: number;       // Si on a des infos de pricing
   }
   ```
6. UI Dashboard: bouton "Test Workflow" sur les capabilities
7. UI Dashboard: affichage du DryRunReport (timeline des appels)
8. Tests: dry run avec 3 tools sÃ©quentiels
9. Tests: dry run avec boucle â†’ capture tous les appels
10. Tests: mock custom pour connecteur GitHub

**Files to Create:**
- `src/sandbox/mock-mcp-proxy.ts` (~150 LOC)
- `src/sandbox/mock-generators.ts` (~100 LOC)
- `src/web/islands/DryRunReport.tsx` (~120 LOC)

**Files to Modify:**
- `src/sandbox/worker-bridge.ts` - Support mode dry_run (~30 LOC)
- `src/web/routes/dashboard.tsx` - Add "Test Workflow" button (~20 LOC)

**Prerequisites:** Story 10.7 (pml_execute), Epic 8 (Dashboard)

**Estimation:** 3-4 jours

**Note:** Cette story est **optionnelle pour le MVP**. Le parsing statique (10.1) suffit
pour le HIL. Le dry run est un nice-to-have pour le debugging avancÃ© de workflows
avec des MCP connecteurs externes.

---

### Epic 10 Breaking Changes Summary

| Phase | Change | Breaking? | Impact |
|-------|--------|-----------|--------|
| 1 | `result` in traces | âŒ No | Additive |
| 2 | `provides` EdgeType | âŒ No | Additive |
| 3 | Capability `source: code \| dag` | âš ï¸ **Yes** | Schema change |
| 4 | Deprecate `pml_search_*` | âš ï¸ **Yes** | MCP APIs |
| 5 | Deprecate `pml_execute_*` | âš ï¸ **Yes** | MCP APIs |
| 6 | New table `capability_invocations` | âŒ No | Additive |

**Migration Strategy:** Breaking changes in Phase 3-5. No transition period - clean cut.

---

### Epic 10 Dependencies

```
â˜… Story 10.1 (DAG Preview) â† FIRST! Valide SWC, dÃ©bloque HIL Phase 4
    â”‚
    â”‚   (peut dÃ©marrer en parallÃ¨le avec 10.2-10.4)
    â”‚
    â”œâ”€â”€â–¶ Story 10.2 (result tracing)
    â”‚        â”‚
    â”‚        â””â”€â”€â–¶ Story 10.3 (provides edge)
    â”‚                  â”‚
    â”‚                  â””â”€â”€â–¶ Story 10.4 (DAG reconstruction POST-exec)
    â”‚
    â””â”€â”€â–¶ Story 10.5 (unified capability) â† Utilise 10.1 + 10.4
              â”‚
              â–¼
         Story 10.6 (pml_discover)
              â”‚
              â–¼
         Story 10.7 (pml_execute) â†â”€â”€ IntÃ¨gre 10.1 pour preview!
              â”‚
              â–¼
         Story 10.8 (pml_get_task_result)
              â”‚
              â–¼
         Story 10.9 (Definition/Invocation views)
              â”‚
              â–¼
         Story 10.10 (Dry Run + Mocks) â† Optional, pour debug connecteurs
```

**External Dependencies:**
- Epic 7 Story 7.1b (Worker RPC Bridge)
- HIL Phase 2 (per_layer_validation, resultPreview)
- Epic 8 (Hypergraph visualization for Story 10.8)

---

### Epic 10 FR Coverage

| FR | Description | Story |
|----|-------------|-------|
| **FR1** | **DAG Preview prÃ©-exÃ©cution (parsing statique)** | **10.1** |
| **FR1b** | **Validation permissions avant exÃ©cution** | **10.1** |
| **FR1c** | **HIL pre-execution approval flow** | **10.1** |
| FR2 | Tracer `result` des tools et capabilities | 10.2 |
| FR3 | Edge type `provides` avec coverage | 10.3 |
| FR4 | Reconstruction DAG depuis traces code | 10.4 |
| FR5 | Capability unifiÃ©e (code OU dag) | 10.5 |
| FR6 | API `pml_discover` unifiÃ©e | 10.6 |
| FR7 | API `pml_execute` unifiÃ©e | 10.7 |
| FR8 | `pml_get_task_result` pour rÃ©sultats complets | 10.8 |
| FR9 | Vue Definition vs Invocation | 10.9 |
| FR10 | DÃ©prÃ©ciation anciennes APIs | 10.6, 10.7 |
| FR11 | Learning automatique aprÃ¨s succÃ¨s | 10.7 |
| FR12 | Dry Run avec Mocks pour connecteurs (optional) | 10.10 |

---

### Epic 10 Estimation Summary

| Story | Description | Effort | Cumulative |
|-------|-------------|--------|------------|
| **10.1** | **DAG Preview (SWC)** â­ ~100-150 LOC | **2-3j** | **3j** |
| 10.2 | Result Tracing | 0.5-1j | 4j |
| 10.3 | Provides Edge | 1-2j | 6j |
| 10.4 | DAG Reconstruction | 2-3j | 9j |
| 10.5 | Unified Capability | 2-3j | 12j |
| 10.6 | pml_discover | 2-3j | 15j |
| 10.7 | pml_execute | 3-5j | 19j |
| 10.8 | pml_get_task_result | 1-2j | 21j |
| 10.9 | Definition/Invocation | 2-3j | 24j |
| 10.10 | Dry Run + Mocks (optional) | 3-4j | 28j |

**Total MVP (10.1-10.9): ~3-4 semaines**
**Total avec 10.10: ~4-5 semaines**

**ğŸ¯ Story 10.1 (DAG Preview) est critique car:**
1. Valide l'approche SWC pour la dÃ©tection des appels MCP + capabilities
2. DÃ©bloque HIL Phase 4 (pre-execution approval)
3. **RÃ©utilise l'existant** : SchemaInferrer (726 LOC), PermissionInferrer (510 LOC)
4. **Valide schemas** : tool_schema + workflow_pattern tables
5. Unifie le flow d'exÃ©cution (preview avant execute)

**ğŸ“‹ Story 10.10 (Dry Run) est optionnelle car:**
- Le parsing statique (10.1) suffit pour HIL/permissions
- Dry run = nice-to-have pour debugging de workflows avec connecteurs
- Utile quand on a des MCP APIs externes (GitHub, Slack, DB, etc.)
