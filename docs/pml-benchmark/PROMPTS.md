# Prompts de test PML

> Liste de requÃªtes pour tester le systÃ¨me PML
> SÃ©parÃ© en deux modes : **Script** (API directe) vs **Chat** (LLM requis)

---

## Mode d'exÃ©cution

### ğŸ¤– Script (API directe)

Peut Ãªtre automatisÃ© sans LLM. L'input est explicite (code fourni, DAG JSON).

**Outils utilisÃ©s** :
- `pml_execute_code({ intent, code })` â†’ code fourni
- `pml_execute_dag({ workflow })` â†’ DAG JSON fourni
- `pml_search_capabilities({ intent })`
- `pml_search_tools({ query })`

**Ce qu'on teste** :
- Eager learning (stockage immÃ©diat)
- Schema inference (AST parsing)
- Tool dependencies (patterns rÃ©pÃ©tÃ©s)
- DAG execution (parallÃ©lisation, dÃ©pendances)
- Capability matching (recherche vectorielle)

### ğŸ’¬ Chat (LLM requis)

NÃ©cessite Claude pour transformer le langage naturel en code/actions.

**Ce qu'on teste** :
- GÃ©nÃ©ration de code depuis un intent
- DÃ©cision de reuse (utiliser une capability matchÃ©e ou pas)
- Composition intelligente de capabilities
- Extraction de paramÃ¨tres depuis le prompt
- Variations sÃ©mantiques naturelles

---

# PARTIE 1 : Tests Scriptables (API)

## S1. Eager Learning

ExÃ©cuter du code explicite et vÃ©rifier la crÃ©ation de capability.

```typescript
// Test S1.1 - CrÃ©ation de capability
pml_execute_code({
  intent: "list source directory files",
  code: `return await mcp.filesystem.list_directory({ path: "/home/ubuntu/CascadeProjects/AgentCards/src" });`
})
// â†’ VÃ©rifier: capability crÃ©Ã©e, usage_count=1, success_rate=1.0

// Test S1.2 - VÃ©rification du stockage
pml_search_capabilities({ intent: "list source directory files" })
// â†’ VÃ©rifier: capabilities.length >= 1, semantic_score > 0.9
```

## S2. Schema Inference

ExÃ©cuter du code avec `args.xxx` et vÃ©rifier l'infÃ©rence.

```typescript
// Test S2.1 - ParamÃ¨tres string
pml_execute_code({
  intent: "read file by path",
  code: `return await mcp.filesystem.read_file({ path: args.filePath });`
})
// â†’ VÃ©rifier: parameters_schema.properties.filePath.type = "string"

// Test S2.2 - ParamÃ¨tres number
pml_execute_code({
  intent: "read file with limit",
  code: `
    const content = await mcp.filesystem.read_file({ path: args.filePath });
    return content.split('\\n').slice(0, args.maxLines).join('\\n');
  `
})
// â†’ VÃ©rifier: parameters_schema contient filePath (string) et maxLines (number)

// Test S2.3 - ParamÃ¨tres boolean
pml_execute_code({
  intent: "read file with debug option",
  code: `
    const content = await mcp.filesystem.read_file({ path: args.filePath });
    if (args.verbose) console.log("Read", content.length, "chars");
    return content;
  `
})
// â†’ VÃ©rifier: parameters_schema contient verbose (boolean)
```

## S3. DAGs explicites

ExÃ©cuter des workflows JSON et vÃ©rifier les dÃ©pendances.

```typescript
// Test S3.1 - DAG sÃ©quentiel
pml_execute_dag({
  workflow: {
    tasks: [
      { id: "list", tool: "filesystem:list_directory", arguments: { path: "/home/ubuntu/CascadeProjects/AgentCards/src/dag" }, dependsOn: [] },
      { id: "read", tool: "filesystem:read_file", arguments: { path: "/home/ubuntu/CascadeProjects/AgentCards/src/dag/mod.ts" }, dependsOn: ["list"] }
    ]
  }
})
// â†’ VÃ©rifier: parallelization_layers = 2, results[0].status = "success"

// Test S3.2 - DAG parallÃ¨le
pml_execute_dag({
  workflow: {
    tasks: [
      { id: "p1", tool: "fetch:fetch", arguments: { url: "https://jsonplaceholder.typicode.com/posts/1" }, dependsOn: [] },
      { id: "p2", tool: "fetch:fetch", arguments: { url: "https://jsonplaceholder.typicode.com/posts/2" }, dependsOn: [] },
      { id: "p3", tool: "fetch:fetch", arguments: { url: "https://jsonplaceholder.typicode.com/posts/3" }, dependsOn: [] }
    ]
  }
})
// â†’ VÃ©rifier: parallelization_layers = 1 (tout en parallÃ¨le)

// Test S3.3 - DAG diamond (A â†’ B,C â†’ D)
pml_execute_dag({
  workflow: {
    tasks: [
      { id: "A", tool: "filesystem:list_directory", arguments: { path: "/home/ubuntu/CascadeProjects/AgentCards/src" }, dependsOn: [] },
      { id: "B", tool: "filesystem:get_file_info", arguments: { path: "/home/ubuntu/CascadeProjects/AgentCards/src/main.ts" }, dependsOn: ["A"] },
      { id: "C", tool: "filesystem:directory_tree", arguments: { path: "/home/ubuntu/CascadeProjects/AgentCards/src/dag" }, dependsOn: ["A"] },
      { id: "D", tool: "filesystem:read_file", arguments: { path: "/home/ubuntu/CascadeProjects/AgentCards/src/main.ts" }, dependsOn: ["B", "C"] }
    ]
  }
})
// â†’ VÃ©rifier: parallelization_layers = 3, ordre respectÃ©
```

## S4. Tool Dependencies

RÃ©pÃ©ter des patterns et vÃ©rifier les `related_tools`.

```typescript
// Test S4.1 - CrÃ©er le pattern list â†’ read (3x)
for (const path of ["src/dag", "src/mcp", "src/capabilities"]) {
  pml_execute_dag({
    workflow: {
      tasks: [
        { id: "list", tool: "filesystem:list_directory", arguments: { path: `/home/ubuntu/CascadeProjects/AgentCards/${path}` }, dependsOn: [] },
        { id: "read", tool: "filesystem:read_file", arguments: { path: `/home/ubuntu/CascadeProjects/AgentCards/${path}/mod.ts` }, dependsOn: ["list"] }
      ]
    }
  })
}

// Test S4.2 - VÃ©rifier les relations apprises
pml_search_tools({ query: "list directory", include_related: true })
// â†’ VÃ©rifier: related_tools contient filesystem:read_file avec relation "often_after"
```

## S5. Capability Matching (prÃ©cision)

Tester le matching vectoriel avec diffÃ©rents intents.

```typescript
// PrÃ©-requis: capability "list source directory files" existe (S1)

// Test S5.1 - Match exact
pml_search_capabilities({ intent: "list source directory files" })
// â†’ semantic_score > 0.95

// Test S5.2 - Match similaire
pml_search_capabilities({ intent: "show files in src folder" })
// â†’ semantic_score > 0.75

// Test S5.3 - Match diffÃ©rent (nÃ©gatif)
pml_search_capabilities({ intent: "deploy to kubernetes" })
// â†’ semantic_score < 0.50 ou capabilities.length = 0
```

---

# PARTIE 2 : Tests Chat (LLM requis)

Ces tests nÃ©cessitent de donner le prompt Ã  Claude et observer le comportement.

## C1. GÃ©nÃ©ration de code

Le LLM doit transformer un intent en code exÃ©cutable.

```
Prompt: "Liste les fichiers dans src/dag"
â†’ Attendu: Claude gÃ©nÃ¨re du code avec mcp.filesystem.list_directory
â†’ VÃ©rifier: capability crÃ©Ã©e avec le bon code
```

```
Prompt: "RÃ©cupÃ¨re le post 1 de jsonplaceholder"
â†’ Attendu: Claude gÃ©nÃ¨re du code avec mcp.fetch.fetch
â†’ VÃ©rifier: capability crÃ©Ã©e
```

## C2. DÃ©cision de reuse

Le LLM doit utiliser une capability existante quand pertinent.

```
PrÃ©-requis: ExÃ©cuter C1 d'abord

Prompt: "Montre-moi le contenu du dossier src/dag"
â†’ Attendu: matched_capabilities affichÃ©, Claude rÃ©utilise ou adapte
â†’ VÃ©rifier: mÃªme capability utilisÃ©e (usage_count incrÃ©mentÃ©)
```

```
Prompt: "Affiche les fichiers de src/dag"
â†’ Attendu: matched_capabilities avec score > 0.7
â†’ VÃ©rifier: pas de nouvelle capability crÃ©Ã©e (reuse)
```

## C3. Composition intelligente

Le LLM doit combiner plusieurs outils pour des tÃ¢ches complexes.

```
Prompt: "Liste src/mcp puis lis le fichier mod.ts qui s'y trouve"
â†’ Attendu: DAG crÃ©Ã© avec list_directory â†’ read_file
â†’ VÃ©rifier: 2 tool invocations dans le rÃ©sultat
```

```
Prompt: "Lis deno.json et dis-moi le nom du projet"
â†’ Attendu: Code composite (read + JSON.parse + extraction)
â†’ VÃ©rifier: capability avec toolsUsed contenant filesystem:read_file
```

## C4. Extraction de paramÃ¨tres

Le LLM doit extraire les valeurs du prompt pour `args`.

```
Prompt: "Lis le fichier src/main.ts et donne-moi les 20 premiÃ¨res lignes"
â†’ Attendu: args.filePath = "src/main.ts", args.maxLines = 20
â†’ VÃ©rifier: valeurs correctement extraites et utilisÃ©es
```

## C5. Variations sÃ©mantiques naturelles

Tester avec des formulations variÃ©es.

| Prompt | Doit matcher |
|--------|--------------|
| "Liste les fichiers dans src" | capability list_directory |
| "Montre le contenu du dossier src" | capability list_directory |
| "Qu'y a-t-il dans src ?" | capability list_directory |
| "C'est quoi les fichiers de src" | capability list_directory |
| "Affiche src/" | capability list_directory |

---

# PARTIE 3 : VÃ©rifications

AprÃ¨s chaque phase de tests, exÃ©cuter :

```typescript
// Lister toutes les capabilities
pml_search_capabilities({ intent: "any operation", include_suggestions: true })

// VÃ©rifier les tool dependencies
pml_search_tools({ query: "filesystem", include_related: true })

// Compter les capabilities avec schema
// â†’ Regarder parameters_schema non vide dans les rÃ©sultats
```

---

# RÃ©sultats attendus

## Tests Script (S1-S5)

| Test | MÃ©trique | Target |
|------|----------|--------|
| S1 | capability crÃ©Ã©e | 1 |
| S2 | schema infÃ©rÃ© | 3 props |
| S3 | DAGs exÃ©cutÃ©s | 3 |
| S4 | related_tools | >= 1 |
| S5 | semantic_score accuracy | > 0.75 |

## Tests Chat (C1-C5)

| Test | MÃ©trique | Target |
|------|----------|--------|
| C1 | code gÃ©nÃ©rÃ© correct | 100% |
| C2 | reuse rate | > 50% |
| C3 | compositions crÃ©Ã©es | >= 2 |
| C4 | params extraits | 100% |
| C5 | match variations | > 80% |
