# AgentCards Product Requirements Document (PRD)

**Author:** BMad
**Date:** 2025-11-03
**Project Level:** 2
**Target Scale:** 1-2 epics, 5-15 stories total

---

## Goals and Background Context

### Goals

1. **Optimiser le contexte LLM** - R√©duire la consommation de contexte par les tool schemas de 30-50% √† <5%, permettant aux d√©veloppeurs de r√©cup√©rer 90% de leur fen√™tre conversationnelle
2. **Parall√©liser l'ex√©cution des workflows** - R√©duire la latence des workflows multi-tools de 5x √† 1x via DAG execution, √©liminant les temps d'attente cumulatifs
3. **Supporter 15+ MCP servers simultan√©ment** - Permettre l'activation de 15+ MCP servers sans d√©gradation de performance, d√©bloquant l'utilisation compl√®te de l'√©cosyst√®me MCP

### Background Context

L'√©cosyst√®me Model Context Protocol (MCP) conna√Æt une adoption explosive avec des centaines de servers disponibles, mais se heurte √† deux goulots d'√©tranglement critiques qui limitent drastiquement son utilisation r√©elle.

Premi√®rement, la **"taxe invisible" du contexte** : 30-50% de la context window LLM est consomm√©e uniquement par les schemas des tools MCP avant toute interaction utile, for√ßant les d√©veloppeurs √† s'auto-limiter √† 7-8 servers maximum au lieu des 15-20+ qu'ils souhaiteraient utiliser. Deuxi√®mement, **l'inefficacit√© des appels s√©quentiels** : les workflows multi-tools s'ex√©cutent sans parall√©lisation, cr√©ant une latence cumulative p√©nible (5 tools = 5x le temps d'attente).

**Le march√© des gateways MCP est encombr√©** avec de nombreuses tentatives de solutions : AIRIS, Smithery, Unla, Context Forge, agentgateway, mcp-gateway-registry, lazy gateway, et d'autres. Cependant, **aucune ne r√©sout de mani√®re satisfaisante les deux probl√®mes simultan√©ment** :
- Certains promettent le lazy loading mais l'impl√©mentation est d√©faillante ou incompl√®te
- D'autres se concentrent uniquement sur l'orchestration sans optimiser le contexte
- La majorit√© reste en approche "all-at-once" qui sature la context window
- Aucune ne combine vector search s√©mantique ET DAG execution de mani√®re production-ready

AgentCards se diff√©rencie par une approche **PGlite-first, zero-config, et double optimisation** : vector search s√©mantique pour le chargement on-demand granulaire (<5% de contexte) ET DAG execution pour la parall√©lisation intelligente (latence 5x ‚Üí 1x). L'architecture edge-ready et le focus DX irr√©prochable (NPS >75 target) visent √† devenir la solution de r√©f√©rence l√† o√π d'autres ont √©chou√© sur l'ex√©cution.

---

## Requirements

### Functional Requirements

**Context Optimization**
- **FR001:** Le syst√®me doit g√©n√©rer des embeddings vectoriels pour tous les tool schemas MCP disponibles
- **FR002:** Le syst√®me doit effectuer une recherche s√©mantique pour identifier les top-k tools pertinents (k=3-10) bas√© sur l'intent utilisateur
- **FR003:** Le syst√®me doit charger les tool schemas on-demand uniquement pour les tools identifi√©s comme pertinents
- **FR004:** Le syst√®me doit maintenir la consommation de contexte par les tool schemas en-dessous de 5% de la context window totale

**DAG Execution & Orchestration**
- **FR005:** Le syst√®me doit analyser les d√©pendances input/output entre tools pour construire un graphe de d√©pendances (DAG)
- **FR006:** Le syst√®me doit identifier automatiquement les tools ex√©cutables en parall√®le vs s√©quentiellement
- **FR007:** Le syst√®me doit ex√©cuter simultan√©ment les branches ind√©pendantes du DAG
- **FR008:** Le syst√®me doit streamer les r√©sultats via SSE d√®s leur disponibilit√© pour feedback progressif

**MCP Server Management**
- **FR009:** Le syst√®me doit auto-d√©couvrir les MCP servers disponibles (stdio et SSE) sans configuration manuelle
- **FR010:** Le syst√®me doit effectuer des health checks automatiques sur les MCP servers au d√©marrage
- **FR011:** Le syst√®me doit supporter 15+ MCP servers actifs simultan√©ment sans d√©gradation de performance

**Storage & Persistence**
- **FR012:** Le syst√®me doit stocker tous les embeddings, schemas, et metadata dans un fichier PGlite unique portable
- **FR013:** Le syst√®me doit cacher les tool schemas pour √©viter les rechargements r√©p√©titifs

**Observability**
- **FR014:** Le syst√®me doit tracker les m√©triques de consommation de contexte et latence d'ex√©cution (opt-in)
- **FR015:** Le syst√®me doit g√©n√©rer des logs structur√©s pour debugging et monitoring

**Migration & Setup**
- **FR016:** Le syst√®me doit pouvoir lire le mcp.json existant de Claude Code et g√©n√©rer automatiquement la configuration AgentCards correspondante

**Code Execution & Sandbox**
- **FR017:** Le syst√®me doit permettre l'ex√©cution de code TypeScript g√©n√©r√© par les agents dans un environnement Deno sandbox isol√© avec permissions explicites
- **FR018:** Le syst√®me doit supporter les **branches DAG safe-to-fail** : t√¢ches sandbox pouvant √©chouer sans compromettre le workflow global, permettant resilient workflows, graceful degradation, et retry safety
- **FR019:** Le syst√®me doit injecter les MCP tools pertinents dans le contexte d'ex√©cution sandbox via vector search, permettant aux agents d'appeler les tools directement depuis le code TypeScript

### Non-Functional Requirements

- **NFR001: Performance** - Le syst√®me doit ex√©cuter un workflow typique de 5 tools avec une latence P95 <3 secondes (am√©lioration 5x vs ex√©cution s√©quentielle baseline)

- **NFR002: Usability (Zero-Config)** - Le syst√®me doit permettre √† un utilisateur de passer de l'installation initiale au premier workflow parall√©lis√© fonctionnel en moins de 10 minutes sans configuration manuelle

- **NFR003: Reliability** - Le syst√®me doit maintenir un taux de succ√®s >99% pour l'ex√©cution des workflows (pas de bugs critiques bloquants comme observ√©s chez les comp√©titeurs)

---

## User Journeys

### Journey 1: Premier Workflow Parall√©lis√© avec AgentCards

**Acteur:** Alex, Power User d√©veloppeur (utilise Claude Code 10h/jour, 15 MCP servers install√©s)

**Objectif:** Passer d'une configuration MCP saturant le contexte √† AgentCards avec context optimis√© et workflows parall√©lis√©s

**√âtapes:**

**1. Setup AgentCards** (3-5 min)
- Alex ex√©cute `agentcards init` dans son terminal
- AgentCards lit automatiquement le `mcp.json` existant de Claude Code
- D√©tecte les 15 MCP servers configur√©s (GitHub, Filesystem, Database, Playwright, Serena, etc.)
- G√©n√®re `~/.agentcards/config.yaml` avec la configuration migr√©e
- G√©n√®re les embeddings vectoriels pour tous les tools (~60s via BGE-Large-EN-v1.5)
- Stocke tout dans `.agentcards.db` (PGlite portable)
- ‚úÖ Console: "15 MCP servers migr√©s et index√©s avec succ√®s"

**2. Migration Config Claude Code** (2 min)
- AgentCards affiche les instructions de migration
- Alex √©dite son `claude_desktop_config.json` (mcp.json)
- **Retire** les 15 entr√©es MCP servers individuelles
- **Ajoute** uniquement la gateway AgentCards:
  ```json
  {
    "mcpServers": {
      "agentcards": {
        "command": "agentcards",
        "args": ["serve"]
      }
    }
  }
  ```
- Red√©marre Claude Code
- Claude voit maintenant un seul MCP server au lieu de 15

**3. Premier Workflow - Context Lib√©r√©** (1-2 min)
- Alex fait une requ√™te cross-MCP: "Lis config.json, parse-le, et cr√©e un ticket GitHub avec les infos"
- AgentCards intercepte la requ√™te depuis Claude
- **Vector search:** Identifie 3 tools pertinents (filesystem:read, json:parse, github:create_issue)
- **Context optimization:** Charge uniquement ces 3 schemas (~2% du contexte vs 45% avant)
- **DAG execution:** D√©tecte d√©pendances s√©quentielles (read ‚Üí parse ‚Üí create)
- Ex√©cute le workflow, r√©sultats stream√©s via SSE
- Console AgentCards: "Context usage: 2.3% | Workflow completed in 4.2s"

**4. "Aha Moment" - Parall√©lisation (<10 min total)**
- Alex teste un workflow parall√©lisable: "Lis 3 fichiers diff√©rents: config.json, package.json, README.md"
- AgentCards d√©tecte que les 3 lectures sont ind√©pendantes
- **DAG execution:** Ex√©cute les 3 filesystem:read en parall√®le (Promise.all)
- Latence: 1.8s au lieu de 5.4s (3x am√©lioration mesur√©e)
- üí° **R√©alisation:** "Je peux activer tous mes MCP servers ET avoir des workflows ultra-rapides!"

**5. Utilisation Continue**
- Alex continue √† utiliser Claude Code normalement
- AgentCards tourne en arri√®re-plan (daemon transparent)
- Tous les 15 MCP servers fonctionnent via la gateway
- Acc√®s filesystem local pr√©serv√© (pas de probl√®mes Docker)
- M√©triques opt-in track√©es: context moyen 3.8%, workflows 4.2x plus rapides

**Points de Validation:**
- ‚úÖ Installation + migration <10 minutes (NFR002)
- ‚úÖ Context <5% maintenu (FR004, NFR001)
- ‚úÖ 15+ MCP servers support√©s simultan√©ment (FR011)
- ‚úÖ Workflows parall√©lis√©s fonctionnels (FR007)
- ‚úÖ Aucun bug bloquant, exp√©rience fluide (NFR003)

---

## UX Design Principles

Pour un outil backend comme AgentCards, l'UX se concentre sur la **Developer Experience (DX)**. Principes cl√©s:

**1. Transparence et Feedback**
- Messages console clairs et informatifs √† chaque √©tape
- Progress bars pour op√©rations longues (g√©n√©ration embeddings)
- Logs structur√©s avec niveaux appropri√©s (error, warn, info, debug)
- M√©triques visibles (context usage %, latency) apr√®s chaque workflow

**2. Zero-Friction Setup**
- Installation en une commande (`agentcards init`)
- Auto-discovery et migration automatique du mcp.json existant
- Configuration par d√©faut sensible (pas de fichiers √† √©diter manuellement)
- Messages d'erreur avec suggestions de r√©solution

**3. Fail-Safe et Debuggable**
- Erreurs explicites avec context (quel MCP server, quelle op√©ration)
- Rollback automatique si migration √©choue
- Mode verbose optionnel (`--verbose`) pour troubleshooting
- Logs persist√©s dans fichier pour analyse post-mortem

**4. Performance Observable**
- M√©triques temps r√©el stream√©es dans console
- Comparaison before/after (context: 45% ‚Üí 3%)
- Dashboard CLI optionnel (`agentcards status`) pour vue d'ensemble

---

## User Interface Design Goals

Pas d'interface graphique MVP, mais output console optimis√©:

**1. Console Output Structur√©e**
- Couleurs pour statut (vert=success, rouge=error, jaune=warning)
- Tableaux format√©s pour m√©triques (context usage, latency)
- ASCII art minimal pour branding (logo AgentCards au d√©marrage)

**2. Logging Levels**
- Default: Info (setup steps, workflow results)
- Quiet mode (`--quiet`): Errors only
- Verbose mode (`--verbose`): Debug traces

**3. Interactive Prompts (si n√©cessaire)**
- Confirmation avant migration destructive
- Opt-in pour telemetry (explicit consent)

---

## Epic List

### Epic 1: Project Foundation & Context Optimization Engine

**Objectif:** √âtablir l'infrastructure projet et impl√©menter le syst√®me de context optimization via vector search s√©mantique

**Livrables cl√©s:**
- Repository configur√© avec CI/CD et structure Deno
- PGlite + pgvector fonctionnel avec embeddings storage
- Vector search s√©mantique op√©rationnel (<100ms queries)
- On-demand schema loading via MCP protocol
- Migration tool (`agentcards init`) fonctionnel

**Estimation:** 7-8 stories

---

### Epic 2: DAG Execution & Production Readiness

**Objectif:** Impl√©menter la parall√©lisation des workflows via DAG execution et pr√©parer le syst√®me pour production

**Livrables cl√©s:**
- Dependency graph construction automatique
- Parallel executor avec SSE streaming
- Gateway MCP int√©gr√© avec Claude Code
- Health checks et observability
- Tests end-to-end et production hardening

**Note architecturale:** Le **DAG** (instance de workflow sp√©cifique) est distinct du **GraphRAG** (Epic 1 - base de connaissances globale). GraphRAG stocke tous les tools et patterns historiques ; le DAG Suggester interroge GraphRAG pour pr√©dire quel DAG construire pour une t√¢che donn√©e ; le DAG Executor ex√©cute ce DAG (possiblement sp√©culativement). Le speculative execution n'est possible que gr√¢ce √† cette architecture : GraphRAG (la connaissance) ‚Üí DAG Suggester (l'intelligence) ‚Üí DAG (le plan d'ex√©cution).

**Estimation:** 6-7 stories

---

### Epic 3: Agent Code Execution & Local Processing

**Objectif:** Impl√©menter un sandbox d'ex√©cution s√©curis√© pour permettre aux agents d'√©crire et ex√©cuter du code TypeScript localement, traitant les large datasets avant injection dans le contexte LLM

**Livrables cl√©s:**
- Deno sandbox executor avec isolation et s√©curit√©
- MCP tools injection dans code context (vector search-guided)
- Local data processing pipeline (filtrage/agr√©gation pr√©-contexte)
- Nouveau tool MCP `agentcards:execute_code`
- PII detection et tokenization automatique
- Code execution caching et optimizations
- Documentation et tests E2E complets

**Estimation:** 8 stories (3.1 √† 3.8)

**Value Proposition:** R√©duction additionnelle de contexte (<5% ‚Üí <1% pour large datasets), protection automatique des donn√©es sensibles, et traitement local des donn√©es volumineuses (1MB+ ‚Üí <1KB dans contexte)

**Architectural Benefit (Safe-to-Fail Branches + Speculative Execution):** L'isolation du sandbox permet de cr√©er des **branches DAG safe-to-fail** : des t√¢ches qui peuvent √©chouer sans compromettre le workflow global. Contrairement aux appels MCP (effets de bord possibles comme cr√©ation de fichiers ou issues GitHub), le code sandbox est **idempotent et isol√©**.

Cette propri√©t√© d√©bloque la **vraie puissance du speculative execution** (Epic 2) : avec les MCP tools directs, l'ex√©cution sp√©culative est risqu√©e (pr√©diction incorrecte = side effect ind√©sirable), mais avec le sandbox, tu peux :
- **Pr√©dire et ex√©cuter** plusieurs approches simultan√©ment sans risque
- **√âchouer gracieusement** si les pr√©dictions sont incorrectes (pas de corruption)
- **Retry en toute s√©curit√©** sans duplication d'effets
- **A/B test en production** avec plusieurs algorithmes en parall√®le

Le combo **Speculative Execution (Epic 2) + Safe-to-Fail Branches (Epic 3)** transforme le DAG executor en syst√®me de **speculative resilience** : ex√©cuter plusieurs hypoth√®ses simultan√©ment, conserver les succ√®s, ignorer les √©checs.

---

**S√©quence:** Epic 1 ‚Üí Epic 2 ‚Üí Epic 3 (chaque epic build sur le pr√©c√©dent). Epic 3 est compl√©mentaire aux Epics 1-2, ajoutant code execution comme alternative aux tool calls directs pour les cas d'usage avec large datasets.

> **Note:** Detailed epic breakdown with full story specifications is available in [epics.md](./epics.md)

---

## Out of Scope

### Fonctionnalit√©s D√©f√©r√©es Post-MVP

**1. Speculative Execution & Tool Prediction**
- Rationale: Besoin validation empirique que √ßa fonctionne r√©ellement (>70% hit rate)
- Timeline: v1.1+ si tests concluants post-MVP

**2. Plugin System pour API Translation**
- Rationale: Pas de cas d'usage bloquants sans plugins day-1
- Timeline: v1.1 si demand utilisateur

**3. Visual Observability Dashboard**
- Rationale: Telemetry backend + logs CLI suffisent pour MVP
- Timeline: v1.2+ si friction analysis manuelle trop lourde

**4. Edge Deployment (Deno Deploy/Cloudflare Workers)**
- Rationale: Local-first simplifie debugging MVP, architecture edge-ready d√®s le d√©but
- Timeline: v1.1 si demand production deployment

**5. Docker/Container Deployment**
- Rationale: Probl√®mes npx + filesystem volumes observ√©s avec AIRIS
- Timeline: Post-MVP si r√©solution des probl√®mes d'architecture

**6. Advanced Caching (Event-Based Invalidation)**
- Rationale: TTL-based cache suffit MVP
- Timeline: v2+ si usage stats montrent besoin

### Fonctionnalit√©s Non-MVP

**7. Multi-Tenancy & Team Features**
- Pas de support teams/organisations MVP
- Focus: d√©veloppeur individuel

**8. Enterprise Features**
- SSO, audit logs, SLA guarantees
- Timeline: Conditional on enterprise demand

**9. Monetization/Managed Service**
- 100% gratuit open-source MVP
- Pas de paywall ou features premium

**10. Support Protocols Non-MCP**
- Uniquement MCP stdio/SSE support√©s
- Pas de REST, GraphQL, ou autres protocols custom
